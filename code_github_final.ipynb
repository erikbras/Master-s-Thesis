{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imported libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import datetime, time #timedelta, timezone not in use\n",
    "import os                                                   # for operations within directory\n",
    "import re                                                   # for operations within directory\n",
    "from dateutil import parser\n",
    "import time     # for calculating duration of codeÂ¨\n",
    "#import math # for basic mathematic operations such as math.ceil()\n",
    "\n",
    "from scipy.integrate import trapezoid # for integrating response spectra \n",
    "\n",
    "from scipy.interpolate import RegularGridInterpolator # for interpolating wave spectrum from wave direction from north to wave direction rel to vessel heading\n",
    "\n",
    "from geopy.distance import geodesic # for calculating distances between points \n",
    "\n",
    "from misc_func import * # Raphael's misc func for converting between absolute and encounter frequency\n",
    "\n",
    "from scipy import signal #welch and csd for FFT\n",
    "\n",
    "from scipy.signal import butter,filtfilt, freqz, welch # low-pass and high-pass filters as well as welch for FFT\n",
    "\n",
    "from geneticalgorithm import geneticalgorithm as ga # the Genetic Algorithm which is used for solving the optimization problem\n",
    "\n",
    "from scipy.optimize import minimize, differential_evolution\n",
    "\n",
    "import pygad\n",
    "\n",
    "import random # for generating initial population in GA with a fixed seed for reproducable results\n",
    "# \n",
    "from icecream import ic\n",
    "# gowtham interpolate\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(filename):\n",
    "    filename = 'data/' + filename\n",
    "    df = pd.read_csv(filename)\n",
    "    return df\n",
    "\n",
    "def cleanRAO(df):\n",
    "    # Ensure the DataFrame is copied before modification to prevent affecting the original data\n",
    "    df = df.copy()\n",
    "    # Select only the required columns\n",
    "    columns_needed = ['period', 'heaveamp', 'rollamp', 'pitchamp']\n",
    "    df = df[columns_needed]\n",
    "\n",
    "    # Remove the first row\n",
    "    df = df.iloc[2:]  # This skips the 2 first rows as the period equals 0 on the first and there is only values of zero in amplitude in the second\n",
    "\n",
    "    # Calculate the frequency from period and add it as a new column using .loc to avoid SettingWithCopyWarning\n",
    "    df.loc[:, 'freq'] = 1 / df['period']\n",
    "\n",
    "    df['rollamp'] = np.deg2rad(df['rollamp'])\n",
    "    df['pitchamp'] = np.deg2rad(df['pitchamp'])\n",
    "\n",
    "    # Rename columns to be more descriptive\n",
    "    rename_map = {\n",
    "        'heaveamp': 'Heave',\n",
    "        'rollamp': 'Roll_rad',\n",
    "        'pitchamp': 'Pitch_rad'\n",
    "    }\n",
    "    df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# retrieve the vessel RAO from Subsea 7 csv files\n",
    "def getRAOs():\n",
    "    folder_path = 'data/raos'\n",
    "    directions = np.arange(15, 181, 15)  # Array of directions\n",
    "    directions = np.append(directions, 360)\n",
    "\n",
    "    # Initialize dictionaries to hold numpy arrays for each response\n",
    "    response_data = {key: [] for key in ['Heave', 'Roll_rad', 'Pitch_rad']}\n",
    "    frequencies = None  # To store frequency values common across all files\n",
    "\n",
    "    # Generate the file names based on the specified format and known increments\n",
    "    for x in directions:\n",
    "        file_name = f\"wave_dir_{x}.csv\"\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "\n",
    "        # Check if the file exists to avoid errors\n",
    "        if os.path.exists(file_path):\n",
    "            df = pd.read_csv(file_path)\n",
    "            df_cleaned = cleanRAO(df)\n",
    "\n",
    "            if frequencies is None:  # Store frequency values from the first file\n",
    "                frequencies = df_cleaned['freq'].values\n",
    "            \n",
    "            # Extract response data and append as numpy arrays\n",
    "            for key in response_data:\n",
    "                response_data[key].append(df_cleaned[key].values)\n",
    "                \n",
    "        else:\n",
    "            print(f\"File not found: {file_path}\")\n",
    "\n",
    "    # Convert lists of arrays into 2D numpy arrays\n",
    "    for key in response_data:\n",
    "        response_data[key] = np.column_stack(response_data[key])\n",
    "\n",
    "    # Return the response data as a list of 2D numpy arrays along with frequencies\n",
    "    TRF_2d_data = [response_data['Heave'], response_data['Roll_rad'], response_data['Pitch_rad']]\n",
    "\n",
    "    return TRF_2d_data, frequencies, directions\n",
    "\n",
    "# sort the RAOs so it is in the same format as the CFE RAO\n",
    "def sort_RAOs(TRF_2d_data, f0_RAO, beta_deg_RAO):\n",
    "    sorted_RAOs = []\n",
    "    for trf in TRF_2d_data:\n",
    "        if isinstance(trf, np.ndarray) and trf.ndim == 2:\n",
    "            reversed_rows = trf[::-1]\n",
    "            sorted_trf = np.roll(reversed_rows, shift=1, axis=1)\n",
    "            sorted_RAOs.append(sorted_trf)\n",
    "    \n",
    "    # Reverse the numpy array f0_RAO\n",
    "    f0_RAO = f0_RAO[::-1]  # This modifies the array by reversing it\n",
    "\n",
    "    # If beta_deg_RAO is a numpy array, handle the popping of the last element and insertion differently\n",
    "    if isinstance(beta_deg_RAO, np.ndarray):\n",
    "        # Remove the last element and prepend 0 to the array\n",
    "        beta_deg_RAO = np.delete(beta_deg_RAO, -1)  # Removes the last element\n",
    "        beta_deg_RAO = np.insert(beta_deg_RAO, 0, 0)  # Inserts 0 at the start of the array\n",
    "\n",
    "    return sorted_RAOs, f0_RAO, beta_deg_RAO\n",
    "\n",
    "# Helper function to rename the first column to Time\n",
    "def renameColTime(df):\n",
    "\n",
    "    # Rename unnamed column by its index\n",
    "    column_names = list(df.columns)\n",
    "    column_names[0] = 'Time'  # Assuming the unnamed column is the first column\n",
    "    df.columns = column_names\n",
    "\n",
    "    return df\n",
    "\n",
    "def getVesselData():\n",
    "    df_motions = getData('motions_ts.csv')\n",
    "    df_pos = getData('position_and_heading.csv')\n",
    "    df_acc = getData('raw_accelerometer_motions_ts.csv')\n",
    "    df_speed = getData('speed_lat_lon_ts.csv')    \n",
    "\n",
    "    # Rename unnamed column by its index\n",
    "    df_motions = renameColTime(df_motions)\n",
    "    df_pos = renameColTime(df_pos)\n",
    "    df_acc = renameColTime(df_acc)\n",
    "\n",
    "    #df_speed = df_speed.drop(columns=df_speed.columns[0]) # Gets rid of first column which is some kind of indexing\n",
    "    #df_speed.columns = ['Time', 'latitude', 'longitude', 'SOG']\n",
    "\n",
    "    df_pos = df_pos.dropna() # gets rid of first row\n",
    "    df_pos['Time'] = pd.to_datetime(df_pos['Time'], utc=True)\n",
    "    df_pos = df_pos.rename(columns={'Time': 'Timestamp'})\n",
    "    df_motions['Timestamp'] = pd.to_datetime(df_motions['Timestamp'], utc=True)\n",
    "    df_speed['Timestamp'] = pd.to_datetime(df_speed['Timestamp'], utc=True)\n",
    "\n",
    "    #df_speed['Speed'] = df_speed['SOG'] * 0.514444\n",
    "\n",
    "    df_acc['Timestamp'] = pd.to_datetime(df_acc['Timestamp'], utc=True)\n",
    "  \n",
    "    return df_motions, df_pos, df_acc, df_speed\n",
    "\n",
    "def getWaveSpectra(csv_files):\n",
    "    # Initialize an empty list to store each DataFrame\n",
    "    dfs = []\n",
    "\n",
    "        # Loop through the list of CSV files\n",
    "    for file in csv_files:\n",
    "        # Check if file exists to avoid FileNotFoundError\n",
    "        file = 'data/' + file\n",
    "        if os.path.exists(file):\n",
    "            # Read the current CSV file into a DataFrame\n",
    "            df = pd.read_csv(file)\n",
    "            \n",
    "            # Append the DataFrame to the list\n",
    "            dfs.append(df)\n",
    "        else:\n",
    "            print(f\"File {file} not found.\")\n",
    "\n",
    "    # Concatenate all DataFrames in the list into a single DataFrame\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "    final_df= final_df.rename(columns={'time': 'Timestamp'}) # ensure it follows the standard notation\n",
    "    #final_df['Timestamp'] = pd.to_datetime(final_df['Timestamp'], utc=True)\n",
    "    final_df.set_index(pd.to_datetime(final_df['Timestamp']), inplace=True)\n",
    "    \n",
    "    return final_df\n",
    "\n",
    "def dfTimeFilter(df, start_time, end_time):\n",
    "    return df[(df['Time'] >= start_time) & (df['Time'] <= end_time)]\n",
    "\n",
    "def countRowsOutsideTime(df, start_time, end_time):\n",
    "    return len(df[~((df['Time'] >= start_time) & (df['Time'] <= end_time))])\n",
    "\n",
    "# Datasets\n",
    "def SampleRateDF(df):\n",
    "    time_data = df['Time']\n",
    "    #print(time_data.head())\n",
    "    time1 = parser.parse(time_data.iloc[0])\n",
    "    time2 = parser.parse(time_data.iloc[1])\n",
    "\n",
    "    timestamp1 = time1.timestamp()\n",
    "    timestamp2 = time2.timestamp()\n",
    "\n",
    "    period = (timestamp2 - timestamp1)\n",
    "    samplingRate = 1/period\n",
    "\n",
    "    return round(samplingRate,2)\n",
    "\n",
    "# input date is a string on the following format:\n",
    "def toDatetime(date):\n",
    "    date = date[0:-6]\n",
    "    #year = date[]\n",
    "    #print(f\"this is date after slicing: {date}\")\n",
    "    date = pd.to_datetime(date)\n",
    "    \n",
    "    return date\n",
    "\n",
    "def dfTimeDuration(df):\n",
    "    # Calculate the difference between the last and first datetime values\n",
    "    time_difference = df['Time'].iloc[-1] - df['Time'].iloc[0]\n",
    "    return time_difference\n",
    "\n",
    "def printStartEndTime(df):\n",
    "    print(f\"this is the start time: {df['Timestamp'].iloc[0]}\")\n",
    "    print(f\"this is the end time: {df['Timestamp'].iloc[-1]}\")\n",
    "\n",
    "\n",
    "def saveSVG(title, folder_path):\n",
    "    \"\"\"\n",
    "    Saves the plot as an SVG in a specified folder under the current directory.\n",
    "    Automatically appends the current date to organize the files.\n",
    "\n",
    "    :param title: Title and base name for the file to be saved.\n",
    "    :param folder_path: Relative path from the current directory where the file should be saved.\n",
    "                        \n",
    "    \"\"\"\n",
    "    # Generate a unique filename using the current date and time\n",
    "    current_time = datetime.now().strftime(\"%H%M\")\n",
    "    filename = f\"{current_time}_\"\n",
    "\n",
    "    # Generate today's date string in the format YYYY-MM-DD\n",
    "    date_string = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create the new directory path by appending the date string\n",
    "    date_folder_path = os.path.join(folder_path, date_string)\n",
    "\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(date_folder_path):\n",
    "        os.makedirs(date_folder_path)\n",
    "    \n",
    "    # Append hour and minute to the folder path\n",
    "    hour_minute_folder_path = os.path.join(date_folder_path, current_time)\n",
    "\n",
    "    # Check if the hour-minute directory exists, if not, create it\n",
    "    if not os.path.exists(hour_minute_folder_path):\n",
    "        os.makedirs(hour_minute_folder_path)\n",
    "\n",
    "    title = filename + title\n",
    "\n",
    "    # Define the file path including the name of the SVG file you want to save\n",
    "    file_path = os.path.join(hour_minute_folder_path, title + '.svg')\n",
    "\n",
    "    # Save the plot as an SVG file in the specified directory\n",
    "    plt.savefig(file_path)\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "\n",
    "def saveSVG(title, folder_path, method):\n",
    "    \"\"\"\n",
    "    Saves the plot as an SVG in a specified folder under the current directory.\n",
    "    Automatically appends the current date to organize the files.\n",
    "\n",
    "    :param title: Title and base name for the file to be saved.\n",
    "    :param folder_path: Relative path from the current directory where the file should be saved.\n",
    "                        \n",
    "    \"\"\"\n",
    "    # Create the new directory path by appending the date string\n",
    "    method_folder_path = os.path.join(folder_path, method)\n",
    "     # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(method_folder_path):\n",
    "        os.makedirs(method_folder_path)\n",
    "\n",
    "    # Generate a unique filename using the current date and time\n",
    "    current_time = datetime.now().strftime(\"%H%M\")\n",
    "    filename = f\"{current_time}_\"\n",
    "\n",
    "    # Generate today's date string in the format YYYY-MM-DD\n",
    "    date_string = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create the new directory path by appending the date string\n",
    "    date_folder_path = os.path.join(method_folder_path, date_string)\n",
    "\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(date_folder_path):\n",
    "        os.makedirs(date_folder_path)\n",
    "    \n",
    "    # Append hour and minute to the folder path\n",
    "    hour_minute_folder_path = os.path.join(date_folder_path, current_time)\n",
    "\n",
    "    # Ensure the hour-minute directory exists\n",
    "    if not os.path.exists(hour_minute_folder_path):\n",
    "        os.makedirs(hour_minute_folder_path)\n",
    "        print(f\"Created directory: {hour_minute_folder_path}\")\n",
    "\n",
    "    # Generate full path for the file, checking if it already exists\n",
    "    file_path = os.path.join(hour_minute_folder_path, f\"{filename}{title}.svg\")\n",
    "    counter = 1\n",
    "    while os.path.exists(file_path):\n",
    "        file_path = os.path.join(hour_minute_folder_path, f\"{filename}{title}_{counter}.svg\")\n",
    "        counter += 1\n",
    "\n",
    "    # Save the plot as an SVG file in the specified directory\n",
    "    plt.savefig(file_path)\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def saveSVGContour(title, folder_path):\n",
    "    \"\"\"\n",
    "    Saves the plot as an SVG in a specified folder under the current directory.\n",
    "    Automatically appends the current date to organize the files.\n",
    "\n",
    "    :param title: Title and base name for the file to be saved.\n",
    "    :param folder_path: Relative path from the current directory where the file should be saved.\n",
    "                        \n",
    "    \"\"\"\n",
    "    # Generate a unique filename using the current date and time\n",
    "    current_time = datetime.now().strftime(\"%H%M\")\n",
    "    filename = f\"{current_time}_\"\n",
    "\n",
    "    # Generate today's date string in the format YYYY-MM-DD\n",
    "    date_string = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create the new directory path by appending the date string\n",
    "    date_folder_path = os.path.join(folder_path, date_string)\n",
    "\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(date_folder_path):\n",
    "        os.makedirs(date_folder_path)\n",
    "    \n",
    "    # Append hour and minute to the folder path\n",
    "    hour_minute_folder_path = os.path.join(date_folder_path, current_time)\n",
    "\n",
    "    # Ensure the hour-minute directory exists\n",
    "    if not os.path.exists(hour_minute_folder_path):\n",
    "        os.makedirs(hour_minute_folder_path)\n",
    "        print(f\"Created directory: {hour_minute_folder_path}\")\n",
    "\n",
    "    # Generate full path for the file, checking if it already exists\n",
    "    file_path = os.path.join(hour_minute_folder_path, f\"{filename}{title}.svg\")\n",
    "    counter = 1\n",
    "    while os.path.exists(file_path):\n",
    "        file_path = os.path.join(hour_minute_folder_path, f\"{filename}{title}_{counter}.svg\")\n",
    "        counter += 1\n",
    "\n",
    "    # Save the plot as an SVG file in the specified directory\n",
    "    plt.savefig(file_path)\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "\n",
    "\n",
    "def saveSVGWS(title, folder_path):\n",
    "    \"\"\"\n",
    "    Saves the plot as an SVG in a specified folder under the current directory.\n",
    "    Automatically appends the current date to organize the files.\n",
    "\n",
    "    :param title: Title and base name for the file to be saved.\n",
    "    :param folder_path: Relative path from the current directory where the file should be saved.\n",
    "                        \n",
    "    \"\"\"\n",
    "\n",
    "    # Generate a unique filename using the current date and time\n",
    "    current_time = datetime.now().strftime(\"%H%M\")\n",
    "    filename = f\"{current_time}_\"\n",
    "\n",
    "    # Generate today's date string in the format YYYY-MM-DD\n",
    "    date_string = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create the new directory path by appending the date string\n",
    "    date_folder_path = os.path.join(folder_path, date_string)\n",
    "\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(date_folder_path):\n",
    "        os.makedirs(date_folder_path)\n",
    "    \n",
    "    # Append hour and minute to the folder path\n",
    "    hour_minute_folder_path = os.path.join(date_folder_path, current_time)\n",
    "\n",
    "    # Ensure the hour-minute directory exists\n",
    "    if not os.path.exists(hour_minute_folder_path):\n",
    "        os.makedirs(hour_minute_folder_path)\n",
    "        print(f\"Created directory: {hour_minute_folder_path}\")\n",
    "\n",
    "    # Generate full path for the file, checking if it already exists\n",
    "    file_path = os.path.join(hour_minute_folder_path, f\"{filename}{title}.svg\")\n",
    "    counter = 1\n",
    "    while os.path.exists(file_path):\n",
    "        file_path = os.path.join(hour_minute_folder_path, f\"{filename}{title}_{counter}.svg\")\n",
    "        counter += 1\n",
    "\n",
    "    # Save the plot as an SVG file in the specified directory\n",
    "    plt.savefig(file_path)\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "\n",
    "\n",
    "\n",
    "def savetoCSV(df, base_name, directory=\".\"):\n",
    "    \"\"\"\n",
    "    Saves the DataFrame with a name that increments based on the highest existing iteration number.\n",
    "    Depending on the base_name, files are saved in specific folders.\n",
    "\n",
    "    :param df: DataFrame to save.\n",
    "    :param base_name: Base name for the file, before the iteration part and without the extension.\n",
    "    :param directory: Directory to check for existing files and save the new file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the folder based on base_name\n",
    "    if 'alpha_segment' in base_name:\n",
    "        sub_directory = 'df_results'\n",
    "    elif 'responseSpectrum_calculated' in base_name:\n",
    "        sub_directory = 'responseSpectrumResults'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported base name. Expected names containing 'df_results' or 'responseSpectrum'.\")\n",
    "    \n",
    "    # Create the full directory path if it does not exist\n",
    "    full_directory = os.path.join(directory, sub_directory)\n",
    "    os.makedirs(full_directory, exist_ok=True)\n",
    "    pattern = re.compile(rf\"{base_name}_iter_(\\d+)\\.csv$\")\n",
    "    highest_num = 0\n",
    "\n",
    "    # Look through all files in the specified directory to find the highest iteration number\n",
    "    for file_name in os.listdir(full_directory):\n",
    "        match = pattern.match(file_name)\n",
    "        if match:\n",
    "            current_num = int(match.group(1))\n",
    "            highest_num = max(highest_num, current_num)\n",
    "\n",
    "    # Increment the highest number found for the new file name\n",
    "    new_file_name = f\"{base_name}_iter_{highest_num + 1}.csv\"\n",
    "    df.to_csv(os.path.join(full_directory, new_file_name), index=False)\n",
    "    print(f\"DataFrame saved as {os.path.join(full_directory, new_file_name)}\")\n",
    "\n",
    "def savetoCSVAllSegments(df, base_name, directory=\".\"):\n",
    "    \"\"\"\n",
    "    Saves the DataFrame with a name that increments based on the highest existing iteration number.\n",
    "    Depending on the base_name, files are saved in specific folders.\n",
    "\n",
    "    :param df: DataFrame to save.\n",
    "    :param base_name: Base name for the file, before the iteration part and without the extension.\n",
    "    :param directory: Directory to check for existing files and save the new file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the folder based on base_name\n",
    "    if 'alpha_segment' in base_name:\n",
    "        sub_directory = 'df_results_ALL'\n",
    "    elif 'responseSpectrum_calculated' in base_name:\n",
    "        sub_directory = 'responseSpectrumResults_ALL'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported base name. Expected names containing 'df_results' or 'responseSpectrum'.\")\n",
    "    \n",
    "    # Create the full directory path if it does not exist\n",
    "    full_directory = os.path.join(directory, sub_directory)\n",
    "    os.makedirs(full_directory, exist_ok=True)\n",
    "    pattern = re.compile(rf\"{base_name}_iter_(\\d+)\\.csv$\")\n",
    "    highest_num = 0\n",
    "\n",
    "    # Look through all files in the specified directory to find the highest iteration number\n",
    "    for file_name in os.listdir(full_directory):\n",
    "        match = pattern.match(file_name)\n",
    "        if match:\n",
    "            current_num = int(match.group(1))\n",
    "            highest_num = max(highest_num, current_num)\n",
    "\n",
    "    # Increment the highest number found for the new file name\n",
    "    new_file_name = f\"{base_name}_iter_{highest_num + 1}.csv\"\n",
    "    df.to_csv(os.path.join(full_directory, new_file_name), index=False)\n",
    "    print(f\"DataFrame saved as {os.path.join(full_directory, new_file_name)}\")\n",
    "\n",
    "def savetoCSVAllSegmentsCombined(df, base_name, directory=\".\"):\n",
    "    \"\"\"\n",
    "    Saves the DataFrame with a name that increments based on the highest existing iteration number.\n",
    "    Depending on the base_name, files are saved in specific folders.\n",
    "\n",
    "    :param df: DataFrame to save.\n",
    "    :param base_name: Base name for the file, before the iteration part and without the extension.\n",
    "    :param directory: Directory to check for existing files and save the new file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Determine the folder based on base_name\n",
    "    if 'alpha_segment' in base_name:\n",
    "        sub_directory = 'df_results_ALL_combined'\n",
    "    elif 'responseSpectrum_calculated' in base_name:\n",
    "        sub_directory = 'responseSpectrumResults_ALL_combined'\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported base name. Expected names containing 'df_results' or 'responseSpectrum'.\")\n",
    "    \n",
    "    # Create the full directory path if it does not exist\n",
    "    full_directory = os.path.join(directory, sub_directory)\n",
    "    os.makedirs(full_directory, exist_ok=True)\n",
    "    pattern = re.compile(rf\"{base_name}_iter_(\\d+)\\.csv$\")\n",
    "    highest_num = 0\n",
    "\n",
    "    # Look through all files in the specified directory to find the highest iteration number\n",
    "    for file_name in os.listdir(full_directory):\n",
    "        match = pattern.match(file_name)\n",
    "        if match:\n",
    "            current_num = int(match.group(1))\n",
    "            highest_num = max(highest_num, current_num)\n",
    "\n",
    "    # Increment the highest number found for the new file name\n",
    "    new_file_name = f\"{base_name}_iter_{highest_num + 1}.csv\"\n",
    "    df.to_csv(os.path.join(full_directory, new_file_name), index=False)\n",
    "    print(f\"DataFrame saved as {os.path.join(full_directory, new_file_name)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentData(df, segment_duration, start, end):\n",
    "    sr = SampleRateDF(df)\n",
    "    print(f\"this is the sample rate of the df: {sr}\")\n",
    "\n",
    "    # Convert start and end timestamps to pandas Timestamp objects\n",
    "    start_time = pd.Timestamp(start)\n",
    "    end_time = pd.Timestamp(end)\n",
    "\n",
    "    # Calculate segment duration in seconds\n",
    "    segment_duration_sec = segment_duration * 60\n",
    "\n",
    "    segments = []\n",
    "\n",
    "    # Initialize the segment start time\n",
    "    segment_start_time = start_time\n",
    "\n",
    "    while segment_start_time < end_time:\n",
    "        # Calculate segment end time\n",
    "        segment_end_time = segment_start_time + pd.Timedelta(seconds=segment_duration_sec)\n",
    "\n",
    "        # Extract segment data from the dataframe\n",
    "        segment = df[(df['Timestamp'] >= segment_start_time) & (df['Timestamp'] < segment_end_time)]\n",
    "\n",
    "        # Append segment to the list\n",
    "        segments.append(segment)\n",
    "\n",
    "        # Move to the next segment start time\n",
    "        segment_start_time = segment_end_time\n",
    "\n",
    "    return segments\n",
    "\n",
    "def avgSegments(segments):\n",
    "    averaged_segments = []\n",
    "    for segment in segments:\n",
    "        # Calculate the mean only for numeric columns\n",
    "        averaged_segment = segment.mean(numeric_only=True)\n",
    "        \n",
    "        # Get the 'Timestamp' from the first row of the segment\n",
    "        first_timestamp = segment['Timestamp'].iloc[0]\n",
    "        averaged_segment['Timestamp'] = first_timestamp\n",
    "        \n",
    "        averaged_segments.append(averaged_segment)\n",
    "\n",
    "    return averaged_segments\n",
    "\n",
    "def segmentData_pos(df, segment_duration, start, end):\n",
    "\n",
    "    # Sample rate in samples per hour given sampling once every 10 minutes\n",
    "    sr = 6  # 60 minutes / 10 minutes = 6 samples per hour\n",
    "\n",
    "    print(f\"This is the assumed sample rate of the df: {sr} samples per hour\")\n",
    "\n",
    "    # Assuming df['Timestamp'] is already in datetime format, if not, convert\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "    # Samples per segment is fixed at 4 given the 10-minute sampling rate for a 30-minute duration\n",
    "    samples_per_segment = 4  # As we include the start and end within the 30-minute window\n",
    "\n",
    "    segments = []\n",
    "\n",
    "    # Filter df for rows within the start and end times to reduce processing\n",
    "    df_filtered = df[(df['Timestamp'] >= pd.to_datetime(start)) & (df['Timestamp'] <= pd.to_datetime(end))]\n",
    "\n",
    "    # Calculate segment start indices\n",
    "    segment_indices = range(0, len(df_filtered), samples_per_segment - 1)\n",
    "\n",
    "    # Create segments\n",
    "    for i in segment_indices:\n",
    "        # Ensure not to exceed the DataFrame length\n",
    "        if i + samples_per_segment <= len(df_filtered):\n",
    "            segment = df_filtered.iloc[i:i + samples_per_segment]\n",
    "\n",
    "            segments.append(segment)\n",
    "\n",
    "    return segments\n",
    "\n",
    "def segmentData_ws(df_ws_interpolated, start, end):\n",
    "    \"\"\"\n",
    "    Filters the dictionary of arrays by timestamps to include only those within\n",
    "    the specified start and end timestamps.\n",
    "\n",
    "    Parameters:\n",
    "    - df_ws_interpolated: Dictionary with keys as timestamps and values as arrays.\n",
    "    - start: Start timestamp (inclusive).\n",
    "    - end: End timestamp (inclusive).\n",
    "\n",
    "    Returns:\n",
    "    - A filtered dictionary with timestamps within the specified range.\n",
    "    \"\"\"\n",
    "    # Convert start and end to pandas timestamps if they are not already\n",
    "    start = pd.to_datetime(start)\n",
    "    end = pd.to_datetime(end)\n",
    "\n",
    "    start = start.tz_convert(None)\n",
    "    end = end.tz_convert(None)\n",
    "\n",
    "    # Filter the dictionary\n",
    "    filtered_dict = {timestamp: array for timestamp, array in df_ws_interpolated.items() if start <= timestamp < end} # does not include the end segment as it has to match nr of elements in df_pos\n",
    "\n",
    "    return filtered_dict\n",
    "    \n",
    "def measure_duration_column(df, datetime_column):\n",
    "    #Measure the duration between the first and last datetime in a specified DataFrame column.\n",
    "\n",
    "    if datetime_column == 'Timestamp': # does not need to be converted to perform calculations\n",
    "        time_start = df[datetime_column].iloc[0]\n",
    "        time_end = df[datetime_column].iloc[-1]\n",
    "\n",
    "    else:\n",
    "\n",
    "        time_start = toDatetime(df[datetime_column].iloc[0])\n",
    "\n",
    "        time_end = toDatetime(df[datetime_column].iloc[-1])\n",
    "    \n",
    "    duration = time_end - time_start\n",
    "\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motionPlot(df, step=1):\n",
    "    df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(14, 10))\n",
    "\n",
    "    for ax in axes.flat:\n",
    "        ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H: %M'))\n",
    "        ax.xaxis.set_major_locator(mdates.AutoDateLocator())\n",
    "        ax.set_xlabel(\"Time\")\n",
    "        ax.tick_params(axis='x', rotation=45)\n",
    "\n",
    "    # Plotting \"Roll\"\n",
    "    axes[0, 0].plot_date(df['Timestamp'][::step], df['Roll'][::step], '-')\n",
    "    axes[0, 0].set_ylabel(\"Degrees\")\n",
    "    axes[0, 0].legend([\"Roll\"])\n",
    "\n",
    "    # Plotting \"Pitch\"\n",
    "    axes[0, 1].plot_date(df['Timestamp'][::step], df['Pitch'][::step], '-')\n",
    "    axes[0, 1].set_ylabel(\"Degrees\")\n",
    "    axes[0, 1].legend([\"Pitch\"])\n",
    "\n",
    "    # Plotting \"Heave\"\n",
    "    axes[1, 0].plot_date(df['Timestamp'][::step], df['Heave'][::step], '-')\n",
    "    axes[1, 0].set_ylabel(\"Meters\")\n",
    "    axes[1, 0].legend([\"Heave\"])\n",
    "\n",
    "    # Plotting \"Heave Velocity\"\n",
    "    axes[1, 1].plot_date(df['Timestamp'][::step], df['Heave_velocity'][::step], '-')\n",
    "    axes[1, 1].set_ylabel(\"Meters/Second\")\n",
    "    axes[1, 1].legend([\"Heave Velocity\"])\n",
    "\n",
    "    # Rotate date labels for clarity\n",
    "    #plt.setp(axes.flat, rotation=45, ha=\"right\")\n",
    "\n",
    "    # Adjust layout for a cleaner look\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def PosPlotTotal(df_pos):\n",
    "    #print(f\"the df_pos contain the following types: {df_pos.info()}\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    # Plot trajectory\n",
    "    plt.plot(df_pos['longitude'], df_pos['latitude'], 'b-', label='Trajectory')\n",
    "\n",
    "    # targets the indeces of every hour in the df_pos\n",
    "    hourly_indices = range(0, df_pos.shape[0], 6)\n",
    "\n",
    "    # Overlay red dots for every hour\n",
    "    plt.plot(df_pos.iloc[hourly_indices]['longitude'], df_pos.iloc[hourly_indices]['latitude'], 'r.', markersize=10, label='Hourly Position')  # Red dots at hourly intervals\n",
    "\n",
    "    # Adding plot details\n",
    "    plt.title('Vessel Trajectory with Hourly Marks')\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def posPlotheading(df_pos):\n",
    "    #df_pos = df_pos.set_index('Timestamp')\n",
    "\n",
    "    # Now, plot the 'Heading' column\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    df_pos.plot(x='Timestamp', y='hdt')\n",
    "\n",
    "    plt.title('Heading Over Time')\n",
    "    plt.xlabel('Time') # Since 'Timestamp' is the index, x-axis represents time\n",
    "    plt.ylabel('Heading Value')\n",
    "    plt.xticks(rotation=45) # Rotate x-axis labels for better readability\n",
    "    plt.tight_layout() # Adjust layout to not cut off labels\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plotError(df_results_alpha, save = False):\n",
    "    title_fig = 'Error_progress'\n",
    "    error_values = df_results_alpha['Error']\n",
    "\n",
    "    # Plotting the error values\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(error_values, marker='o', linestyle='-')\n",
    "    plt.title('Error Progress')\n",
    "    plt.xlabel('Segment')\n",
    "    plt.ylabel('Error')\n",
    "    plt.grid(True)\n",
    "\n",
    "    if (save):\n",
    "            folder_path = 'Plots/Results'\n",
    "\n",
    "            saveSVG(title_fig, folder_path)\n",
    "\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response Spectrum plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plotResponseSpectrum(freq, df, title, save = False):\n",
    "  # Want  to only plot for frequencies [0, 0.3] as there is very little response for frequencies above 0.3 Hz\n",
    "  freq = freq[freq < 0.3]\n",
    "  indices = len(freq)\n",
    "  df = df.iloc[:indices]\n",
    "              \n",
    "  fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(12, 10))\n",
    "\n",
    "  fig.suptitle(title, fontsize=16)\n",
    "\n",
    "\n",
    "  # Plotting \"Roll\"\n",
    "\n",
    "  axes[0,0].plot(freq, np.abs(df['Roll_rad']))\n",
    "  axes[0,0].set_xlabel(\"frequency [Hz]\")\n",
    "  axes[0,0].set_ylabel(\"Roll [rad**2/Hz]\")\n",
    "  axes[0,0].set_title('Roll')\n",
    "\n",
    "  # Plotting \"Pitch\"\n",
    "\n",
    "  axes[0,1].plot(freq, np.abs(df['Pitch_rad']))\n",
    "  axes[0,1].set_xlabel(\"frequency [Hz]\")\n",
    "  axes[0,1].set_ylabel(\"Pitch [rad**2/Hz]\")\n",
    "  axes[0,1].set_title('Pitch')\n",
    "\n",
    "\n",
    "  # Plotting \"Heave\"\n",
    "  axes[1,0].plot(freq, np.abs(df['Heave']))\n",
    "  axes[1,0].set_xlabel(\"frequency [Hz]\")\n",
    "  axes[1,0].set_ylabel(\"Heave [m**2/Hz]\")\n",
    "  axes[1,0].set_title('Heave')\n",
    "\n",
    "\n",
    "  # Plotting \"Heave Velocity\"\n",
    "\n",
    "  axes[1,1].plot(freq, np.abs(df['Heave_velocity']))\n",
    "  axes[1,1].set_xlabel(\"frequency [Hz]\")\n",
    "  axes[1,1].set_ylabel(\"Heave velocity [(m/s)**2/Hz]\")\n",
    "  axes[1,1].set_title('Heave Velocity')\n",
    "\n",
    "  if (save):\n",
    "      folder_path = 'Plots/ResponseSpectra'\n",
    "      \n",
    "      saveSVG(title, folder_path)\n",
    "\n",
    "  # Adjust layout for a cleaner look\n",
    "  plt.tight_layout()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "  return\n",
    "    \n",
    "def plotResponseSpectrumResult(segment, freq, responseSpectrum_measured, responseSpectrum_calculated, title_file, save = False):\n",
    "\n",
    "  mask_freq = freq < 0.3\n",
    "  freq_filtered = freq[mask_freq]\n",
    "  \n",
    "  responseSpectrum_measured_filtered = responseSpectrum_measured[segment].loc[mask_freq]              # responseSpectrum_measured is a list of dfs\n",
    "  \n",
    "  # is only a single df. Sort by column segment so that it matches current segment\n",
    "  mask_segment = responseSpectrum_calculated['segment'] == segment                                    # Creating a mask where 'segment' equals the current segment\n",
    "\n",
    "  filtered_responseSpectrum_calculated = responseSpectrum_calculated[mask_segment]                    # Applying the mask to the DataFrame to filter rows\n",
    "  \n",
    "\n",
    "  segment_array = filtered_responseSpectrum_calculated['segment']\n",
    "\n",
    "\n",
    "  filtered_responseSpectrum_calculated =  filtered_responseSpectrum_calculated.loc[mask_freq]         # apply mask for only containing frequencies up to 0.3 hz \n",
    "\n",
    "  filtered_responseSpectrum_calculated = filtered_responseSpectrum_calculated.reset_index(drop=True)  # reset the index so that it matches the measured response spectrum. \n",
    "\n",
    "  segment_array = filtered_responseSpectrum_calculated['segment']\n",
    "  title_fig = f'Response estimation results for segment: {segment}'       \n",
    "  fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 10))  # Adjusted width\n",
    "  fig.suptitle(title_fig, fontsize=16)\n",
    "\n",
    "\n",
    "  # Plotting \"Roll\"\n",
    "  linewidth_measured = 2\n",
    "  linewidth_calculated = 1.5\n",
    "  measured_color = 'g'      # green\n",
    "  calculated_color = 'b'    # Blue\n",
    "  error_color = 'r'         # A bright red for error\n",
    "  measured_marker = 's'     # Square marker\n",
    "\n",
    "  # Titles for each subplot\n",
    "  titles = ['Heave', 'Roll', 'Pitch']\n",
    "  y_labels = ['Heave [m**2/Hz]', 'Roll [rad**2/Hz]', 'Pitch [rad**2/Hz]']\n",
    "\n",
    "  # Data keys for each plot, assuming these are column names in your DataFrames\n",
    "  data_keys = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "  # Iterate over the axes, titles, and data keys to create each subplot\n",
    "  for ax, title, y_label, key in zip(axes, titles, y_labels, data_keys):\n",
    "      # Plot measured data\n",
    "      ax.plot(freq_filtered, np.abs(responseSpectrum_measured_filtered[key]), \n",
    "              label='Measured', color=measured_color, linewidth=linewidth_measured, \n",
    "              markersize=4, marker=measured_marker)\n",
    "\n",
    "      # Plot calculated data\n",
    "      ax.plot(freq_filtered, np.abs(filtered_responseSpectrum_calculated[key]), \n",
    "              label='Calculated', color=calculated_color, linestyle='-', \n",
    "              linewidth=linewidth_calculated)\n",
    "\n",
    "      # Calculate and plot error\n",
    "      error = np.abs(responseSpectrum_measured_filtered[key] - filtered_responseSpectrum_calculated[key])\n",
    "      ax.plot(freq_filtered, error, label='Error', color=error_color, linestyle='--', \n",
    "              linewidth=1.5)\n",
    "\n",
    "      # Set titles and labels\n",
    "      ax.set_title(title)\n",
    "      ax.set_xlabel(\"Frequency [Hz]\")\n",
    "      ax.set_ylabel(y_label)\n",
    "\n",
    "      # Add legend\n",
    "      ax.legend()\n",
    "      ax.grid(True)\n",
    "  \n",
    "  if (save):\n",
    "      folder_path = 'Plots/Results'\n",
    "      saveSVG(title_file, folder_path)\n",
    "\n",
    "  # Adjust layout for a cleaner look\n",
    "  plt.tight_layout()\n",
    "  plt.show()\n",
    "  return\n",
    "\n",
    "def plotErrorBetweenSpectra(df_error_SM, df_error_WA, title_file, save= False):\n",
    "    title_fig = f'Error between Measured and Calculated Response Spectra for different averaging methods'\n",
    "\n",
    "    segment_array = np.arange(len(df_error_SM))\n",
    "         \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 10))  # Adjusted width\n",
    "    fig.suptitle(title_fig, fontsize=16)\n",
    "\n",
    "    linewidth_measured = 2\n",
    "    linewidth_calculated = 2\n",
    "    measured_color = 'r'      # red\n",
    "    calculated_color = 'b'    # Blue\n",
    "    #error_color = 'r'         # A bright red for error\n",
    "    #measured_marker = 's'     # Square marker\n",
    "\n",
    "    # Titles for each subplot\n",
    "    titles = ['Heave', 'Roll', 'Pitch']\n",
    "    y_labels = ['Heave [m**2/Hz]', 'Roll [rad**2/Hz]', 'Pitch [rad**2/Hz]']\n",
    "\n",
    "    # Data keys for each plot, assuming these are column names in your DataFrames\n",
    "    data_keys = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "    # Iterate over the axes, titles, and data keys to create each subplot\n",
    "    for ax, title, y_label, key in zip(axes, titles, y_labels, data_keys):\n",
    "        # Plot measured data\n",
    "        ax.plot(segment_array, np.abs(df_error_SM[key]), \n",
    "                label='Simple Mean', color=measured_color, linestyle = '--', linewidth=linewidth_measured, \n",
    "                markersize=4)\n",
    "\n",
    "        # Plot calculated data\n",
    "        ax.plot(segment_array, np.abs(df_error_WA[key]), \n",
    "                label='Weighted avg', color=calculated_color, linestyle='-', \n",
    "                linewidth=linewidth_calculated)\n",
    "\n",
    "        # Set titles and labels\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Segment\")\n",
    "        ax.set_ylabel(y_label)\n",
    "\n",
    "        # Add legend\n",
    "        ax.legend()\n",
    "   \n",
    "    if (save):\n",
    "        folder_path = 'Plots/Results'\n",
    "        saveSVG(title_file, folder_path)\n",
    "\n",
    "    # Adjust layout for a cleaner look\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def sliceCalculatedResponseSpectrum(responseSpectrum_calculated, segment, mask_freq):\n",
    "      # is only a single df. Sort by column segment so that it matches current segment\n",
    "    mask_segment = responseSpectrum_calculated['segment'] == segment\n",
    "    filtered_responseSpectrum_calculated = responseSpectrum_calculated[mask_segment] \n",
    "    filtered_responseSpectrum_calculated =  filtered_responseSpectrum_calculated.loc[mask_freq]         # apply mask for only containing frequencies up to 0.3 hz \n",
    "    filtered_responseSpectrum_calculated = filtered_responseSpectrum_calculated.reset_index(drop=True)  # reset the index so that it matches the measured response spectrum.\n",
    "\n",
    "    return filtered_responseSpectrum_calculated\n",
    "\n",
    "\n",
    "def plotResponseSpectrumResult_avg_method(segment, freq, responseSpectrum_calculated_SM, responseSpectrum_calculated_WA, df_error_SM, df_error_WA, df_error_calculated, df_results_alpha_current, responseSpectrum_measured, responseSpectrum_calculated, title_file, save = False):\n",
    "    mask_freq = freq < 0.3\n",
    "    freq_filtered = freq[mask_freq]\n",
    "\n",
    "    responseSpectrum_measured_curr = responseSpectrum_measured[segment]\n",
    "    mask_segment = responseSpectrum_calculated['segment'] == segment\n",
    "    filtered_responseSpectrum_calculated = responseSpectrum_calculated[mask_segment] \n",
    "\n",
    "    #check_dataframe_indices(responseSpectrum_measured_curr, filtered_responseSpectrum_calculated, responseSpectrum_calculated_SM, responseSpectrum_calculated_WA)\n",
    "    \n",
    "    responseSpectrum_measured_filtered = responseSpectrum_measured[segment].loc[mask_freq]              # responseSpectrum_measured is a list of dfs\n",
    "    \n",
    "    filtered_responseSpectrum_calculated = sliceCalculatedResponseSpectrum(responseSpectrum_calculated, segment,mask_freq)\n",
    "    filtered_responseSpectrum_calculated_SM = sliceCalculatedResponseSpectrum(responseSpectrum_calculated_SM, segment, mask_freq)\n",
    "    filtered_responseSpectrum_calculated_WA = sliceCalculatedResponseSpectrum(responseSpectrum_calculated_WA, segment, mask_freq)\n",
    "\n",
    "    df_error_calculated_curr = df_error_calculated.iloc[segment]\n",
    "    df_error_SM_curr = df_error_SM.iloc[segment] # on the form ['Heave' : x, 'Pitch_rad': x, 'Roll_rad': x ]\n",
    "    df_error_WA_curr = df_error_WA.iloc[segment]\n",
    "\n",
    "    segment_array = filtered_responseSpectrum_calculated['segment']\n",
    "\n",
    "    title_fig = f'Response estimation results for segment: {segment}'       \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 10))  # Adjusted width\n",
    "    fig.suptitle(title_fig, fontsize=20, fontweight='bold')\n",
    "\n",
    "\n",
    "    # Plotting \"Roll\"\n",
    "    linewidth_measured = 1.0\n",
    "    linewidth_calculated = 1.0\n",
    "    measured_color = 'g'      # green\n",
    "    calculated_color = 'k'    # black\n",
    "    SM_color = 'r'         # A bright red for error\n",
    "    WA_color = 'b'\n",
    "    measured_marker = 's'     # Square marker\n",
    "\n",
    "    # Titles for each subplot\n",
    "    titles = ['Heave', 'Roll', 'Pitch']\n",
    "    y_labels = ['Heave [m**2/Hz]', 'Roll [rad**2/Hz]', 'Pitch [rad**2/Hz]']\n",
    "\n",
    "    label_strings = [\n",
    "    [fr'$\\varepsilon_{{zz}} = {df_error_calculated_curr[\"Heave\"]:.3f}$', fr'$\\varepsilon_{{zz}} = {df_error_SM_curr[\"Heave\"]:.3f}$', fr'$\\varepsilon_{{zz}} = {df_error_WA_curr[\"Heave\"]:.3f}$'],\n",
    "    [fr'$\\varepsilon_{{\\phi \\phi}} = {df_error_calculated_curr[\"Roll_rad\"]:.3f}$', fr'$\\varepsilon_{{\\phi \\phi}} = {df_error_SM_curr[\"Roll_rad\"]:.3f}$', fr'$\\varepsilon_{{\\phi \\phi}} = {df_error_WA_curr[\"Roll_rad\"]:.3f}$'],\n",
    "    [fr'$\\varepsilon_{{\\theta \\theta}} = {df_error_calculated_curr[\"Pitch_rad\"]:.3f}$', fr'$\\varepsilon_{{\\theta \\theta}} = {df_error_SM_curr[\"Pitch_rad\"]:.3f}$', fr'$\\varepsilon_{{\\theta \\theta}} = {df_error_WA_curr[\"Pitch_rad\"]:.3f}$']\n",
    "    ]\n",
    "\n",
    "    legend_titles = [fr'$S_{{zz}}: Seg. {segment}$', fr'$S_{{\\phi \\phi}}: Seg. {segment}$', fr'$S_{{\\theta \\theta}}: Seg. {segment}$']\n",
    "   \n",
    "    # Data keys for each plot, assuming these are column names in your DataFrames\n",
    "    data_keys = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "    # Iterate over the axes, titles, and data keys to create each subplot\n",
    "    for ax, title, y_label, key, label_list, legend_title in zip(axes, titles, y_labels, data_keys, label_strings, legend_titles):\n",
    "        # Plot measured data\n",
    "\n",
    "        ax.plot(freq_filtered, np.abs(responseSpectrum_measured_filtered[key]), \n",
    "                label='Measured', color=measured_color, linewidth=linewidth_measured, \n",
    "                markersize=4, marker=measured_marker)\n",
    "\n",
    "        # Plot calculated data\n",
    "        ax.plot(freq_filtered, np.abs(filtered_responseSpectrum_calculated[key]), \n",
    "                label=label_list[0], color=calculated_color,  linestyle='-.', \n",
    "                linewidth=linewidth_calculated)\n",
    "        \n",
    "        ax.plot(freq_filtered, np.abs(filtered_responseSpectrum_calculated_SM[key]), label=label_list[1], color=SM_color, linestyle='--', \n",
    "                linewidth=1.0)\n",
    "        \n",
    "        ax.plot(freq_filtered, np.abs(filtered_responseSpectrum_calculated_WA[key]), label=label_list[2], color=WA_color, linestyle='-', \n",
    "                linewidth=1.0)\n",
    "\n",
    "        # Set titles and labels\n",
    "        ax.set_title(title, fontsize=16)\n",
    "        ax.set_xlabel(\"Encounter frequency [Hz]\", fontsize=14)\n",
    "        ax.set_ylabel(y_label, fontsize=14)\n",
    "        # Add legend\n",
    "        legend = ax.legend(fancybox=True, fontsize=12, title_fontsize=14, loc = \"upper right\", framealpha=0.5) # frame alpha controls transparency\n",
    "        legend.set_title(legend_title)\n",
    "\n",
    "        ax.tick_params(axis='both', which='major', labelsize=12)  # Adjust tick parameters for readability\n",
    "\n",
    "        ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        ax.lines[0].set_linewidth(3)\n",
    "\n",
    "    if (save):\n",
    "        folder_path = 'Plots/Results'\n",
    "        saveSVG(title_file, folder_path)\n",
    "\n",
    "    # Adjust layout for a cleaner look\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "    \n",
    "def sliceCalculatedResponseSpectrum_same_segment(responseSpectrum_calculated, iteration, mask_freq, segment):\n",
    "      # is only a single df. Sort by column segment so that it matches current segment\n",
    "    mask_segment = responseSpectrum_calculated['segment'] == segment\n",
    "    filtered_responseSpectrum_calculated = responseSpectrum_calculated[mask_segment] \n",
    "    filtered_responseSpectrum_calculated =  filtered_responseSpectrum_calculated.loc[mask_freq]         # apply mask for only containing frequencies up to 0.3 hz \n",
    "    filtered_responseSpectrum_calculated = filtered_responseSpectrum_calculated.reset_index(drop=True)  # reset the index so that it matches the measured response spectrum.\n",
    "\n",
    "    return filtered_responseSpectrum_calculated\n",
    "\n",
    "\n",
    "def plotResponseSpectrumResult_same_segment(segment, f0, responseSpectrum_measured_curr_seg_abs, responseSpectrum_calculated, title_file, save = False):\n",
    "    # only select the last iteration as it gives the best result\n",
    "    # Step 1: Trim responseSpectrum_calculated to match the length of responseSpectrum_measured\n",
    "    n_rows = responseSpectrum_measured_curr_seg_abs.shape[0]\n",
    "\n",
    "\n",
    "    responseSpectrum_calculated = responseSpectrum_calculated.tail(n_rows)\n",
    "\n",
    "    # Step 2: Create a mask for frequency values less than 0.3\n",
    "    mask_freq = f0 < 0.3\n",
    "\n",
    "    # Apply the mask to frequency array to create a filtered frequency array (optional, if needed)\n",
    "    freq_filtered = f0[mask_freq]\n",
    " \n",
    "    # Apply the mask to both DataFrames\n",
    "    responseSpectrum_measured_filtered = responseSpectrum_measured_curr_seg_abs[mask_freq].reset_index(drop=True)\n",
    "    responseSpectrum_calculated_filtered = responseSpectrum_calculated[mask_freq].reset_index(drop=True)\n",
    "\n",
    "    title_fig = f'Response estimation results after optimizing parameters on segment: {segment}'       \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(18, 10))  # Adjusted width\n",
    "    fig.suptitle(title_fig, fontsize=16)\n",
    "\n",
    "    #df_motions[\"Roll\"].plot(ax=axes[0,0], legend=True, grid=True, title=\"Roll\")\n",
    "    linewidth_measured = 2\n",
    "    linewidth_calculated = 1.5\n",
    "    measured_color = 'g'      # green\n",
    "    calculated_color = 'b'    # Blue\n",
    "    error_color = 'r'         # A bright red for error\n",
    "    measured_marker = 's'     # Square marker\n",
    "\n",
    "    # Titles for each subplot\n",
    "    titles = ['Heave', 'Roll', 'Pitch']\n",
    "    y_labels = ['Heave [m**2/Hz]', 'Roll [rad**2/Hz]', 'Pitch [rad**2/Hz]']\n",
    "\n",
    "    # Data keys for each plot, assuming these are column names in your DataFrames\n",
    "    data_keys = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "    # Iterate over the axes, titles, and data keys to create each subplot\n",
    "    for ax, title, y_label, key in zip(axes, titles, y_labels, data_keys):\n",
    "        # Plot measured data\n",
    "        ax.plot(freq_filtered, np.abs(responseSpectrum_measured_filtered[key]), \n",
    "                label='Measured', color=measured_color, linewidth=linewidth_measured, \n",
    "                markersize=4, marker=measured_marker)\n",
    "\n",
    "        # Plot calculated data\n",
    "        ax.plot(freq_filtered, np.abs(responseSpectrum_calculated_filtered[key]), \n",
    "                label='Calculated', color=calculated_color, linestyle='-', \n",
    "                linewidth=linewidth_calculated)\n",
    "\n",
    "        # Set titles and labels\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Absolute Frequency [Hz]\")\n",
    "        ax.set_ylabel(y_label)\n",
    "\n",
    "        # Add legend\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    if (save):\n",
    "        folder_path = 'Plots/Results'\n",
    "        saveSVG(title_file, folder_path)\n",
    "\n",
    "    # Adjust layout for a cleaner look\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "       \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for RAOs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the result from df_results_alpha to find the best performing alpha. Use the alpha in the CFE to calculate the transfer functions.\n",
    "\n",
    "def segmentData_TRF(om0_rad, segment, df_speed_segments_avg):\n",
    "    #yaw = df_pos_segments_avg[segment]['hdt']\n",
    "    U = df_speed_segments_avg[segment]['Speed']\n",
    "    Nabla = None   # Volume Deplacement\n",
    "\n",
    "    return om0_rad, U, Nabla\n",
    "\n",
    "def calculateTRF(alpha, segment_data_TRF, beta_plot):\n",
    "    df_TRF_list = []\n",
    "\n",
    "    om0_rad, U, Nabla = segment_data_TRF\n",
    "\n",
    "    C_B_1 = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "    C_B_2 = Nabla / (alpha[4] * alpha[5] * alpha[6])\n",
    "\n",
    "    responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "    for response in responses:\n",
    "        # Calculate the CFEs\n",
    "        if response == \"Heave\":\n",
    "            # transfer function for Heave is in units [m/m]\n",
    "            TRF_2d = heaveCF(om0_rad,beta_plot,U,alpha[0],alpha[1],alpha[2],C_B_1) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "            TRF_2d = TRF_2d * alpha[3] # multiply by the gain\n",
    "            \n",
    "        if response == \"Pitch_rad\":\n",
    "            # transfer function for Pitch is in units [rad/m]\n",
    "            TRF_2d = pitchCF(om0_rad,beta_plot,U,alpha[4],alpha[5],alpha[6],C_B_2) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "        if response == \"Roll_rad\":\n",
    "            kappa = alpha[7] - alpha[9]\n",
    "            TRF_2d = rollCF(om0_rad,beta_plot,U,alpha[4],alpha[5],alpha[6],C_B_2,alpha[7],alpha[8],kappa,alpha[10],T_N=0)\n",
    "\n",
    "        df_TRF_list.append(TRF_2d)\n",
    "\n",
    "    return df_TRF_list\n",
    "\n",
    "def calculateTRFDeg(alpha, segment_data_TRF, beta_plot):\n",
    "    df_TRF_list = []\n",
    "\n",
    "    om0_rad, U, Nabla = segment_data_TRF\n",
    "\n",
    "    C_B = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "\n",
    "    responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "    for response in responses:\n",
    "         # Calculate the CFEs\n",
    "         # the resulting TRF is a numpy array of size (len(om0_rad), len(beta_TRF))\n",
    "        if response == \"Heave\":\n",
    "            # transfer function for Heave is in units [m/m]\n",
    "            TRF_2d = heaveCF(om0_rad,beta_plot,U,alpha[0],alpha[1],alpha[2],C_B) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "        if response == \"Pitch_rad\":\n",
    "            # transfer function for Pitch is in units [rad/m]\n",
    "            TRF_2d = pitchCFDeg(om0_rad,beta_plot,U,alpha[0],alpha[1],alpha[2],C_B) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "        if response == \"Roll_rad\":\n",
    "            kappa = alpha[3] - alpha[5]\n",
    "            \n",
    "            TRF_2d = rollCFDeg(om0_rad,beta_plot,U,alpha[0],alpha[1],alpha[2],C_B,alpha[3],alpha[4],kappa,alpha[6],T_N=0)\n",
    "            \n",
    "        df_TRF_list.append(TRF_2d)\n",
    "\n",
    "    return df_TRF_list\n",
    "\n",
    "def plotIsolatedTransferFunctionsWithSubplots(TRF_init, TRF_best, om0_rad, beta_plot, responses,title_file, save=False):\n",
    "    # Ensure beta_plot is a numpy array and contains the desired beta values\n",
    "    beta_degrees = [60, 120, 180]  # Define the specific beta degree values to plot\n",
    "    beta_indices = [np.where(beta_plot == bd)[0][0] for bd in beta_degrees]  # Get indices for these values in beta_plot\n",
    "\n",
    "    for idx, response in enumerate(responses):\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 6))  # Create a figure with three subplots\n",
    "        fig.suptitle(f'{response} Transfer Function Results', fontsize=20)\n",
    "\n",
    "        # Iterate through the desired beta indices and plot the initial and best TRF\n",
    "        for ax, beta_idx in zip(axes, beta_indices):\n",
    "            beta_degree = beta_plot[beta_idx]\n",
    "            label_init = f'Initial'\n",
    "            label_best = f'Optimized'\n",
    "            ax.plot(om0_rad, np.abs(TRF_init[idx][:, beta_idx]), label=label_init, linestyle = '--', linewidth=2)\n",
    "            ax.plot(om0_rad, np.abs(TRF_best[idx][:, beta_idx]), label=label_best, linestyle='-', linewidth=2)\n",
    "\n",
    "            # Set titles, labels, and grid for each subplot\n",
    "            ax.set_title(f'Beta = {beta_degree}Â°', fontsize = 14)\n",
    "            ax.set_xlabel('Frequency [rad/s]', fontsize=11)\n",
    "            y_label = f'{response} [{\"m/\" if response == \"Heave\" else \"rad/\"}m]'\n",
    "            ax.set_ylabel(y_label,fontsize=11)\n",
    "\n",
    "            # Customize the legend\n",
    "            legend_title = 'Initial CFE | Optimized CFE'  # You can customize this title\n",
    "\n",
    "                        # Adjust the legend properties to make it smaller\n",
    "            legend = ax.legend(\n",
    "                fancybox=True, \n",
    "                fontsize=10, \n",
    "                title_fontsize=12, \n",
    "                loc=\"upper right\", \n",
    "                framealpha=0.5, \n",
    "                borderpad=0.5,  # Smaller border padding\n",
    "                labelspacing=0.5,  # Smaller label spacing\n",
    "                handlelength=2  # Shorter handles\n",
    "            )\n",
    "            legend.set_title(legend_title)\n",
    "            legend.get_frame().set_edgecolor('black')  # Set the legend frame edge color\n",
    "            plt.setp(legend.get_texts(), fontsize='10')  # Adjust font size of legend text\n",
    "            \"\"\"\n",
    "            # Add legend\n",
    "            legend = ax.legend(fancybox=True, fontsize=12, title_fontsize=14, loc = \"upper right\", framealpha=0.5) # frame alpha controls transparency\n",
    "            legend.set_title(legend_title)\n",
    "            legend.get_frame().set_edgecolor('black')  # Set the legend frame edge color\n",
    "            #legend.get_title().set_fontweight('bold')  # Set the title to bold\n",
    "            \"\"\"\n",
    "            #ax.tick_params(axis='both', which='major', labelsize=12)  # Adjust tick parameters for readability\n",
    "\n",
    "            ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "            #ax.lines[0].set_linewidth(3)\n",
    "            \n",
    "\n",
    "        # Adjust layout and show/save the plot\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust the top margin to not overlap with suptitle\n",
    "        if (save):\n",
    "            folder_path = 'Plots/TransferFunctionResults'\n",
    "            saveSVG(title_file, folder_path)\n",
    "        plt.show()\n",
    "\n",
    "def plotTransferFunction(df_results_alpha_current, alpha_init, df_speed_segments_avg, segment, om0_rad, title_file, save = False):\n",
    "\n",
    "    # want to make a plotting of transfer functions for comparing CFE transfer functions before and after optimizing\n",
    "    # should currently just work for the same segment. \n",
    "    # Therefore \n",
    "\n",
    "    segment_data_TRF = segmentData_TRF(om0_rad, segment, df_speed_segments_avg)\n",
    "\n",
    "    best_alpha = df_results_alpha_current.tail(1)\n",
    "    best_alpha = best_alpha.to_numpy()\n",
    "\n",
    "    print(f\"this is best_alpha: {best_alpha}\")\n",
    "    error = best_alpha[-1, -1]\n",
    "    print(f\"this is the error: {error}\")\n",
    "    best_alpha = best_alpha[0, :-1].flatten()\n",
    "    print(f\"this is best_alpha as a 1d array: {best_alpha}\")\n",
    "\n",
    "    beta_plot = np.arange(0, 181, 30)\n",
    "\n",
    "    TRF_init = calculateTRF(alpha_init, segment_data_TRF, beta_plot)\n",
    "    TRF_best = calculateTRF(best_alpha, segment_data_TRF, beta_plot)\n",
    "    responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "    plotIsolatedTransferFunctionsWithSubplots(TRF_init, TRF_best, om0_rad, beta_plot, responses,title_file, save=save)\n",
    "    \n",
    "    return\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def c(theta):\n",
    "    return np.cos(theta)\n",
    "\n",
    "def s(theta):\n",
    "    return np.sin(theta)\n",
    "\n",
    "# Euler angles for rotation from body to NED frame\n",
    "\n",
    "# roll - phi, pitch - theta, yaw - psi\n",
    "def rotationBN(pitch, roll, yaw):\n",
    "    Rx = np.matrix([\n",
    "        [1,0,0],\n",
    "        [0, c(roll), -s(roll)],\n",
    "        [0, s(roll), c(roll)]\n",
    "    ])\n",
    "    Ry = np.matrix([\n",
    "        [c(pitch),0,s(pitch)],\n",
    "        [0, 1, 0],\n",
    "        [-s(pitch), 0, c(pitch)]\n",
    "    ])\n",
    "    Rz = np.matrix([\n",
    "        [c(yaw),-s(yaw),0],\n",
    "        [s(yaw), c(yaw), 0],\n",
    "        [0, 0, 1]\n",
    "    ])\n",
    "\n",
    "    R = Rx*Ry*Rz\n",
    "    return R\n",
    "\n",
    "def print_basic_info(mu):\n",
    "    print(\"Type of mu:\", type(mu))\n",
    "    print(\"Length of mu:\", len(mu))\n",
    "    print(\"First few elements:\", mu[:5])\n",
    "    print(\"Last few elements:\", mu[-5:])\n",
    "\n",
    "def distance(point1, point2):\n",
    "# Calculate the distance between the points\n",
    "    distance = geodesic(point1, point2).kilometers\n",
    "    print(f\"The distance between ({str(point1)}, {str(point2)}) is : {distance} kilometers.\")\n",
    "    return distance  # or .miles for distance in miles\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for ensuring stationary data segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stationaryDFHeading(df_pos_segments):\n",
    "    # Function to calculate the normalized heading difference accounting for wrap-around\n",
    "    def normalized_heading_diff(h1, h2):\n",
    "        return min(abs(h1 - h2), 360 - abs(h1 - h2))\n",
    "\n",
    "    # List to hold stationary dataframes\n",
    "    stationary_segments = []\n",
    "\n",
    "    non_stationary_segments_idx =[]\n",
    "\n",
    "    segment = 0\n",
    "    # Iterate through each segment\n",
    "    for df in df_pos_segments:\n",
    "        if 'hdt' in df.columns:\n",
    "            # Calculate differences between all pairs of headings in the segment\n",
    "            max_diff = 0\n",
    "            for i in range(len(df['hdt'])):\n",
    "                for j in range(i + 1, len(df['hdt'])):\n",
    "                    diff = normalized_heading_diff(df['hdt'].iloc[i], df['hdt'].iloc[j])\n",
    "                    if diff > max_diff:\n",
    "                        max_diff = diff\n",
    "\n",
    "            # Check if the maximum difference exceeds 10 degrees\n",
    "            if max_diff > 10:\n",
    "                # Assuming there's a time column called 'time' to identify the start time of the segment\n",
    "                print(f\"Segment nr: {segment} starting at {df['Timestamp'].iloc[0]} is non-stationary and will be removed.\")\n",
    "                non_stationary_segments_idx.append(segment)\n",
    "            else:\n",
    "                df = df.reset_index(drop=True)\n",
    "                stationary_segments.append(df)\n",
    "                # want to reset the index for each df anywars\n",
    "        else:\n",
    "            print(\"The dataframe does not contain a 'hdt' column.\")\n",
    "        \n",
    "        segment += 1\n",
    "\n",
    "    return stationary_segments, non_stationary_segments_idx\n",
    "\n",
    "# function for checking if there are any negative values of speed in the segments. There are none.\n",
    "def check_negative_speed(df_speed_segments):\n",
    "    for segment, df in enumerate(df_speed_segments):\n",
    "        if 'Speed' in df.columns:\n",
    "            if (df['Speed'] < 0).any():\n",
    "                print(f\"Segment nr: {segment} contains negative speeds.\")\n",
    "            else:\n",
    "                print(f\"Segment nr: {segment} does not contain negative speeds.\")\n",
    "        else:\n",
    "            print(\"The dataframe does not contain a 'Speed' column.\")\n",
    "\n",
    "#check_negative_speed(df_speed_segments)\n",
    "\n",
    "# Checked: speed does not exceed 1 m/s\n",
    "# function for ensuring speed in segments does not exceed 1 m/s. \n",
    "def stationaryDFSpeed(df_speed_segments):\n",
    "    # List to hold stationary dataframes\n",
    "    stationary_segments = []\n",
    "    \n",
    "    segment = 0\n",
    "    # Iterate through each segment\n",
    "    for df in df_speed_segments:\n",
    "        start_time = time.time()\n",
    "        print(f\"Currently in segment nr: {segment}\")\n",
    "        #print(f\"This is the number of rows in this segment: {len(df)}\")\n",
    "        \n",
    "        if 'Speed' in df.columns:\n",
    "            # Sample speeds every tenth row\n",
    "            sampled_indices = range(0, len(df['Speed']), 10)\n",
    "            speeds_sampled = df['Speed'].iloc[sampled_indices]\n",
    "\n",
    "            # Check if any sampled speed exceeds the threshold of 1 m/s\n",
    "            if all(speed <= 1 for speed in speeds_sampled):\n",
    "                # Reset the index for each dataframe that is appended to the list\n",
    "                df = df.reset_index(drop=True)\n",
    "                stationary_segments.append(df)\n",
    "            else:\n",
    "                print(f\"Segment nr: {segment} starting at {df['Timestamp'].iloc[0]} has speeds exceeding 1 m/s and will be removed.\")\n",
    "        else:\n",
    "            print(\"The dataframe does not contain a 'Speed' column.\")\n",
    "        \n",
    "        segment += 1  # Increment segment counter\n",
    "        end_time = time.time()\n",
    "        #print(f\"Execution time for a segment: {(end_time - start_time)/60} minutes\")\n",
    "\n",
    "    return stationary_segments\n",
    "\n",
    "def remove_indices_from_list(df_motions_segments, non_stationary_segments_idx):\n",
    "    # Sort the indices in reverse order to ensure correct removal\n",
    "    non_stationary_segments_idx.sort(reverse=True)\n",
    "    \n",
    "    # Remove elements from the list using the indices\n",
    "    for idx in non_stationary_segments_idx:\n",
    "        if 0 <= idx < len(df_motions_segments):\n",
    "            del df_motions_segments[idx]\n",
    "    \n",
    "    return df_motions_segments\n",
    "\n",
    "def remove_indices_from_dict(df_ws_segments, non_stationary_segments_idx):\n",
    "    # Convert the dictionary to a list of key-value pairs\n",
    "    items = list(df_ws_segments.items())\n",
    "\n",
    "    # Iterate over the list of indices\n",
    "    for index in non_stationary_segments_idx:\n",
    "        # Check if the index is within the range of the list of items\n",
    "        if 0 <= index < len(items):\n",
    "            # Remove the item with the corresponding index\n",
    "            del items[index]\n",
    "\n",
    "    # Convert the modified list back to a dictionary\n",
    "    df_ws_segments = dict(items)\n",
    "\n",
    "    return df_ws_segments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions for averaging parameters for CFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculateResponseSpectrum(alpha, ws, segment):\n",
    "\n",
    "    responseSpectrum_calculated_tmp = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "    responseSpectrum_calculated_tmp[response] = calculated_spectrum_values_tmp\n",
    "    Nabla = None\n",
    "\n",
    "    C_B = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "\n",
    "    responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "    for response in responses:\n",
    "\n",
    "        if response == \"Heave\":\n",
    "                # transfer function for Heave is in units [m/m]\n",
    "            TRF1 = heaveCF(om0_rad,beta_TRF,U,alpha[0],alpha[1],alpha[2],C_B) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "        if response == \"Pitch_rad\":\n",
    "            # transfer function for Pitch is in units [rad/m]\n",
    "            TRF1 = pitchCF(om0_rad,beta_TRF,U,alpha[0],alpha[1],alpha[2],C_B) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "        if response == \"Roll_rad\":\n",
    "            kappa = alpha[3] - alpha[5]\n",
    "            #mu = alpha[6]\n",
    "            #B0 = alpha[1] # assigned B0 = B. Not sure if this is right.\n",
    "            # transfer function for Roll is in units [rad/m]\n",
    "            TRF1 = rollCF(om0_rad,beta_TRF,U,alpha[0],alpha[1],alpha[2],C_B,alpha[3],alpha[4],kappa,alpha[6],T_N=0)\n",
    "\n",
    "        # Copy TRF2 as TRF1 to get a Power Spectral Density and not a Cross Spectral Density\n",
    "        TRF2 = TRF1\n",
    "\n",
    "        calculated_spectrum_values_tmp = resp_spec_2d(f0, mu, ws, beta_TRF, TRF1, TRF2, fe, U, yaw, conv='to')\n",
    "\n",
    "        responseSpectrum_calculated_tmp[response] = calculated_spectrum_values_tmp\n",
    "    \n",
    "    # fill in\n",
    "    responseSpectrum_calculated_tmp['segment'] = segment\n",
    "        \n",
    "    return responseSpectrum_calculated_tmp \n",
    "\n",
    "def simpleMean(alpha_final):\n",
    "   return alpha_final.mean()\n",
    "\n",
    "def weightedAvg(alpha_final):\n",
    "   fmax = alpha_final['Error'].max()\n",
    "\n",
    "   param_sum_numerator = pd.Series([0] * (len(alpha_final.columns) - 1), index=alpha_final.columns[:-1])\n",
    "   param_sum_denominator = 0\n",
    "\n",
    "   for idx, row in alpha_final.iterrows():\n",
    "      if row['Error'] < fmax:\n",
    "         weight_i = fmax - row['Error']\n",
    "      else:\n",
    "         weight_i = 0\n",
    "      \n",
    "      #alpha['Weight'] = weight_i\n",
    "      # update the sums for weighted avg calc\n",
    "      param_sum_numerator += weight_i * row[:-1] # to slice off the last column: error\n",
    "      param_sum_denominator += weight_i\n",
    "   \n",
    "   # Calculate weighted average if denominator is not zero\n",
    "   if param_sum_denominator != 0:\n",
    "      alpha_WA = param_sum_numerator / param_sum_denominator\n",
    "   else:\n",
    "      alpha_WA = pd.Series([None] * len(alpha_final.columns[:-1]), index=alpha_final.columns[:-1])\n",
    "\n",
    "   return alpha_WA\n",
    "\n",
    "\n",
    "# Calculates the error between the measured and calculated response spectra using the 1d list of alpha\n",
    "def calculateErrorBetweenSpectra(df_alpha, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, responseSpectrum_measured, nr_seg_compile, alpha1D = True):\n",
    "    df_error = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "    if alpha1D == True:\n",
    "        alpha = df_alpha.tolist()\n",
    "\n",
    "    for segment in range(nr_seg_compile):\n",
    "\n",
    "        # if alpha is a df with several rows, such as df_results_alpha_current\n",
    "        \n",
    "        if alpha1D == False:\n",
    "            \n",
    "            #print(f\"in if loop. type of alpha: {type(alpha)}\")\n",
    "            alpha = df_alpha.iloc[segment].tolist()\n",
    "\n",
    "        error_list = []\n",
    "        m0 = 0\n",
    "        timestamp, ws = list(df_ws_segments.items())[segment]\n",
    "        yaw = df_pos_segments_avg[segment]['hdt']  # 1 value per segment. Heading [deg]\n",
    "        U = df_speed_segments_avg[segment]['Speed']  # Speed Over Ground [m/s]\n",
    "        beta_TRF = mu_deg - yaw # Might have to use re_range() here to avoid negative angles\n",
    "        beta_TRF = re_range(beta_TRF) # ensure that beta_TRF is within the range of [0, 360]\n",
    "\n",
    "        responseSpectrum_calculated_tmp = calculateResponseSpectrum(alpha, ws, segment)\n",
    "\n",
    "        responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "        for response in responses:\n",
    "            m0 =  trapezoid(responseSpectrum_measured[segment][response],fe) # variance\n",
    "\n",
    "            measured_spectrum = responseSpectrum_measured[segment][response].values\n",
    "            calculated_spectrum = responseSpectrum_calculated_tmp[response]\n",
    "\n",
    "            expression = measured_spectrum - calculated_spectrum\n",
    "            error = trapezoid(np.abs(expression), fe) / m0\n",
    "                \n",
    "            # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "            error_list.append(error)\n",
    "\n",
    "        df_error_tmp = pd.DataFrame([error_list], columns=df_error.columns)\n",
    "        df_error = pd.concat([df_error, df_error_tmp], ignore_index=True)\n",
    "\n",
    "    # after iterating through all segments\n",
    "    return df_error\n",
    "\n",
    "def calculateResponseSpectrum_entire_run(alpha, df_ws_segments, nr_seg_compile):\n",
    "    responseSpectrum_calculated = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "    alpha = alpha.tolist()\n",
    "    for segment in range(nr_seg_compile):\n",
    "        timestamp, ws = list(df_ws_segments.items())[segment]\n",
    "        responseSpectrum_calculated_tmp = calculateResponseSpectrum(alpha, ws, segment)\n",
    "\n",
    "         # for first iteration: Create df\n",
    "        if segment == 0:\n",
    "            responseSpectrum_calculated = responseSpectrum_calculated_tmp\n",
    "\n",
    "        # else: update existing df\n",
    "        else:\n",
    "            responseSpectrum_calculated = pd.concat([responseSpectrum_calculated, responseSpectrum_calculated_tmp], ignore_index=True)\n",
    "    \n",
    "    return responseSpectrum_calculated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_motions, df_pos, df_acc, df_speed = getVesselData()\n",
    "\n",
    "df_motions['Pitch_rad'] = np.radians(df_motions['Pitch'])\n",
    "df_motions['Roll_rad'] = np.radians(df_motions['Roll'])\n",
    "\n",
    "csv_files = None#\n",
    "\n",
    "df_ws = getWaveSpectra(csv_files)\n",
    "\n",
    "\n",
    "\n",
    "#print(\"this is the type of df_ws: {df_ws.dtype}\")\n",
    "\n",
    "#print(df_ws.dtypes)\n",
    "\n",
    "om0 = df_ws['freq']\n",
    "\n",
    "# ensure that mu and yaw have corresponding time ranges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preparing and sorting RAO data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRF_2d_data, f0_RAO, beta_deg_RAO = getRAOs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Filters\n",
    "\n",
    "### Low-pass filter\n",
    " Cut off frequency at 1 hz as the majority of the energy is way below this. \n",
    "\n",
    " Max freq from ws is 0.54 Hz and most of the energy from response spectra is below 0.3 Hz.\n",
    "\n",
    " However, the response and transfer functions can be shifted to higher frequencies \n",
    "\n",
    " at forward speeds > 0 for head and following seas. Therefore it can be smart to set \n",
    " \n",
    " the cut off frequency with a margin at 1 hz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_lowpass_filter(data, cutoff, fs, order):\n",
    "    nyq = fs/2 # nyquist frequency\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "    y = filtfilt(b, a, data)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High- Pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should apply a high-pass filter to remove any physical effetcs caused by winds.\n",
    "# By inspecting the reponse spectra this can be seen for roll below 0.025\n",
    "\n",
    "def butter_highpass_filter(data, cutoff, fs, order):\n",
    "    nyq = fs/2 # nyquist frequency\n",
    "    normal_cutoff = cutoff / nyq\n",
    "    # the correct syntax of btype might be highpass\n",
    "    b, a = butter(order, normal_cutoff, btype='high', analog=False) # order controls the steepness of the filter's slope at the cut off frequency\n",
    "    y = filtfilt(b, a, data)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter Motion data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_low = 1 # [Hz]\n",
    "cutoff_high = 0.025 # [Hz]\n",
    "order = 10\n",
    "sr_motions = SampleRateDF(df_motions)\n",
    "print(f\"this is the sample rate for df_motions: {sr_motions}\")\n",
    "\n",
    "# ensure that they are not referenced to the same object. Changes to df_motions_filtered wont effect the original df\n",
    "df_motions_filtered = df_motions.copy(deep=True)\n",
    "\n",
    "for column in df_motions_filtered.columns:\n",
    "        \n",
    "        if column != \"Time\" and column != \"Timestamp\":\n",
    "                   \n",
    "            df_motions_filtered[column] =  butter_highpass_filter(df_motions_filtered[column], cutoff_high, sr_motions, order)\n",
    "\n",
    "            df_motions_filtered[column] =  butter_lowpass_filter(df_motions_filtered[column], cutoff_low, sr_motions, order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Response Spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works only with one dataframe at a time\n",
    "def responseSpectrum(df_motions, nperseg):\n",
    "    # \n",
    "    ## Perform the Fast Fourier Transform (FFT). From: https://pythonnumericalmethods.berkeley.edu/notebooks/chapter24.04-FFT-in-Python.html\n",
    "    # think i noticed a mistake where the response_s\n",
    "    columns_motions =  ['Heave', 'Heave_velocity', 'Pitch', 'Pitch_rad', 'Roll', 'Roll_rad']\n",
    "    df_motions_spectra = pd.DataFrame(columns = columns_motions)\n",
    "\n",
    "    #columns_list = list(df_motions.columns)\n",
    "    sampling_rate = SampleRateDF(df_motions)\n",
    "    \n",
    "    for column in df_motions.columns:\n",
    "        \n",
    "        if column != \"Time\" and column != \"Timestamp\":\n",
    "                   \n",
    "            motion_data = df_motions[column].values\n",
    "            index_onesided = (nperseg // 2) + 1\n",
    "            df_motions_spectra = df_motions_spectra.iloc[:index_onesided]\n",
    "            # return twosided so that the size of the output dataframe is the same as the input dataframe\n",
    "            freqs, psd = signal.welch(motion_data, fs=sampling_rate, window='hann',nperseg=nperseg, noverlap = nperseg // 2, scaling='density')\n",
    "\n",
    "            df_motions_spectra[column] = psd\n",
    "\n",
    "    # set the index of the df to be the encounter frequency\n",
    "    df_motions_spectra['freq'] = freqs\n",
    "    #df_motions_spectra = df_motions_spectra.set_index('freq')\n",
    "    return freqs, df_motions_spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns encounter frequency and list of response spectra\n",
    "def getListResponseSpectrum(df_motions, nperseg, plot = False, save = False):\n",
    "\n",
    "    listResponseSpectrum = []\n",
    "\n",
    "    # frequencies should be the same no matter the motion segment.\n",
    "    # Encounte freqs should only depend on sampling rate and nperseg\n",
    "    fe = None\n",
    "\n",
    "    counter = 0\n",
    "    for motion_segment in df_motions:\n",
    "        freq, df_responseSpectrum = responseSpectrum(motion_segment, nperseg)\n",
    "        listResponseSpectrum.append(df_responseSpectrum)\n",
    "\n",
    "        if counter == 0:\n",
    "            fe = freq\n",
    "            responseSpectrum_first = listResponseSpectrum[0]\n",
    "            if plot:\n",
    "\n",
    "                plotResponseSpectrum(fe, responseSpectrum_first, title = f'ResponseSpectrum_segment_0', save = save)\n",
    "\n",
    "        counter += 1\n",
    "    return fe, listResponseSpectrum\n",
    "\n",
    "nperseg = 2048\n",
    "\n",
    "fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg, plot = True, save = False)\n",
    "\n",
    "fe_unfiltered, responseSpectrum_measured_unfiltered = getListResponseSpectrum(df_motions_segments_unfiltered, nperseg, plot = True, save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation of measured response spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_motions_first = df_motions_segments[0]\n",
    "\n",
    "variance_heave_time_series = df_motions_first['Heave'].var()\n",
    "#print(\"Variance in Heave:\", variance_heave_time_series)\n",
    "\n",
    "# calculate the 0th spectral moment of the response spectrum of segment 0 \n",
    "responseSpectrum_measured_first = responseSpectrum_measured[0]\n",
    "m0 = trapezoid(responseSpectrum_measured_first['Heave'],fe) # variance\n",
    "\n",
    "\n",
    "difference = np.abs(variance_heave_time_series - m0)\n",
    "\n",
    "fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg, plot = False, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def saveSVGRoll(title, folder_path):\n",
    "    \"\"\"\n",
    "    Saves the plot as an SVG in a specified folder under the current directory.\n",
    "    Automatically appends the current date to organize the files.\n",
    "\n",
    "    :param title: Title and base name for the file to be saved.\n",
    "    :param folder_path: Relative path from the current directory where the file should be saved.\n",
    "                        \n",
    "    \"\"\"\n",
    "    # Generate a unique filename using the current date and time\n",
    "    current_time = datetime.now().strftime(\"%H%M\")\n",
    "    filename = f\"{current_time}_\"\n",
    "\n",
    "    # Generate today's date string in the format YYYY-MM-DD\n",
    "    date_string = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Create the new directory path by appending the date string\n",
    "    date_folder_path = os.path.join(folder_path, date_string)\n",
    "\n",
    "    # Check if the directory exists, if not, create it\n",
    "    if not os.path.exists(date_folder_path):\n",
    "        os.makedirs(date_folder_path)\n",
    "    \n",
    "    # Append hour and minute to the folder path\n",
    "    hour_minute_folder_path = os.path.join(date_folder_path, current_time)\n",
    "\n",
    "    # Check if the hour-minute directory exists, if not, create it\n",
    "    if not os.path.exists(hour_minute_folder_path):\n",
    "        os.makedirs(hour_minute_folder_path)\n",
    "\n",
    "    title = filename + title\n",
    "\n",
    "    # Define the file path including the name of the SVG file you want to save\n",
    "    file_path = os.path.join(hour_minute_folder_path, title + '.svg')\n",
    "\n",
    "    # Save the plot as an SVG file in the specified directory\n",
    "    plt.savefig(file_path)\n",
    "    print(f\"Plot saved as {file_path}\")\n",
    "\n",
    "def plotResponseSpectrumRoll(freq, df, title, save=False):\n",
    "  # Filter frequencies to only include those less than 0.3 Hz\n",
    "  freq = freq[freq < 0.3]\n",
    "  indices = len(freq)\n",
    "  df = df.iloc[:indices]\n",
    "\n",
    "  # Initialize a single plot\n",
    "  fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "  # Plotting \"Roll\" spectrum\n",
    "  ax.plot(freq, np.abs(df['Roll_rad']), label='Roll', color='b')\n",
    "  ax.set_xlabel(\"Frequency [Hz]\")\n",
    "  ax.set_ylabel(\"Roll [Rad**2/Hz]\")\n",
    "  ax.set_title('Roll Response Spectrum')\n",
    "  ax.grid(True)\n",
    "\n",
    "  # Set the overall figure title\n",
    "  #fig.suptitle(title, fontsize=16)\n",
    "\n",
    "  # Option to save the plot as SVG\n",
    "  if save:\n",
    "      folder_path = 'Plots/ResponseSpectra/Roll'\n",
    "      saveSVGRoll(title, folder_path)  # Ensure saveSVG is a defined function or replace this with actual saving code\n",
    "\n",
    "  # Show the plot\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nperseg = 2048\n",
    "df_motions_first = df_motions_segments_unfiltered[0]\n",
    "freq, df_responseSpectrum = responseSpectrum(df_motions_first, nperseg)\n",
    "\n",
    "\n",
    "plotResponseSpectrumRoll(freq, df_responseSpectrum, title = f'ResponseSpectrum_segment_unfiltered', save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nperseg = 2048\n",
    "df_motions_first = df_motions_segments[0]\n",
    "freq, df_responseSpectrum = responseSpectrum(df_motions_first, nperseg)\n",
    "\n",
    "\n",
    "plotResponseSpectrumRoll(freq, df_responseSpectrum, title = f'ResponseSpectrum_segment_filtered', save = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "\n",
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for df in df_motions_segments:\n",
    "df_motions_first = df_motions_segments[0]\n",
    "df_motions_last = df_motions_segments[-1]\n",
    "\n",
    "nsegments = len(df_motions_segments)\n",
    "\n",
    "# constants\n",
    "f0 = om0  # [Hz]\n",
    "nf0 = len(f0)\n",
    "om0_rad = f0 * 2* np.pi # [rad/s]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vessel Dimensions.\n",
    "\n",
    "Actual values is not available for public. None is used instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_WP = None # Waterplane area\n",
    "L = None     # Length [m]\n",
    "B = None        # Breadth [m]\n",
    "T = None      # Draught [m]\n",
    "C_WP = A_WP / (L* B)      # Waterplane area coefficient [-]. Guessed value\n",
    "GM_T = None     # Given Metacentric height [m]\n",
    "delta = 0.5     # Hull geometry parameter [-]. Guessed value\n",
    "tau = 0.1       # ratio of viscous roll damping to critical damping [-]. Guessed value\n",
    "d_IMU = 5       # Distance between IMU position and centre of flotation [m]. Guessed value\n",
    "\n",
    "alpha_init = [L, B, T, C_WP, GM_T, delta, tau, d_IMU] # parameters which are to be optimized\n",
    "\n",
    "# Constants\n",
    "Nabla = None   # Volume Deplacement\n",
    "\n",
    "# Starting value for variable according to alpha\n",
    "C_B = Nabla / (alpha_init[0] * alpha_init[1] * alpha_init[2])      # Block coefficient\n",
    "\n",
    "varbound = np.array([\n",
    "[(1/2)*L, (3/2)*L],   # L\n",
    "[(1/2)*B, (3/2)*B],   # B\n",
    "[(1/2)*T, (3/2)*T],   # T\n",
    "[(1/2)*C_WP, (3/2)*C_WP],     # C_WP\n",
    "[0.1, 2*B],   # GM_T\n",
    "[0.1, 0.99],     # delta. if it is 1 a singularity occurs\n",
    "[0.1, 1],     # tau\n",
    "[5, 20]    # d_IMU\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def savePolarPlot(segment, save):\n",
    "    title_file = f'PolarPlot_{segment}'\n",
    "    if (save):\n",
    "            folder_path = 'Plots/WaveSpectrum/PolarPlots'\n",
    "            saveSVG(title_file, folder_path)\n",
    "\n",
    "    # Function to interpolate rows\n",
    "\n",
    "def plotWS1D(f0, freq_intrp, mu_deg, beta_TRF, ws_2d_mu, ws_2d_intrp):\n",
    "\n",
    "    # Custom order for beta_TRF: Start from -4, loop to end, then from start to -5\n",
    "    start_index = -4 % len(beta_TRF)\n",
    "    end_index = -5 % len(beta_TRF)\n",
    "    order_beta = list(range(start_index, len(beta_TRF))) + list(range(0, end_index + 1))\n",
    "\n",
    "    # Regular order for mu_deg\n",
    "    order_mu = range(len(mu_deg))\n",
    "    \n",
    "    # Iterate through the number of directions in mu_deg\n",
    "    for i in range(len(mu_deg)):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "\n",
    "        # Index for mu_deg and beta_TRF (beta_TRF uses the custom order)\n",
    "        idx_mu = i\n",
    "        idx_beta = order_beta[i % len(order_beta)]  # Use modulo to wrap around the custom beta_TRF order\n",
    "\n",
    "        max_freq = f0[-1]\n",
    "\n",
    "        # Plot for original data\n",
    "        #plt.subplot(1, 2, 1)\n",
    "        plt.plot(f0, ws_2d_mu[:, idx_mu], label='Original Data')\n",
    "        plt.title(f'Original Data at {mu_deg[idx_mu]:.2f} degrees')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('Wave Spectrum Energy (m^2/Hz)')\n",
    "        plt.legend()\n",
    "        plt.xlim(0, max_freq)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# this is the correct sorted version\n",
    "def plotContourPlot(mu_deg, beta_TRF, f0, freq_intrp, ws_2d_mu, ws_2d_beta, title_file, save = False):\n",
    "    # Plot original and interpolated data\n",
    "    f0_rad = f0 * 2*np.pi\n",
    "    freq_intrp_rad = freq_intrp *2 * np.pi\n",
    " \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    #plt.subplot(1, 2, 1)\n",
    "    plt.contourf(mu_deg, f0, ws_2d_mu, levels=50, cmap='viridis')\n",
    "    #plt.title('Original Data')\n",
    "    plt.xlabel(r'Direction $[\\degree]$')\n",
    "    plt.ylabel('Encounter Frequency [Hz]')\n",
    "    cbar = plt.colorbar()\n",
    "    cbar.set_label(r'$[m^2 / Hz]$', rotation=270, labelpad=15)  # labelpad is the space between the label and the colorbar\n",
    " \n",
    "    # have to sort the ws_2d_beta relative to the directions\n",
    "   \n",
    "    # Get the indices that would sort beta_TRF\n",
    "    sorted_indices = np.argsort(beta_TRF)\n",
    " \n",
    "    # Use these indices to sort the columns of ws_2d_intrp\n",
    "    sorted_ws_2d_beta = ws_2d_beta[:, sorted_indices]\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if (save):\n",
    "        folder_path = 'Plots/WaveSpectrum/ContourPlots'\n",
    "        saveSVGContour(title_file, folder_path)\n",
    "   \n",
    "    plt.show()\n",
    "\n",
    "def plotPolarPlot(mu_deg, beta_TRF, f0, freq_intrp, ws_2d_mu, ws_2d_beta, savePolar):\n",
    "    \n",
    "    # Assuming f0, mu_deg, beta_TRF, ws_2d_mu, ws_2d_beta are defined and available\n",
    "    mu_rad = np.deg2rad(mu_deg)  # Convert degrees to radians for polar plot\n",
    "    beta_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "    # Append the first angle plus 360 degrees to close the loop visually\n",
    "    mu_rad = np.append(mu_rad, mu_rad[0] + 2*np.pi)\n",
    "    ws_2d_mu_polar = np.hstack((ws_2d_mu, ws_2d_mu[:, [0]]))\n",
    "\n",
    "    ws_2d_beta_polar = np.hstack((ws_2d_beta, ws_2d_beta[:, [0]]))\n",
    "    beta_rad = np.append(beta_rad, beta_rad[0] + 2*np.pi)\n",
    "\n",
    "    # Create meshgrids for polar coordinates\n",
    "    R_mu, Theta_mu = np.meshgrid(f0, mu_rad)  # R is frequency, Theta is direction in radians\n",
    "    R_beta, Theta_beta = np.meshgrid(freq_intrp, beta_rad)\n",
    "\n",
    "    # Create a figure for polar plots\n",
    "    fig = plt.figure(figsize=(14, 12))\n",
    "\n",
    "    # Plot original data using pcolormesh\n",
    "    ax1 = plt.subplot(1, 2, 1, projection='polar')\n",
    "    contour1_f = ax1.contourf(Theta_mu, R_mu, ws_2d_mu_polar.T, levels=50, cmap='viridis')\n",
    "\n",
    "    ax1.set_title('Original Spectrum') \n",
    "    cbar = plt.colorbar(contour1_f, ax=ax1, label=r'$m^2 s/rad$', fraction=0.046, pad=0.04)\n",
    "\n",
    "    ax1.tick_params(axis='y', colors='white')  # 'y' axis for radial ticks   \n",
    "\n",
    "\n",
    "    # Plot interpolated data in polar coordinates\n",
    "    ax2 = plt.subplot(1, 2, 2, projection='polar')\n",
    "    contour2_f = ax2.contourf(Theta_beta, R_beta, ws_2d_beta_polar.T, levels=50, cmap='viridis')\n",
    " \n",
    "\n",
    "    ax2.set_title('Interpolated Spectrum')     \n",
    "\n",
    "    cbar2 = plt.colorbar(contour2_f, ax=ax2, label=r'$m^2 s/rad$', fraction=0.046, pad=0.04)\n",
    "\n",
    "    # Change radial tick label colors to white\n",
    "    ax2.tick_params(axis='y', colors='white')  # 'y' axis for radial ticks\n",
    "\n",
    "    plt.tight_layout()  # Adjust layout to make room for the main title\n",
    "    savePolarPlot(segment, save = savePolar)\n",
    "    \n",
    "    #plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plotResponseSpectrumResult_same_segment_initial_CFE(segment, fe_sliced, responseSpectrum_measured_curr_seg_abs, responseSpectrum_calculated,responseSpectrum_calculated_init, title_file, method, save = False):\n",
    "    # only select the last iteration as it gives the best result\n",
    "    # Step 1: Trim responseSpectrum_calculated to match the length of responseSpectrum_measured\n",
    "    n_rows = responseSpectrum_measured_curr_seg_abs.shape[0]\n",
    "    \n",
    "    print(f\" this is responseSpectrum_measured[segment]'s shape: {responseSpectrum_measured_curr_seg_abs.shape}\")\n",
    "    print(f\"this is nrows: {n_rows}\")\n",
    "    #print(responseSpectrum_measured_curr_seg_abs)\n",
    "    \n",
    "    responseSpectrum_calculated = responseSpectrum_calculated.tail(n_rows)\n",
    "    #freq_limit_rad = 0.3 * 2*np.pi\n",
    "    # Step 2: Create a mask for frequency values less than 0.3\n",
    "    #mask_freq = f0 < freq_limit_rad\n",
    "    mask_freq = fe_sliced < 0.3\n",
    "\n",
    "    # Apply the mask to frequency array to create a filtered frequency array (optional, if needed)\n",
    "    freq_filtered = fe_sliced[mask_freq]\n",
    "    #freq_filtered = f0\n",
    "    #freq_filtered = f0* 2*np.pi\n",
    " \n",
    "    # Apply the mask to both DataFrames\n",
    "\n",
    "\n",
    "    responseSpectrum_measured_filtered = responseSpectrum_measured_curr_seg_abs[mask_freq].reset_index(drop=True)\n",
    "    responseSpectrum_calculated_filtered = responseSpectrum_calculated[mask_freq].reset_index(drop=True)\n",
    "    responseSpectrum_calculated_init_filtered = responseSpectrum_calculated_init[mask_freq].reset_index(drop=True)\n",
    "\n",
    "    title_fig = f'Response estimation results after using optimization method {method} on segment {segment}'   \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 10))  # Adjusted width\n",
    "    fig.suptitle(title_fig, fontsize=16)\n",
    "\n",
    "    # Plotting \"Roll\"\n",
    "\n",
    "    linewidth_measured = 2\n",
    "    linewidth_calculated = 2\n",
    "    measured_color = 'g'      # green\n",
    "    calculated_color_init = 'orange'    # Blue\n",
    "    calculated_color = 'b'    # Blue\n",
    "    error_color = 'r'         # A bright red for error\n",
    "    measured_marker = 's'     # Square marker\n",
    "    calc_marker = 'd'           # diamond marker\n",
    "\n",
    "    # Titles for each subplot\n",
    "    titles = ['Heave', 'Roll', 'Pitch']\n",
    "    y_labels = ['Heave [m**2/Hz]', 'Roll [rad**2/Hz]', 'Pitch [rad**2/Hz]']\n",
    "\n",
    "    # Data keys for each plot, assuming these are column names in your DataFrames\n",
    "    data_keys = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "    # Iterate over the axes, titles, and data keys to create each subplot\n",
    "    for ax, title, y_label, key in zip(axes, titles, y_labels, data_keys):\n",
    "        # Plot measured data\n",
    "        \n",
    "        ax.plot(freq_filtered, np.abs(responseSpectrum_measured_filtered[key]), \n",
    "                label='Measured', color=measured_color, linewidth=linewidth_measured, \n",
    "                markersize=4, marker=measured_marker)\n",
    "        \n",
    "        ax.plot(freq_filtered, np.abs(responseSpectrum_calculated_init_filtered[key]), \n",
    "                label='Calculated with initial parameters', color=calculated_color_init, linestyle='-', \n",
    "                linewidth=linewidth_calculated, markersize=4, marker=calc_marker)\n",
    "\n",
    "        # Plot calculated data\n",
    "        ax.plot(freq_filtered, np.abs(responseSpectrum_calculated_filtered[key]), \n",
    "                label='Calculated with optimized parameters', color=calculated_color, linestyle='-', \n",
    "                linewidth=linewidth_calculated)\n",
    "    \n",
    "\n",
    "        # Set titles and labels\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Encounter Frequency [Hz]\")\n",
    "        ax.set_ylabel(y_label)\n",
    "\n",
    "                # Adjust the legend properties to make it smaller\n",
    "        legend = ax.legend(\n",
    "        fancybox=True, \n",
    "        fontsize=10, \n",
    "        title_fontsize=12, \n",
    "        loc=\"upper right\", \n",
    "        framealpha=0.5, \n",
    "        borderpad=0.5,  # Smaller border padding\n",
    "        labelspacing=0.5,  # Smaller label spacing\n",
    "        handlelength=2  # Shorter handles\n",
    "        )\n",
    "        #legend.set_title(legend_title)\n",
    "        legend.get_frame().set_edgecolor('black')  # Set the legend frame edge color\n",
    "        plt.setp(legend.get_texts(), fontsize='10')  # Adjust font size of legend text\n",
    "\n",
    "        #ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    if (save):\n",
    "        folder_path = 'Plots/Results'\n",
    "        saveSVG(title_file, folder_path, method)\n",
    "\n",
    "    # Adjust layout for a cleaner look\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "def plotResponseSpectrumResult_same_segment_initial_CFE_ALL(segment, fe_sliced, responseSpectrum_measured_curr_seg_abs, responseSpectrum_calculated,responseSpectrum_calculated_init, title_file, method, save = False):\n",
    "    # only select the last iteration as it gives the best result\n",
    "    # Step 1: Trim responseSpectrum_calculated to match the length of responseSpectrum_measured\n",
    "    n_rows = responseSpectrum_measured_curr_seg_abs.shape[0]\n",
    "\n",
    "    \n",
    "    responseSpectrum_calculated = responseSpectrum_calculated.tail(n_rows)\n",
    "\n",
    "    mask_freq = fe_sliced < 0.3\n",
    "\n",
    "    # Apply the mask to frequency array to create a filtered frequency array (optional, if needed)\n",
    "    freq_filtered = fe_sliced[mask_freq]\n",
    "\n",
    " \n",
    "    # Apply the mask to both DataFrames\n",
    "\n",
    "\n",
    "    responseSpectrum_measured_filtered = responseSpectrum_measured_curr_seg_abs[mask_freq].reset_index(drop=True)\n",
    "    responseSpectrum_calculated_filtered = responseSpectrum_calculated[mask_freq].reset_index(drop=True)\n",
    "    responseSpectrum_calculated_init_filtered = responseSpectrum_calculated_init[mask_freq].reset_index(drop=True)\n",
    "    \n",
    "    #print(f\"this is segment array after masking freq: {segment_array}\")\n",
    "    #responseSpectrum_calculated = responseSpectrum_calculated[segment].loc[mask]\n",
    "    title_fig = f'Response estimation results after using optimization method {method} on segment {segment}'   \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(16, 10))  # Adjusted width\n",
    "    fig.suptitle(title_fig, fontsize=16)\n",
    "    #plt.style.use('seaborn-dark-palette')\n",
    "\n",
    "    #axes.set_color_cycle(sns.color_palette(\"coolwarm_r\",num_lines))\n",
    "\n",
    "    # Plotting \"Roll\"\n",
    "    #df_motions[\"Roll\"].plot(ax=axes[0,0], legend=True, grid=True, title=\"Roll\")\n",
    "    linewidth_measured = 2.5\n",
    "    linewidth_calculated = 2.0\n",
    "    measured_color = 'g'      # green\n",
    "    calculated_color_init = 'orange'    # Blue\n",
    "    calculated_color = 'b'    # Blue\n",
    "    error_color = 'r'         # A bright red for error\n",
    "    measured_marker = 's'     # Square marker\n",
    "    calc_marker = 'd'           # diamond marker\n",
    "\n",
    "    # Titles for each subplot\n",
    "    titles = ['Heave', 'Roll', 'Pitch']\n",
    "    y_labels = ['Heave [m**2/Hz]', 'Roll [rad**2/Hz]', 'Pitch [rad**2/Hz]']\n",
    "\n",
    "    # Data keys for each plot, assuming these are column names in your DataFrames\n",
    "    data_keys = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "    step = 3\n",
    "\n",
    "    # Iterate over the axes, titles, and data keys to create each subplot\n",
    "    for ax, title, y_label, key in zip(axes, titles, y_labels, data_keys):\n",
    "        # Plot measured data\n",
    "        \n",
    "        ax.plot(freq_filtered[::step], np.abs(responseSpectrum_measured_filtered[key][::step]), \n",
    "                label='Measured', color=measured_color, linewidth=linewidth_measured, \n",
    "                markersize=4, marker=measured_marker)\n",
    "        \n",
    "        ax.plot(freq_filtered[::step], np.abs(responseSpectrum_calculated_init_filtered[key][::step]), \n",
    "                label='Calculated with initial parameters', color=calculated_color_init, linestyle='--', \n",
    "                linewidth=linewidth_calculated, markersize=3, marker=calc_marker)\n",
    "\n",
    "        # Plot calculated data\n",
    "        ax.plot(freq_filtered[::step], np.abs(responseSpectrum_calculated_filtered[key][::step]), \n",
    "                label='Calculated with optimized parameters', color=calculated_color, linestyle='-', \n",
    "                linewidth=linewidth_calculated, marker = measured_marker, markersize = 3)\n",
    "        \n",
    "        # Set titles and labels\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel(\"Encounter Frequency [Hz]\")\n",
    "        ax.set_ylabel(y_label)\n",
    "\n",
    "                # Adjust the legend properties to make it smaller\n",
    "        legend = ax.legend(\n",
    "        fancybox=True, \n",
    "        fontsize=10, \n",
    "        title_fontsize=12, \n",
    "        loc=\"upper right\", \n",
    "        framealpha=0.5, \n",
    "        borderpad=0.5,  # Smaller border padding\n",
    "        labelspacing=0.5,  # Smaller label spacing\n",
    "        handlelength=2  # Shorter handles\n",
    "        )\n",
    "        #legend.set_title(legend_title)\n",
    "        legend.get_frame().set_edgecolor('black')  # Set the legend frame edge color\n",
    "        plt.setp(legend.get_texts(), fontsize='10')  # Adjust font size of legend text\n",
    "\n",
    "        #ax.legend()\n",
    "        ax.grid(True)\n",
    "\n",
    "    if (save):\n",
    "        folder_path = 'Plots/Results/AllSegments'\n",
    "        saveSVG(title_file, folder_path, method)\n",
    "\n",
    "    # Adjust layout for a cleaner look\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "\n",
    "def plotResponseSpectrumResult_single_response(response, segment, fe_sliced, responseSpectrum_measured_curr_seg_abs, responseSpectrum_calculated, responseSpectrum_calculated_init, title_file, method, save=False):\n",
    "    # Dictionary for mapping response to data keys and y labels\n",
    "    response_mapping = {\n",
    "        \"heave\": {\"key\": \"Heave\", \"label\": \"Heave [m**2/Hz]\", \"title\": \"Heave\"},\n",
    "        \"roll\": {\"key\": \"Roll_rad\", \"label\": \"Roll [rad**2/Hz]\", \"title\": \"Roll\"},\n",
    "        \"pitch\": {\"key\": \"Pitch_rad\", \"label\": \"Pitch [rad**2/Hz]\", \"title\": \"Pitch\"},\n",
    "    }\n",
    "\n",
    "    # Validate the response\n",
    "    if response.lower() not in response_mapping:\n",
    "        raise ValueError(f\"Invalid response type '{response}'. Available responses are: {list(response_mapping.keys())}\")\n",
    "\n",
    "    # Select the data key and label\n",
    "    data_key = response_mapping[response.lower()][\"key\"]\n",
    "    y_label = response_mapping[response.lower()][\"label\"]\n",
    "    title = response_mapping[response.lower()][\"title\"]\n",
    "\n",
    "    # Trim the calculated spectrum to match the measured spectrum's length\n",
    "    n_rows = responseSpectrum_measured_curr_seg_abs.shape[0]\n",
    "    responseSpectrum_calculated = responseSpectrum_calculated.tail(n_rows)\n",
    "\n",
    "    # Create a mask for frequency values less than 0.3 Hz\n",
    "    mask_freq = fe_sliced < 0.3\n",
    "    freq_filtered = fe_sliced[mask_freq]\n",
    "\n",
    "    # Apply the mask to both measured and calculated dataframes\n",
    "    responseSpectrum_measured_filtered = responseSpectrum_measured_curr_seg_abs[mask_freq].reset_index(drop=True)\n",
    "    responseSpectrum_calculated_filtered = responseSpectrum_calculated[mask_freq].reset_index(drop=True)\n",
    "    responseSpectrum_calculated_init_filtered = responseSpectrum_calculated_init[mask_freq].reset_index(drop=True)\n",
    "\n",
    "    # Set plot parameters\n",
    "    linewidth_measured = 2.5\n",
    "    linewidth_calculated = 2.5\n",
    "    measured_color = 'g'      # Green\n",
    "    calculated_color_init = 'orange'    # Orange\n",
    "    calculated_color = 'b'    # Blue\n",
    "    measured_marker = 's'     # Square marker\n",
    "    calc_marker = 'd'         # Diamond marker\n",
    "    step = 3\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(8, 5))\n",
    "    ax.plot(freq_filtered[::step], np.abs(responseSpectrum_measured_filtered[data_key][::step]), \n",
    "            label='Measured', color=measured_color, linewidth=linewidth_measured, \n",
    "            markersize=4, marker=measured_marker)\n",
    "    ax.plot(freq_filtered[::step], np.abs(responseSpectrum_calculated_init_filtered[data_key][::step]), \n",
    "            label='Calculated with initial parameters', color=calculated_color_init, linestyle='--', \n",
    "            linewidth=linewidth_calculated, markersize=4, marker=calc_marker)\n",
    "    ax.plot(freq_filtered[::step], np.abs(responseSpectrum_calculated_filtered[data_key][::step]), \n",
    "            label='Calculated with optimized parameters', color=calculated_color, linestyle='-', \n",
    "            linewidth=linewidth_calculated, marker = measured_marker, markersize = 4)\n",
    "\n",
    "    # Set titles and labels\n",
    "    title_fig = f'Response estimation results using {method} on segment {segment}'\n",
    "    ax.set_title(title_fig, fontsize=14)\n",
    "    ax.set_xlabel(\"Encounter Frequency [Hz]\")\n",
    "    ax.set_ylabel(y_label)\n",
    "\n",
    "    # Add legend\n",
    "    legend = ax.legend(\n",
    "        fancybox=True, fontsize=10, title_fontsize=12, loc=\"upper right\", \n",
    "        framealpha=0.5, borderpad=0.5, labelspacing=0.5, handlelength=2\n",
    "    )\n",
    "    legend.get_frame().set_edgecolor('black')\n",
    "    plt.setp(legend.get_texts(), fontsize='10')\n",
    "\n",
    "    # Add grid and adjust layout\n",
    "    ax.grid(True)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot if required\n",
    "    if save:\n",
    "        folder_path = 'Plots/Results/AllSegments/SingleResponse/'\n",
    "        saveSVG(title_file, folder_path, method)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Want to interpolate to an increased number of frequency points to get higher accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def responseSpectrum_measured_abs(responseSpectrum_measured_curr_seg, freq_intrp, fe):\n",
    "\n",
    "    df_responseSpectrum_abs = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "    # Interpolate to the new frequency points\n",
    "    \n",
    "    responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "    for response in responses:\n",
    "        response_abs = np.interp(freq_intrp, fe, responseSpectrum_measured_curr_seg[response])\n",
    "        df_responseSpectrum_abs[response] = response_abs\n",
    "\n",
    "    return df_responseSpectrum_abs\n",
    "\n",
    "def responseSpectrum_measured_slice(responseSpectrum_measured_curr_seg, fe, step, nr_freqs, max_fe=0.5):\n",
    "    # Limit the fe array to max_fe and apply the step size\n",
    "    step = 1    # currently not using step\n",
    "    fe_sliced = fe[fe <= max_fe]\n",
    "\n",
    "    fe_sliced = np.linspace(fe_sliced[0], fe_sliced[-1], nr_freqs)\n",
    "\n",
    "    # Determine the number of rows required based on fe_sliced\n",
    "    num_rows = len(fe_sliced)\n",
    "\n",
    "    #print(f\" this is the number of rows in fe_sliced: {num_rows}\")\n",
    "\n",
    "    # Slice the DataFrame to match the fe_sliced\n",
    "    df_responseSpectrum_enc = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "    responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "    # Interpolate the measured response spectrum to the new encounter frequency. \n",
    "    for response in responses:\n",
    "        response_abs = np.interp(fe_sliced, fe, responseSpectrum_measured_curr_seg[response])\n",
    "        df_responseSpectrum_enc[response] = response_abs\n",
    "\n",
    "    return df_responseSpectrum_enc, fe_sliced\n",
    "\n",
    "def interpolate2dWS(ws_2d_mu, mu_deg, f0, freq_intrp, beta_TRF):\n",
    "    # add the final\n",
    "    values_first_column = ws_2d_mu[:,0]\n",
    "    values_last_column = ws_2d_mu[:,-1]\n",
    "\n",
    "    values_first_column = values_first_column.reshape(-1, 1)\n",
    "    values_last_column = values_last_column.reshape(-1, 1)\n",
    "\n",
    "    # Horizontal stack the first column, original array, and last column\n",
    "    ws_2d_mu_ext = np.hstack((values_last_column, ws_2d_mu, values_first_column))\n",
    "\n",
    "    #Then I would have to append these directions to mu_deg and beta_TRF as well\n",
    "    mu_deg_ext = np.concatenate(([-7.5], mu_deg, [367.5]))\n",
    "\n",
    "    # Interpolate across directions\n",
    "    interpolated_ws_dir = np.zeros((len(f0), len(beta_TRF)))\n",
    "    for i in range(ws_2d_mu_ext.shape[0]):\n",
    "        interpolated_ws_dir[i, :] = np.interp(beta_TRF, mu_deg_ext, ws_2d_mu_ext[i, :])\n",
    "\n",
    "    # Interpolate across frequencies\n",
    "    interpolated_ws = np.zeros((len(freq_intrp), len(beta_TRF)))\n",
    "    for j in range(len(beta_TRF)):\n",
    "        interpolated_ws[:, j] = np.interp(freq_intrp, f0, interpolated_ws_dir[:, j])\n",
    "    \n",
    "    return interpolated_ws\n",
    "\n",
    "\n",
    "def plotIntegratedWS(segment, timestamp, freq_intrp, beta_TRF, ws_2d_intrp, title_file , plot = False, save = False):\n",
    "    # Compute the integrated wave spectrum using the trapezoidal rule\n",
    "\n",
    "    #print(f\"shape of ws_2d_intrp before trapzoid: {ws_2d_intrp.shape}\")\n",
    " \n",
    "    #print(f\"shape of beta_TRF before trapzoid: {beta_TRF.shape}\")\n",
    " \n",
    "    beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "    sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "    sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "\n",
    "    ws_1d_intrp = trapezoid(sorted_ws_2d_beta_dirs, x = np.sort(beta_TRF_rad), axis=1)\n",
    "\n",
    "\n",
    "    freq_intrp_rad = freq_intrp * 2* np.pi\n",
    " \n",
    "    if plot:\n",
    "        # Create a figure with specific dimensions\n",
    "        plt.figure(figsize=(10, 4))\n",
    "       \n",
    "        # Plot the integrated wave spectrum against the interpolated frequency\n",
    "        plt.plot(freq_intrp, ws_1d_intrp, label='Wave Spectrum', color='blue')\n",
    "        #plt.title(f'1D Wave Spectrum for segment using trapezoidal: {segment}, {timestamp}')\n",
    "        plt.xlabel(r'Encounter Frequency $[Hz]$')\n",
    "        #ylabel = r'$m^2 / Hz$'\n",
    "        plt.ylabel(r'$[m^2 / Hz]$')\n",
    "        plt.legend()\n",
    "        plt.grid(True)  # Optional: add grid for better visualization\n",
    "       \n",
    "        # Tight layout for neatness\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Save the plot if required\n",
    "        if save:\n",
    "            folder_path = 'Plots/WaveSpectra'\n",
    "            saveSVGWS(title_file, folder_path)\n",
    "       \n",
    "        # Display the plot\n",
    "        plt.show()\n",
    " \n",
    "    return ws_1d_intrp\n",
    "\n",
    "def print_params(param_values):\n",
    "    param_names = [\"L\", \"B\", \"T\", \"C_WP\", \"GM_T\", \"delta\", \"tau\", \"d_IMU\"]\n",
    "\n",
    "    for name, value in zip(param_names, param_values):\n",
    "        print(f\"{name} = {value:.3f}\")\n",
    "\n",
    "def print_params_heave(param_values):\n",
    "    param_names = [\"L\", \"B\", \"T\", \"C_WP\", \"GM_T\", \"delta\", \"tau\", \"d_IMU\", 'gain_heave']\n",
    "\n",
    "    for name, value in zip(param_names, param_values):\n",
    "        print(f\"{name} = {value:.3f}\")\n",
    "\n",
    "def print_params_combined(param_values):\n",
    "    param_names = ['L_1', 'B_1', 'T_1', 'gain_heave', 'L_2', 'B_2', 'T_2', 'C_WP_2', 'GM_T_2', 'delta_2', 'tau_2', 'd_IMU_2']\n",
    "\n",
    "    for name, value in zip(param_names, param_values):\n",
    "        print(f\"{name} = {value:.3f}\")\n",
    "    \n",
    "\n",
    "def interpolateFreq(f0, fe, segment, timestamp, responseSpectrum_measured, ws_2d_mu, beta_TRF, mu_deg, step, nr_freqs, plot = False):\n",
    "    responseSpectrum_measured_curr_seg =  responseSpectrum_measured[segment]\n",
    "\n",
    "    responseSpectrum_measured_curr_seg_sliced, fe_sliced = responseSpectrum_measured_slice(responseSpectrum_measured_curr_seg, fe, step, nr_freqs, max_fe=0.5)\n",
    "    ws_2d_intrp = interpolate2dWS(ws_2d_mu, mu_deg, f0, fe_sliced, beta_TRF)\n",
    "\n",
    "    title_file = f'1DWS_{segment}'\n",
    "    ws_1d_intrp = plotIntegratedWS(segment, timestamp, fe_sliced, beta_TRF, ws_2d_intrp, title_file,  plot = plot, save = False)\n",
    "\n",
    "    title_file = f'Contourplot_{segment}'\n",
    "    #plotContourPlot(mu_deg, beta_TRF, f0, fe_sliced, ws_2d_mu, ws_2d_intrp, title_file, save = False)\n",
    "\n",
    "    return responseSpectrum_measured_curr_seg_sliced, ws_2d_intrp, fe_sliced\n",
    "\n",
    "# Calculates 1D response Spectrum\n",
    "def PlotTRF(TRF_2d, freq_sliced, response, beta_TRF):\n",
    "    for i in range(len(beta_TRF)):\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.plot(freq_sliced, TRF_2d[:, i], label='TRF Data')\n",
    "        plt.title(f'TRF_2d for {response} at {beta_TRF[i]:.2f} degrees')\n",
    "        plt.xlabel('Frequency (Hz)')\n",
    "        plt.ylabel('TRF')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def calculateResponsSpectrum_own(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs):\n",
    "\n",
    "    RspecAbs = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "\n",
    "    timestamp, ws_2d_mu = list(df_ws_segments.items())[segment]\n",
    "    yaw = df_pos_segments_avg[segment]['hdt']  # 1 value per segment. Heading [deg]\n",
    "    U = df_speed_segments_avg[segment]['Speed']  # Speed Over Ground [m/s]\n",
    "\n",
    "    beta_TRF = mu_deg - yaw # Might have to use re_range() here to avoid negative angles\n",
    "    beta_TRF = re_range(beta_TRF) # ensure that beta_TRF is within the range of [0, 360]\n",
    "    beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "    responseSpectrum_measured_curr_seg_sliced, ws_2d_intrp, fe_sliced = interpolateFreq(f0, fe, segment, timestamp,  responseSpectrum_measured, ws_2d_mu, beta_TRF, mu_deg, step, nr_freqs, plot = False)\n",
    "    fe_sliced_rad = 2* np.pi* (fe_sliced)\n",
    "    \n",
    "    responses = ['Roll_rad','Heave',  'Pitch_rad']\n",
    "\n",
    "    \n",
    "    A_WP = None # Waterplane area\n",
    "    Nabla = None   # Volume Deplacement\n",
    "    C_B = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "    #alpha[3] = A_WP / (alpha[0] * alpha[1])\n",
    "\n",
    "    sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "    sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "    beta_TRF_sorted = np.sort(beta_TRF)\n",
    "    beta_TRF_rad_sorted = np.sort(beta_TRF_rad)\n",
    "\n",
    "    for response in responses:\n",
    "        \n",
    "        #m0 =  trapezoid(responseSpectrum_measured_ground_truth[response],fe) # variance\n",
    "\n",
    "        # Calculate the CFEs\n",
    "        if response == \"Heave\":\n",
    "            # transfer function for Heave is in units [m/m]\n",
    "            TRF_2d = heaveCF(fe_sliced_rad,beta_TRF,U,alpha[0],alpha[1],alpha[2],C_B) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "            TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[7]**2) * TRF_roll_tmp**2))\n",
    "\n",
    "        if response == \"Pitch_rad\":\n",
    "            # transfer function for Pitch is in units [rad/m]\n",
    "            TRF_2d = pitchCF(fe_sliced_rad,beta_TRF,U,alpha[0],alpha[1],alpha[2],C_B) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "        if response == \"Roll_rad\":\n",
    "            kappa = alpha[3] - alpha[5]\n",
    "            \n",
    "            TRF_2d = rollCF(fe_sliced_rad,beta_TRF,U,alpha[0],alpha[1],alpha[2],C_B,alpha[3],alpha[4],kappa,alpha[6],T_N=0)\n",
    "            TRF_roll_tmp = TRF_2d\n",
    "\n",
    "      \n",
    "        # for every response: calculate the response spectrum\n",
    "        integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "        RspecAbs_response = trapezoid(integrand, x = beta_TRF_rad_sorted, axis = 1)\n",
    "        RspecAbs[response] = RspecAbs_response\n",
    "\n",
    "    RspecAbs['segment'] = segment\n",
    "\n",
    "    return RspecAbs, responseSpectrum_measured_curr_seg_sliced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "def prepare_segment_data(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False):\n",
    "    # This function prepares the data required for each segment\n",
    "    timestamp, ws_2d_mu = list(df_ws_segments.items())[segment]\n",
    "    yaw = df_pos_segments_avg[segment]['hdt']\n",
    "    U = df_speed_segments_avg[segment]['Speed']\n",
    "\n",
    "\n",
    "    beta_TRF = mu_deg - yaw # Might have to use re_range() here to avoid negative angles\n",
    "    beta_TRF = re_range(beta_TRF) # ensure that beta_TRF is within the range of [0, 360]\n",
    "    \n",
    "\n",
    "    responseSpectrum_measured_curr_seg_sliced, ws_2d_intrp, fe_sliced  = interpolateFreq(f0, fe, segment, timestamp,  responseSpectrum_measured, ws_2d_mu, beta_TRF, mu_deg, step, nr_freqs, plot = True)\n",
    "\n",
    "\n",
    "    # Plot original and interpolated data\n",
    "    #plotContourPlot(mu_deg, beta_TRF, f0, fe_sliced, ws_2d_mu, ws_2d_intrp)\n",
    "\n",
    "    #plotWS1D(f0, fe_sliced, mu_deg, beta_TRF, ws_2d_mu, ws_2d_intrp)\n",
    "    \n",
    "    # --------------------------Polar Plot\n",
    "    #plotPolarPlot(mu_deg, beta_TRF, f0, fe_sliced, ws_2d_mu, ws_2d_intrp, savePolar)\n",
    "\n",
    "    return fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NM and L-BFGS-B 8 Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_simulation_single_segment(iterations, segment, alpha_init, varbound, segment_data, param_options, step, nr_freqs, saveInitRS = False):\n",
    "\n",
    "    # unpack current segment data\n",
    "    \n",
    "    fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced = segment_data\n",
    "    beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "    fe_sliced_rad = 2* np.pi* (fe_sliced)\n",
    "    #ws_2d_intrp_rad = ws_2d_intrp / (2* np.pi)\n",
    "\n",
    "    # setting alpha equal to initial conditions for first iteration\n",
    "    alpha = alpha_init\n",
    "\n",
    "    RspecAbs_result_init, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    "    \n",
    "    #RspecAbs_result_init = calculateResponsSpectrum_own(segment, mu_deg, f0, om0_rad, df_pos_segments_avg, df_speed_segments_avg, alpha_init)\n",
    "    df_responseSpectrum_calculated_init = pd.DataFrame(RspecAbs_result_init, columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "    df_responseSpectrum_calculated = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "    df_results_alpha = pd.DataFrame(columns=['L', 'B', 'T', 'C_WP', 'GM_T', 'delta', 'tau', 'd_IMU', 'Error'])\n",
    "    \n",
    "    error = 0\n",
    "    \n",
    "\n",
    "    for iteration in range(iterations):\n",
    "        print(f\"current iteration: {iteration}\")\n",
    "        print(f\"these are the starting values of alpha: {alpha}\")\n",
    "        count = 0\n",
    "        # Cost function which is to be minimised.\n",
    "        def func(alpha):\n",
    "            nonlocal count\n",
    "            responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "        \n",
    "            #print(f\"In cost function. alpha: {alpha}\")\n",
    "            m0 = {} # variance of response spectrum initialized\n",
    "            CF = 0 # cost function initialized\n",
    "            \n",
    "            \n",
    "            Nabla = None # Volume Deplacement\n",
    "            A_WP = None # Waterplane area\n",
    "\n",
    "            C_B = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "            #alpha[3] = A_WP / (alpha[0] * alpha[1])\n",
    "\n",
    "            sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "            sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "            beta_TRF_sorted = np.sort(beta_TRF)\n",
    "\n",
    "            for response in responses:\n",
    "                \n",
    "                m0 =  trapezoid(responseSpectrum_measured_curr_seg_sliced[response], fe_sliced) # variance of measured response spectrum. Note: is given in abs freq\n",
    "\n",
    "                # Calculate the CFEs\n",
    "                if response == \"Heave\":\n",
    "                    # transfer function for Heave is in units [m/m]\n",
    "                    TRF_2d = heaveCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "                    TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[7]**2) * TRF_roll_tmp**2))\n",
    "\n",
    "                if response == \"Pitch_rad\":\n",
    "                    # transfer function for Pitch is in units [rad/m]\n",
    "                    TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "                if response == \"Roll_rad\":\n",
    "                    kappa = alpha[3] - alpha[5]\n",
    "                    TRF_2d = rollCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B,alpha[3],alpha[4],kappa,alpha[6],T_N=0)\n",
    "                    TRF_roll_tmp = TRF_2d\n",
    "\n",
    "                integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "        \n",
    "                RspecAbs_response = trapezoid(integrand, x = np.sort(beta_TRF_rad), axis = 1)\n",
    "\n",
    "                calculated_spectrum = RspecAbs_response\n",
    "\n",
    "                measured_spectrum = responseSpectrum_measured_curr_seg_sliced[response].values\n",
    "\n",
    "                # Difference between measured and calculated spectra\n",
    "                expression = measured_spectrum - calculated_spectrum\n",
    "                \n",
    "                error = np.sqrt(trapezoid(np.abs(expression), fe_sliced) / m0)\n",
    "                # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "                CF += error\n",
    "            #only print every 100th count\n",
    "            if count % 100 == 0 or count == 0:\n",
    "                print(f\"count: {count}, alpha: {alpha}, error: {CF}\")\n",
    "            count += 1\n",
    "        \n",
    "            return CF\n",
    "\n",
    "         # want to use the previous results of the parameters in the next iteration\n",
    "        if iteration != 0:\n",
    "            #print(f\"these are the parameters of previous segment finalist alpha: {alpha}\")\n",
    "            alpha = alpha_final[:-1] # slice off the last parameter error.\n",
    "            print(f\"new alpha after using previous iteration best result: {alpha}\")\n",
    "\n",
    "        param_options = {\n",
    "            'ftol' : 1e-9,\n",
    "            'gtol' : 1e-9\n",
    "        }\n",
    "\n",
    "        #solution = minimize(func, alpha, method=\"nelder-mead\", bounds = varbound, options = param_options) # can use tol = 1e-3\n",
    "        solution = minimize(func, alpha, method=\"L-BFGS-B\", bounds = varbound, options = param_options) # can use tol = 1e-3\n",
    "\n",
    "        print(f\"this is the solution: {solution}\")\n",
    "\n",
    "        alpha_final = solution['x']\n",
    "        alpha_final = alpha_final.tolist()\n",
    "\n",
    "        print(\"These are the final parameters:\")\n",
    "        print_params(alpha_final)\n",
    "        RspecAbs_result, _ = calculateResponsSpectrum_own(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha_final, df_ws_segments, fe,step, nr_freqs)\n",
    "        #RspecAbs_result_rad = RspecAbs_result / (2*np.pi)\n",
    "\n",
    "        error = solution['fun']\n",
    "\n",
    "        print(f\"this was the final error of the cost function {error}\")\n",
    "        # Append results to df_results_alpha\n",
    "        alpha_final.append(error)\n",
    "\n",
    "    # write results to temporary dfs\n",
    "        alpha_final_df = pd.DataFrame([alpha_final], columns=df_results_alpha.columns)\n",
    "        \n",
    "        # for first iteration: Create df\n",
    "        if iteration == 0:\n",
    "            df_results_alpha = alpha_final_df\n",
    "            df_responseSpectrum_calculated = RspecAbs_result\n",
    "    \n",
    "        # else: update existing df\n",
    "        else:\n",
    "            df_results_alpha = pd.concat([df_results_alpha, alpha_final_df], ignore_index=True)\n",
    "            df_responseSpectrum_calculated = pd.concat([df_responseSpectrum_calculated, RspecAbs_result], ignore_index=True)\n",
    "\n",
    "        #print(f\"at segment {segment} the responsespectrum_calculated is : {responseSpectrum_calculated}\")\n",
    "\n",
    "    savetoCSV(df_results_alpha, f\"alpha_segment_{segment}_fe_{nr_freqs}_mtd_NM\")\n",
    "    savetoCSV(df_responseSpectrum_calculated, f'responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_NM')\n",
    "    if saveInitRS:\n",
    "        savetoCSV(df_responseSpectrum_calculated_init, f'responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}')\n",
    "\n",
    "\n",
    "    return df_results_alpha, df_responseSpectrum_calculated, df_responseSpectrum_calculated_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nr_freqs = 600\n",
    "\n",
    "iterations = 1\n",
    "segment = 0\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "\n",
    "segment_data = prepare_segment_data(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "\n",
    "# Set options for the Nelder-Mead optimizer\n",
    "param_options = {\n",
    "    'xatol': 1e-6,   # Tolerance for convergence on x\n",
    "    'fatol': 1e-6,   # Tolerance for convergence on the function value\n",
    "    'maxiter': 1600*20,  # Maximum number of iterations # standard is N*200 where N is len(alpha) -> standard: 1600. If both maxiter and maxfev are set: will stop at first reached.\n",
    "    'maxfev': 1600*20    # Maximum number of function evaluations\n",
    "}\n",
    "# additional options are:\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "df_results_alpha, responseSpectrum_calculated, df_responseSpectrum_calculated_init = run_simulation_single_segment(iterations, segment, \\\n",
    "                                                        alpha_init, varbound, segment_data, param_options, step, nr_freqs, saveInitRS = True)\n",
    "\n",
    "# Capture the end time\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the execution time\n",
    "print(f\"Ran successfully the simulation with {iterations} compiled iterations.\")\n",
    "print(f\"Execution time: {(end_time - start_time)/60} minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readResults(segment, nr_run, nr_freqs):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Define the paths to the files\n",
    "  df_results_alpha_path = f\"df_results/alpha_segment_{segment}_fe_{nr_freqs}_mtd_NM_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_path = f\"responseSpectrumResults/responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_NM_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_init_path = f\"responseSpectrumResults/responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_iter_1.csv\"\n",
    "  \n",
    "\n",
    "  # Read the DataFrames from the CSV files\n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "  responseSpectrum_calculated_current = pd.read_csv(responseSpectrum_calculated_path)\n",
    "  responseSpectrum_calculated_init = pd.read_csv(responseSpectrum_calculated_init_path)\n",
    "\n",
    "  return df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init\n",
    "\n",
    "segment = 0\n",
    "nr_run = 1\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init = readResults(segment, nr_run, nr_freqs)\n",
    "\n",
    "title_file = f'After_optm_Response_estimation_results_same_segment_{segment}_scipy_nr_run_{nr_run}'\n",
    "\n",
    "\n",
    "nperseg = 2048\n",
    "\n",
    "fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg, plot = False) # this is given in encounter freq\n",
    "\n",
    "responseSpectrum_measured_curr_seg = responseSpectrum_measured[segment]\n",
    "\n",
    "\n",
    "responseSpectrum_measured_curr_seg_sliced, fe_sliced = responseSpectrum_measured_slice(responseSpectrum_measured_curr_seg, fe, step, nr_freqs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_file = f'After_optm_TRF_results_same_segment_{segment}_fe_{nr_freqs}_mtd_NM'\n",
    "\n",
    "alpha_init = [L, B, T, C_WP, GM_T, delta, tau, d_IMU] # parameters which are to be optimized\n",
    "\n",
    "method = 'Nelder Mead'\n",
    "\n",
    "plotResponseSpectrumResult_same_segment_initial_CFE(segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current,responseSpectrum_calculated_init, title_file, method, save = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_generation(ga_instance):\n",
    "    generation = ga_instance.generations_completed\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    average_fitness = np.mean([fitness for fitness in ga_instance.last_generation_fitness if fitness is not None])\n",
    "    worst_fitness = min([fitness for fitness in ga_instance.last_generation_fitness if fitness is not None])\n",
    "    diversity = len(set(ga_instance.last_generation_fitness))\n",
    "\n",
    "    print(f\"Generation = {generation}\")\n",
    "    print(f\"Average Fitness = {average_fitness:.2f}\")\n",
    "    print(f\"Best Fitness = {solution_fitness:.4f}\")\n",
    "    print(f\"Worst Fitness = {worst_fitness:.2f}\")\n",
    "    print(f\"Diversity (unique fitness values) = {diversity}\")\n",
    "\n",
    "last_fitness = 0\n",
    "def callback_generation(ga_instance):\n",
    "    global last_fitness\n",
    "\n",
    "    error = 1/ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1]\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "    #print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1]))\n",
    "    print(f\"Error     = {error}\")\n",
    "    print(\"Change     = {change}\".format(change=ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1] - last_fitness))\n",
    "    last_fitness = ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1]\n",
    "\n",
    "def plotGA(ga_instance, segment, nr_freqs):\n",
    "\n",
    "        ga_instance.summary()\n",
    "        print(\"plot fitness\")\n",
    "        ga_instance.plot_fitness()\n",
    "\n",
    "        print(\"plot new solution rate\")\n",
    "        ga_instance.plot_new_solution_rate()\n",
    "\n",
    "        print(\"plot genes\")\n",
    "        #ga_instance.plot_genes(plot_type= \"scatter\", title = f\"gene_plot_segment_{segment}_fe_{nr_freqs}\",save_dir = (f\"Plots/PYGAD/GeneticAlgorithm/gene_plot_scatter_segment_{segment}_fe_{nr_freqs}\"))\n",
    "        ga_instance.plot_genes(plot_type= \"plot\", title = f\"gene_plot_segment_{segment}_fe_{nr_freqs}\",save_dir = (f\"Plots/PYGAD/GeneticAlgorithm/gene_plot_segment_{segment}_fe_{nr_freqs}\"))\n",
    "        # plot boxplot for every parameter\n",
    "        ga_instance.plot_genes(graph_type=\"boxplot\", save_dir = (f\"Plots/PYGAD/GeneticAlgorithm/gene_plot_boxplot_segment_{segment}_fe_{nr_freqs}\"))\n",
    "\n",
    "\n",
    "        # slightly implements some variation to the initial population so that not all individuals are the same\n",
    "def generate_initial_population(base_solution, population_size, variation_range=0.1):\n",
    "    initial_population = []\n",
    "    for _ in range(population_size):\n",
    "        varied_solution = [np.random.uniform(low=max(0, gene - abs(gene * variation_range)),\n",
    "                                             high=gene + abs(gene * variation_range))\n",
    "                           for gene in base_solution]\n",
    "        initial_population.append(varied_solution)\n",
    "    return initial_population\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 params using PyGAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_generation(ga_instance):\n",
    "    generation = ga_instance.generations_completed\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    average_fitness = np.mean([fitness for fitness in ga_instance.last_generation_fitness if fitness is not None])\n",
    "    worst_fitness = min([fitness for fitness in ga_instance.last_generation_fitness if fitness is not None])\n",
    "    diversity = len(set(ga_instance.last_generation_fitness))\n",
    "\n",
    "    print(f\"Generation = {generation}\")\n",
    "    print(f\"Average Fitness = {average_fitness:.2f}\")\n",
    "    print(f\"Best Fitness = {solution_fitness:.4f}\")\n",
    "    print(f\"Worst Fitness = {worst_fitness:.2f}\")\n",
    "    print(f\"Diversity (unique fitness values) = {diversity}\")\n",
    "\n",
    "last_fitness = 0\n",
    "def callback_generation(ga_instance):\n",
    "    global last_fitness\n",
    "\n",
    "    error = 1/ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1]\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "    #print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1]))\n",
    "    print(f\"Error     = {error}\")\n",
    "    print(\"Change     = {change}\".format(change=ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1] - last_fitness))\n",
    "    last_fitness = ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1]\n",
    "\n",
    "def plotGA(ga_instance, segment, nr_freqs):\n",
    "\n",
    "        #ga_instance.summary()\n",
    "        #print(\"plot fitness\")\n",
    "        ga_instance.plot_fitness()\n",
    "\n",
    "        print(\"plot new solution rate\")\n",
    "        #ga_instance.plot_new_solution_rate()\n",
    "\n",
    "        print(\"plot genes\")\n",
    "        #ga_instance.plot_genes(plot_type= \"scatter\", title = f\"gene_plot_segment_{segment}_fe_{nr_freqs}\",save_dir = (f\"Plots/PYGAD/GeneticAlgorithm/gene_plot_scatter_segment_{segment}_fe_{nr_freqs}\"))\n",
    "        ga_instance.plot_genes(plot_type= \"plot\", title = f\"gene_plot_segment_{segment}_fe_{nr_freqs}\",save_dir = (f\"Plots/PYGAD/GeneticAlgorithm/gene_plot_segment_{segment}_fe_{nr_freqs}\"))\n",
    "        # plot boxplot for every parameter\n",
    "        ga_instance.plot_genes(graph_type=\"boxplot\", save_dir = (f\"Plots/PYGAD/GeneticAlgorithm/gene_plot_boxplot_segment_{segment}_fe_{nr_freqs}\"))\n",
    "\n",
    "\n",
    "        # slightly implements some variation to the initial population so that not all individuals are the same\n",
    "def generate_initial_population(base_solution, population_size, variation_range=0.1):\n",
    "    initial_population = []\n",
    "    for _ in range(population_size):\n",
    "        varied_solution = [np.random.uniform(low=max(0, gene - abs(gene * variation_range)),\n",
    "                                             high=gene + abs(gene * variation_range))\n",
    "                           for gene in base_solution]\n",
    "        initial_population.append(varied_solution)\n",
    "    return initial_population\n",
    "\n",
    "\n",
    "def prepare_constant_data(f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments):\n",
    "    return f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_simulation_single_segment_for_all_segments_NM_PYGAD_heave(constant_data, df_ws_segments,df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, \\\n",
    "                                                                   alpha_init_heave, varbound_heave, algorithm_param_pygad, saveInitRS = False):\n",
    "\n",
    "    \n",
    "    f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments = constant_data\n",
    "    count = 0\n",
    "\n",
    "    for segment in range(start_seg, stop_seg):\n",
    "        print(f\"Current segment: {segment}\")\n",
    "\n",
    "        #print(f\"these are the starting values of alpha: {alpha}\")\n",
    "        start_time_seg = time.time()\n",
    "\n",
    "        if count != 0:\n",
    "            #print(f\"these are the parameters of previous segment finalist alpha: {alpha}\")\n",
    "            alpha = alpha_final_pygad[:-1] # slice off the last parameter error.\n",
    "        else:\n",
    "            alpha = alpha_init_heave\n",
    "\n",
    "        alpha = alpha_init_heave # hardcode alpha to be initialized for every start of the segment\n",
    "\n",
    "        segment_data = prepare_segment_data(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "        fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced = segment_data\n",
    "        beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "        fe_sliced_rad = fe_sliced * 2 * np.pi\n",
    "\n",
    "        RspecAbs_result_init, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own_heave(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    " \n",
    "        df_responseSpectrum_calculated_init = pd.DataFrame(RspecAbs_result_init, columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "        df_responseSpectrum_calculated = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "        df_results_alpha = pd.DataFrame(columns=['L', 'B', 'T', 'C_WP', 'GM_T', 'delta', 'tau', 'd_IMU', 'gain_heave' ,'Error'])\n",
    "\n",
    "        sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "        sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "        beta_TRF_sorted = np.sort(beta_TRF)\n",
    "        beta_TRF_rad_sorted = np.sort(beta_TRF_rad)\n",
    "\n",
    "      \n",
    "        count = 0\n",
    "        error = 0\n",
    "        # Cost function which is to be minimised.\n",
    "        def fitness_func(ga_instance, solution, solution_idx):\n",
    "            nonlocal count\n",
    "            responses = ['Roll_rad','Heave',  'Pitch_rad']\n",
    "        \n",
    "            alpha = solution\n",
    "        \n",
    "            #print(f\"In cost function. alpha: {alpha}\")\n",
    "            m0 = {} # variance of response spectrum initialized\n",
    "            CF = 0 # cost function initialized\n",
    "            \n",
    "            Nabla = None  # Volume Deplacement\n",
    "            A_WP = None # Waterplane area\n",
    "\n",
    "            C_B = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "            #alpha[3] = A_WP / (alpha[0] * alpha[1])\n",
    "\n",
    "            #responseSpectrum_measured_curr_seg_sliced_s_rad = responseSpectrum_measured_curr_seg_sliced / (2* np.pi)\n",
    "            for response in responses:\n",
    "                m0 =  trapezoid(responseSpectrum_measured_curr_seg_sliced[response], fe_sliced) # variance of measured response spectrum. Note: is given in abs freq\n",
    "\n",
    "                # Calculate the CFEs\n",
    "                if response == \"Heave\":\n",
    "                    # transfer function for Heave is in units [m/m]\n",
    "                    TRF_2d = heaveCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "                    TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[7]**2) * TRF_roll_tmp**2))\n",
    "                    TRF_2d = TRF_2d * alpha[8] # multiply by the gain\n",
    "\n",
    "                if response == \"Pitch_rad\":\n",
    "                        # transfer function for Pitch is in units [rad/m]\n",
    "                    TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "                if response == \"Roll_rad\":\n",
    "                    kappa = alpha[3] - alpha[5]\n",
    "                    TRF_2d = rollCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B,alpha[3],alpha[4],kappa,alpha[6],T_N=0)\n",
    "                    TRF_roll_tmp = TRF_2d\n",
    "           \n",
    "                #TRF_2d = TRF_2d / (2 * np.pi) # convert the transfer function from rad/s to Hz\n",
    "                integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "            \n",
    "                RspecAbs_response = trapezoid(integrand, x = beta_TRF_rad_sorted, axis = 1)\n",
    "            \n",
    "                calculated_spectrum = RspecAbs_response\n",
    "\n",
    "                measured_spectrum = responseSpectrum_measured_curr_seg_sliced[response].values\n",
    "\n",
    "                # Difference between measured and calculated spectra\n",
    "                expression = measured_spectrum - calculated_spectrum\n",
    "\n",
    "                #error = np.sqrt(trapezoid(np.abs(expression), fe_sliced) / m0)\n",
    "                error = np.sqrt(trapezoid(np.abs(expression), fe_sliced) / m0)\n",
    "                # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "                CF += error\n",
    "  \n",
    "        \n",
    "            return 1/CF\n",
    "        # ---------------after iterating through cost function\n",
    "\n",
    "         # want to use the previous results of the parameters in the next iteration\n",
    "        \n",
    "\n",
    "        # uses GA for finding global optimum\n",
    "        init_pop =  generate_initial_population(alpha, population_size = algorithm_param_pygad['population_size'], variation_range=0.1)\n",
    "        \n",
    "        ga_instance = pygad.GA(num_generations= algorithm_param_pygad['max_num_iteration'],\n",
    "                               sol_per_pop= algorithm_param_pygad['population_size'],\n",
    "                               num_parents_mating=algorithm_param_pygad['num_parents_mating'],\n",
    "                               fitness_func = fitness_func,\n",
    "                               num_genes=len(alpha),\n",
    "                               gene_type=float,\n",
    "                               gene_space=algorithm_param_pygad['gene_space'], # parent_selection_type=\"rws\",\n",
    "                               mutation_num_genes=algorithm_param_pygad['mutation_num_genes'], #when mutation_type = 'adaptive' has to be set to the following format: [60,30]\n",
    "                               crossover_probability=algorithm_param_pygad['crossover_probability'],\n",
    "                               mutation_type=\"random\",\n",
    "                               mutation_by_replacement=True, # to make sure genes do not go beyond range after mutation. prev true\n",
    "                               crossover_type=algorithm_param_pygad['crossover_type'], \n",
    "                               on_generation=callback_generation,\n",
    "                               save_solutions = True,\n",
    "                               initial_population = init_pop,\n",
    "                               stop_criteria = [f\"saturate_{algorithm_param_pygad['max_iteration_without_improv']}\"],\n",
    "                               keep_elitism = algorithm_param_pygad['elit_ratio']\n",
    "                            \n",
    "                            )\n",
    "        \n",
    "        ga_instance.run()\n",
    "        solution, solution_fitness, solution_idx  = ga_instance.best_solution()\n",
    "        plotGA(ga_instance, segment, nr_freqs)\n",
    "\n",
    "    \n",
    "        alpha_final_pygad = solution\n",
    "        alpha_final_pygad = alpha_final_pygad.tolist()\n",
    "        error = 1/solution_fitness\n",
    "\n",
    "        print(\"These are the final parameters after using GA for finding global optimum:\")\n",
    "        print_params_heave(alpha_final_pygad)\n",
    "        print(f\"this is the final error of GA: {error}\")\n",
    "\n",
    "        RspecAbs_result, _ = calculateResponsSpectrum_own_heave(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha_final_pygad, df_ws_segments, fe,step, nr_freqs)\n",
    "        #RspecAbs_result_rad = RspecAbs_result / (2*np.pi)\n",
    "        #error = solution['fun']\n",
    "        print(f\"this was the final error of the cost function using NM: {error}\")\n",
    "        # Append results to df_results_alpha\n",
    "        alpha_final_pygad.append(error)\n",
    "\n",
    "        #print(f\"Parameters of the best solution : {solution}\")\n",
    "        #print(f\"Fitness value of the best solution = {solution_fitness}\")\n",
    "        #print(f\"Index of the best solution : {solution_idx}\")\n",
    "\n",
    "    # write results to temporary dfs\n",
    "        alpha_final_df = pd.DataFrame([alpha_final_pygad], columns=df_results_alpha.columns)\n",
    "\n",
    "        df_results_alpha = alpha_final_df\n",
    "        df_responseSpectrum_calculated = RspecAbs_result\n",
    "\n",
    "        #print(f\"at segment {segment} the responsespectrum_calculated is : {responseSpectrum_calculated}\")\n",
    "        savetoCSVAllSegments(df_results_alpha, f\"alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_9_param_runs_{algorithm_param_pygad['max_num_iteration']}_same_init_alpha_inc_d_IMU\")\n",
    "        savetoCSVAllSegments(df_responseSpectrum_calculated, f\"responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_9_param_runs_{algorithm_param_pygad['max_num_iteration']}_same_init_alpha_inc_d_IMU\")\n",
    "        if saveInitRS:\n",
    "            savetoCSVAllSegments(df_responseSpectrum_calculated_init, f'responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_9_param_inc_d_IMU')\n",
    "\n",
    "        end_time_seg = time.time()\n",
    "        print(f\"Ran successfully. Execution time: {(end_time_seg - start_time_seg)/60} minutes\")\n",
    "        count += 1\n",
    "\n",
    "    #nr_freqs = 1025/step\n",
    "    # Save results to CSV\n",
    "   \n",
    "\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_simulation_multiple_segments_NM_PYGAD_heave(alpha_init_heave, varbound_heave,constant_data,\\\n",
    "                                    df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured,algorithm_param_pygad,saveInitRS = False):\n",
    "    start_time = time.time()\n",
    "        \n",
    "    run_simulation_single_segment_for_all_segments_NM_PYGAD_heave(constant_data, df_ws_segments,df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured,\\\n",
    "                                                        alpha_init_heave, varbound_heave, algorithm_param_pygad, saveInitRS)\n",
    "\n",
    "    # Capture the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate and print the execution time\n",
    "    print(f\"Ran successfully the ssimulation with {nr_segments} compiled segments.\")\n",
    "    print(f\"Execution time: {(end_time - start_time)/60} minutes\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 params PYGAD including d_IMU same init alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nr_freqs = 600\n",
    "#nr_segments = 2\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "start_seg = 24\n",
    "stop_seg = 136\n",
    "nr_segments = stop_seg - start_seg\n",
    "\n",
    "gene_space = [{'low': float(bounds[0]), 'high': float(bounds[1])} for bounds in varbound_heave] # create continous voundaries\n",
    "\n",
    "# Set options for the Nelder-Mead optimizer\n",
    "algorithm_param_pygad_4 = {'max_num_iteration': 100, # 1000\n",
    "                    'population_size': 50, # can try 150 \n",
    "                    'mutation_num_genes': 1, # prev 0.3\n",
    "                    'elit_ratio': 2, # prev 0.2\n",
    "                    'crossover_probability': 0.7,\n",
    "                    'num_parents_mating': 15, # prev 0.2\n",
    "                    'crossover_type': 'uniform',\n",
    "                    'max_iteration_without_improv': 150,\n",
    "                    'gene_space' : gene_space   \n",
    "                    }\n",
    "\n",
    "constant_data = prepare_constant_data(f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments)\n",
    "\n",
    "\n",
    "run_simulation_multiple_segments_NM_PYGAD_heave(alpha_init_heave, varbound_heave, constant_data, \\\n",
    "                                    df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, algorithm_param_pygad_4, saveInitRS = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readResults(segment, nr_run, nr_freqs, iterations):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Define the paths to the files\n",
    "  df_results_alpha_path = f\"df_results_ALL/alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_9_param_runs_{iterations}_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_path = f\"responseSpectrumResults_ALL/responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_9_param_runs_{iterations}_iter_{nr_run}.csv\"\n",
    "\n",
    "  responseSpectrum_calculated_init_path = f\"responseSpectrumResults_ALL/responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_iter_1.csv\"\n",
    "\n",
    "  # Read the DataFrames from the CSV files\n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "  responseSpectrum_calculated_current = pd.read_csv(responseSpectrum_calculated_path)\n",
    "  responseSpectrum_calculated_init = pd.read_csv(responseSpectrum_calculated_init_path)\n",
    "\n",
    "  return df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init\n",
    "\n",
    "\n",
    "def readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, iterations, response, df_motions_segments):\n",
    "  nperseg = 2048\n",
    "  fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg,plot = None, save = False) # this is given in encounter freq\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_runs_{iterations}'\n",
    "\n",
    "\n",
    "    responseSpectrum_measured_curr_seg = responseSpectrum_measured[segment]\n",
    "    responseSpectrum_measured_curr_seg_sliced, fe_sliced = responseSpectrum_measured_slice(responseSpectrum_measured_curr_seg, fe, step, nr_freqs)\n",
    "\n",
    "    method = 'PyGAD'\n",
    "    \n",
    "    plotResponseSpectrumResult_same_segment_initial_CFE_ALL(segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current,responseSpectrum_calculated_init, title_file, method, save = True)\n",
    "\n",
    "    if response != None:\n",
    "      title_file = f'After_optm_heave_results_segment_{segment}_fe_{nr_freqs}__resp_{response}_mtd_PYGAD_runs_{iterations}'\n",
    "      plotResponseSpectrumResult_single_response(response, segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current, responseSpectrum_calculated_init, title_file, method, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_seg = 1\n",
    "stop_seg = 2\n",
    "nr_run = 2\n",
    "response = 'heave'\n",
    "iterations = 200 # max nr of iterations/ generations\n",
    "\n",
    "nr_segments = stop_seg - start_seg\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, iterations, response, df_motions_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12 params. Separate tuning parameters for heave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculateResponsSpectrum_own_combined(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs):\n",
    "\n",
    "    RspecAbs = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "\n",
    "    timestamp, ws_2d_mu = list(df_ws_segments.items())[segment]\n",
    "    yaw = df_pos_segments_avg[segment]['hdt']  # 1 value per segment. Heading [deg]\n",
    "    U = df_speed_segments_avg[segment]['Speed']  # Speed Over Ground [m/s]\n",
    "\n",
    "    beta_TRF = mu_deg - yaw # Might have to use re_range() here to avoid negative angles\n",
    "    beta_TRF = re_range(beta_TRF) # ensure that beta_TRF is within the range of [0, 360]\n",
    "    beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "\n",
    "    responseSpectrum_measured_curr_seg_sliced, ws_2d_intrp, fe_sliced = interpolateFreq(f0, fe, segment, timestamp,  responseSpectrum_measured, ws_2d_mu, beta_TRF, mu_deg, step, nr_freqs, plot = False)\n",
    "    fe_sliced_rad = 2* np.pi* (fe_sliced)\n",
    "\n",
    "    \n",
    "    responses = ['Roll_rad','Heave',  'Pitch_rad']\n",
    "\n",
    "    Nabla = None  # Volume Deplacement\n",
    "    A_WP = None # Waterplane area\n",
    "\n",
    "    C_B_1 = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "    C_B_2 = Nabla / (alpha[4] * alpha[5] * alpha[6])\n",
    "\n",
    "    #alpha[3] = A_WP / (alpha[0] * alpha[1])\n",
    "\n",
    "    sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "    sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "    \n",
    "    beta_TRF_sorted = np.sort(beta_TRF)\n",
    "    beta_TRF_rad_sorted = np.sort(beta_TRF_rad)\n",
    "\n",
    "    for response in responses:\n",
    "        \n",
    "        #m0 =  trapezoid(responseSpectrum_measured_ground_truth[response],fe) # variance\n",
    "\n",
    "        # Calculate the CFEs\n",
    "        if response == \"Heave\":\n",
    "            # transfer function for Heave is in units [m/m]\n",
    "            TRF_2d = heaveCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B_1) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "            TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[11]**2) * TRF_roll_tmp**2))\n",
    "            TRF_2d = TRF_2d * alpha[3] # multiply by the gain\n",
    "            \n",
    "        if response == \"Pitch_rad\":\n",
    "            # transfer function for Pitch is in units [rad/m]\n",
    "            TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_2) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "        if response == \"Roll_rad\":\n",
    "            kappa = alpha[7] - alpha[9]\n",
    "            \n",
    "            TRF_2d = rollCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_2,alpha[7],alpha[8],kappa,alpha[10],T_N=0)\n",
    "            TRF_roll_tmp = TRF_2d\n",
    "\n",
    "        #PlotTRF(TRF_2d, freq_intrp_rad, response, beta_TRF)\n",
    "        #TRF_2d = TRF_2d / (2 * np.pi) # convert the transfer function from rad/s to Hz\n",
    "\n",
    "        # for every response: calculate the response spectrum\n",
    "        #dx = beta_TRF_rad[1] - beta_TRF_rad[0]\n",
    "        integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "        \n",
    "        RspecAbs_response = trapezoid(integrand, x = beta_TRF_rad_sorted, axis = 1)\n",
    "        RspecAbs[response] = RspecAbs_response\n",
    "\n",
    "    RspecAbs['segment'] = segment\n",
    "\n",
    "    return RspecAbs, responseSpectrum_measured_curr_seg_sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_single_segment_for_all_segments_PYGAD_combined(constant_data, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, alpha_init_combined, varbound_combined, algorithm_param_pygad, saveInitRS = False):\n",
    "    \n",
    "    f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments = constant_data\n",
    "    count = 0\n",
    "    for segment in range(start_seg, stop_seg):\n",
    "        start_time_seg = time.time()\n",
    "        print(f\"Current segment: {segment}\")\n",
    "\n",
    "        if count != 0:\n",
    "            #print(f\"these are the parameters of previous segment finalist alpha: {alpha}\")\n",
    "            alpha = alpha_final_pygad[:-1] # slice off the last parameter error.\n",
    "        else:\n",
    "            alpha = alpha_init_combined\n",
    "\n",
    "        alpha = alpha_init_combined\n",
    "\n",
    "        segment_data = prepare_segment_data(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "        fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced = segment_data\n",
    "        beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "        fe_sliced_rad = fe_sliced * 2 * np.pi\n",
    "\n",
    "        RspecAbs_result_init, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own_combined(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    " \n",
    "        df_responseSpectrum_calculated_init = pd.DataFrame(RspecAbs_result_init, columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "        df_responseSpectrum_calculated = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "        df_results_alpha = pd.DataFrame(columns=['L_1', 'B_1', 'T_1', 'gain_heave', 'L_2', 'B_2', 'T_2', 'C_WP_2', 'GM_T_2', 'delta_2', 'tau_2', 'd_IMU_2', 'Error'])\n",
    "       \n",
    "        \n",
    "        sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "        sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "        beta_TRF_sorted = np.sort(beta_TRF)\n",
    "        beta_TRF_rad_sorted = np.sort(beta_TRF_rad)\n",
    "\n",
    "        error = 0\n",
    "\n",
    "        #print(f\"these are the starting values of alpha: {alpha}\")\n",
    "        count = 0\n",
    "        # Cost function which is to be minimised.\n",
    "        def fitness_func(ga_instance, solution, solution_idx):\n",
    "            nonlocal count\n",
    "            responses = ['Roll_rad','Heave',  'Pitch_rad']\n",
    "            alpha = solution\n",
    "            #print(f\"In cost function. alpha: {alpha}\")\n",
    "            m0 = {} # variance of response spectrum initialized\n",
    "            CF = 0 # cost function initialized\n",
    "            \n",
    "            Nabla = None  # Volume Deplacement\n",
    "            A_WP = None# Waterplane area\n",
    "\n",
    "            C_B_1 = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "            C_B_2 = Nabla / (alpha[4] * alpha[5] * alpha[6])\n",
    "        \n",
    "            for response in responses:\n",
    "                \n",
    "                m0 =  trapezoid(responseSpectrum_measured_curr_seg_sliced[response], fe_sliced) # variance of measured response spectrum. Note: is given in abs freq\n",
    "\n",
    "                # Calculate the CFEs\n",
    "                if response == \"Heave\":\n",
    "                    # transfer function for Heave is in units [m/m]\n",
    "                    TRF_2d = heaveCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B_1) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "                    TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[11]**2) * TRF_roll_tmp**2))\n",
    "                    TRF_2d = TRF_2d * alpha[3] # multiply by the gain\n",
    "                    \n",
    "                if response == \"Pitch_rad\":\n",
    "                    # transfer function for Pitch is in units [rad/m]\n",
    "                    TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_2) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "                if response == \"Roll_rad\":\n",
    "                    kappa = alpha[7] - alpha[9]\n",
    "                    TRF_2d = rollCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_2,alpha[7],alpha[8],kappa,alpha[10],T_N=0)\n",
    "                    TRF_roll_tmp = TRF_2d\n",
    "\n",
    "\n",
    "                integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "                RspecAbs_response = trapezoid(integrand, x = beta_TRF_rad_sorted, axis = 1)\n",
    "\n",
    "                calculated_spectrum = RspecAbs_response\n",
    "\n",
    "                measured_spectrum = responseSpectrum_measured_curr_seg_sliced[response].values\n",
    "\n",
    "                # Difference between measured and calculated spectra\n",
    "                expression = measured_spectrum - calculated_spectrum\n",
    "                \n",
    "                error = np.sqrt(trapezoid(np.abs(expression), fe_sliced) / m0)\n",
    "                # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "                CF += error\n",
    "            #only print every 100th count\n",
    "            #if count % 100 == 0 or count == 0:\n",
    "                #print(f\"count: {count}, alpha: {alpha}, error: {CF}\")\n",
    "            #count += 1\n",
    "        \n",
    "            return 1/CF\n",
    "        # ---------------after iterating through cost function\n",
    "        # generate init population for new alpha\n",
    "        #init_population = generate_initial_population(alpha, population_size = algorithm_param_pygad['population_size'], variation_range=0.1)\n",
    "        #init_population =  generate_initial_population(alpha, algorithm_param_pygad['population_size'], varbound_combined,variation_range=0.1)\n",
    "        init_population  = generate_initial_population(alpha_init_combined, population_size = 50, variation_range=0.1)\n",
    "\n",
    "        ga_instance = pygad.GA(num_generations= algorithm_param_pygad['max_num_iteration'],\n",
    "                               sol_per_pop= algorithm_param_pygad['population_size'],\n",
    "                               num_parents_mating=algorithm_param_pygad['num_parents_mating'],\n",
    "                               fitness_func = fitness_func,\n",
    "                               num_genes=len(alpha),\n",
    "                               gene_type=float,\n",
    "                               gene_space=algorithm_param_pygad['gene_space'], # parent_selection_type=\"rws\",\n",
    "                               mutation_num_genes=algorithm_param_pygad['mutation_num_genes'], #when mutation_type = 'adaptive' has to be set to the following format: [60,30]\n",
    "                               crossover_probability=algorithm_param_pygad['crossover_probability'],\n",
    "                               mutation_type=\"random\",\n",
    "                               mutation_by_replacement=True, # to make sure genes do not go beyond range after mutation. prev true\n",
    "                               crossover_type=algorithm_param_pygad['crossover_type'], \n",
    "                               on_generation=callback_generation,\n",
    "                               save_solutions = True,\n",
    "                               initial_population = init_population,\n",
    "                               stop_criteria = [f\"saturate_{algorithm_param_pygad['max_iteration_without_improv']}\"],\n",
    "                               keep_elitism = algorithm_param_pygad['elit_ratio']\n",
    "                            )\n",
    "        \n",
    "        ga_instance.run()\n",
    "        solution, solution_fitness, solution_idx  = ga_instance.best_solution()\n",
    "        plotGA(ga_instance)\n",
    "\n",
    "        alpha_final_pygad = solution\n",
    "        alpha_final_pygad = alpha_final_pygad.tolist()\n",
    "        error = 1/solution_fitness\n",
    "\n",
    "        print(\"These are the final parameters after using GA for finding global optimum:\")\n",
    "        print_params_combined(alpha_final_pygad)\n",
    "        print(f\"this is the final error of GA: {error}\")\n",
    "        #RspecAbs_result, _ = calculateResponsSpectrum_own(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha_final, df_ws_segments, fe,step, nr_freqs)\n",
    "        RspecAbs_result, _ =  calculateResponsSpectrum_own_combined(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha_final_pygad, df_ws_segments, fe,step, nr_freqs)\n",
    "        #RspecAbs_result_rad = RspecAbs_result / (2*np.pi)\n",
    "\n",
    "        print(f\"this was the final error of the cost function {error}\")\n",
    "        # Append results to df_results_alpha\n",
    "        alpha_final_pygad.append(error)\n",
    "\n",
    "    # write results to temporary dfs\n",
    "        alpha_final_df = pd.DataFrame([alpha_final_pygad], columns=df_results_alpha.columns)\n",
    "\n",
    "        df_results_alpha = alpha_final_df\n",
    "        df_responseSpectrum_calculated = RspecAbs_result\n",
    " \n",
    "        # Save results to CSV\n",
    "        savetoCSVAllSegmentsCombined(df_results_alpha, f\"alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{algorithm_param_pygad['max_num_iteration']}_same_init_alpha_inc_d_IMU\")\n",
    "        savetoCSVAllSegmentsCombined(df_responseSpectrum_calculated, f\"responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{algorithm_param_pygad['max_num_iteration']}_same_init_alpha_inc_d_IMU\")\n",
    "        if saveInitRS:\n",
    "            #savetoCSVAllSegmentsCombined(df_responseSpectrum_calculated_init, f'responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}')\n",
    "            savetoCSVAllSegmentsCombined(df_responseSpectrum_calculated_init, f'responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_same_init_alpha')\n",
    "\n",
    "\n",
    "        end_time_seg = time.time()\n",
    "        print(f\"Ran successfully. Execution time: {(end_time_seg - start_time_seg)/60} minutes\")\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_simulation_multiple_segments_PYGAD_combined(alpha_init_combined, varbound_combined, constant_data, \\\n",
    "                                    df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, param_options,saveInitRS = False):\n",
    "\n",
    "    start_time = time.time()\n",
    "    run_simulation_single_segment_for_all_segments_PYGAD_combined(constant_data, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, alpha_init_combined, varbound_combined,param_options, saveInitRS)\n",
    "\n",
    "    # Capture the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate and print the execution time\n",
    "    print(f\"Ran successfully the simulation with {nr_segments} compiled segments.\")\n",
    "    print(f\"Execution time: {(end_time - start_time)/60} minutes\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm_param_pygad_4 = {'max_num_iteration':100, # 1000\n",
    "                    'population_size': 50, #  150 \n",
    "                    'mutation_num_genes': 1, # prev 0.3\n",
    "                    'elit_ratio': 2, # prev 0.2\n",
    "                    'crossover_probability': 0.7,\n",
    "                    'num_parents_mating': 15, # prev 0.2\n",
    "                    'crossover_type': 'uniform',\n",
    "                    'max_iteration_without_improv': 150,\n",
    "                    'gene_space' : gene_space   \n",
    "                    }\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "constant_data = prepare_constant_data(f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments)\n",
    "\n",
    "run_simulation_multiple_segments_PYGAD_combined(alpha_init_combined, varbound_combined, constant_data, \\\n",
    "                                    df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, algorithm_param_pygad_4, saveInitRS = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readResults(segment, nr_run, nr_freqs, iterations):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Define the paths to the files\n",
    "  df_results_alpha_path = f\"df_results_ALL_combined/alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{iterations}_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{iterations}_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_init_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_iter_1.csv\"\n",
    "\n",
    "  # Read the DataFrames from the CSV files\n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "  responseSpectrum_calculated_current = pd.read_csv(responseSpectrum_calculated_path)\n",
    "  responseSpectrum_calculated_init = pd.read_csv(responseSpectrum_calculated_init_path)\n",
    "\n",
    "  return df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init\n",
    "\n",
    "\n",
    "def readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, iterations, response, df_motions_segments):\n",
    "  nperseg = 2048\n",
    "  fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg,plot = None, save = False) # this is given in encounter freq\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_runs_{iterations}'\n",
    "\n",
    "    responseSpectrum_measured_curr_seg = responseSpectrum_measured[segment]\n",
    "    ic(len(responseSpectrum_measured_curr_seg))\n",
    "    responseSpectrum_measured_curr_seg_sliced, fe_sliced = responseSpectrum_measured_slice(responseSpectrum_measured_curr_seg, fe, step, nr_freqs)\n",
    "    ic(len(responseSpectrum_measured_curr_seg_sliced))\n",
    "    ic(len(fe_sliced))\n",
    "\n",
    "    method = 'PyGAD'\n",
    "\n",
    "    plotResponseSpectrumResult_same_segment_initial_CFE_ALL(segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current,responseSpectrum_calculated_init, title_file, method, save = True)\n",
    "\n",
    "    if response != None:\n",
    "      title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_resp_{response}_mtd_PYGAD_runs_{iterations}'\n",
    "      plotResponseSpectrumResult_single_response(response, segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current, responseSpectrum_calculated_init, title_file, method, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_seg = 0\n",
    "stop_seg = 136\n",
    "nr_run = 1\n",
    "response = None\n",
    "iterations = 800 # max number of iterations\n",
    "\n",
    "nr_segments = stop_seg - start_seg\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, iterations, response, df_motions_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L-BFGS-B 12 param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_single_segment_for_all_segments_LBFGS_combined(constant_data, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, alpha_init_combined, varbound_combined, algorithm_param_pygad, saveInitRS = False):\n",
    "    \n",
    "    f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments = constant_data\n",
    "    count = 0\n",
    "    for segment in range(start_seg, stop_seg):\n",
    "        start_time_seg = time.time()\n",
    "        print(f\"Current segment: {segment}\")\n",
    "\n",
    "        if count != 0:\n",
    "            #print(f\"these are the parameters of previous segment finalist alpha: {alpha}\")\n",
    "            alpha = alpha_final[:-1] # slice off the last parameter error.\n",
    "        else:\n",
    "            alpha = alpha_init_combined\n",
    "\n",
    "        alpha = alpha_init_combined\n",
    "\n",
    "        segment_data = prepare_segment_data(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "        fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced = segment_data\n",
    "        beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "        fe_sliced_rad = fe_sliced * 2 * np.pi\n",
    "\n",
    "        RspecAbs_result_init, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own_combined(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    " \n",
    "        df_responseSpectrum_calculated_init = pd.DataFrame(RspecAbs_result_init, columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "        df_responseSpectrum_calculated = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "        df_results_alpha = pd.DataFrame(columns=['L_1', 'B_1', 'T_1', 'gain_heave', 'L_2', 'B_2', 'T_2', 'C_WP_2', 'GM_T_2', 'delta_2', 'tau_2', 'd_IMU_2', 'Error'])\n",
    "        \n",
    "        sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "        sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "        beta_TRF_sorted = np.sort(beta_TRF)\n",
    "        beta_TRF_rad_sorted = np.sort(beta_TRF_rad)\n",
    "\n",
    "        error = 0\n",
    "\n",
    "        #print(f\"these are the starting values of alpha: {alpha}\")\n",
    "        count = 0\n",
    "        # Cost function which is to be minimised.\n",
    "        def func(alpha):\n",
    "            nonlocal count\n",
    "            responses = ['Roll_rad','Heave',  'Pitch_rad']\n",
    "            #print(f\"In cost function. alpha: {alpha}\")\n",
    "            m0 = {} # variance of response spectrum initialized\n",
    "            CF = 0 # cost function initialized\n",
    "            \n",
    "            Nabla = None   # Volume Deplacement\n",
    "            A_WP = None # Waterplane area\n",
    "\n",
    "            C_B_1 = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "            C_B_2 = Nabla / (alpha[4] * alpha[5] * alpha[6])\n",
    "\n",
    "            for response in responses:\n",
    "                \n",
    "                m0 =  trapezoid(responseSpectrum_measured_curr_seg_sliced[response], fe_sliced) # variance of measured response spectrum. Note: is given in abs freq\n",
    "\n",
    "                # Calculate the CFEs\n",
    "                if response == \"Heave\":\n",
    "                    # transfer function for Heave is in units [m/m]\n",
    "                    TRF_2d = heaveCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B_1) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "                    TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[11]**2) * TRF_roll_tmp**2))\n",
    "\n",
    "                    TRF_2d = TRF_2d * alpha[3] # multiply by the gain\n",
    "                    \n",
    "                if response == \"Pitch_rad\":\n",
    "                    # transfer function for Pitch is in units [rad/m]\n",
    "                    TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_2) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "                if response == \"Roll_rad\":\n",
    "                    kappa = alpha[7] - alpha[9]\n",
    "                    TRF_2d = rollCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_2,alpha[7],alpha[8],kappa,alpha[10],T_N=0)\n",
    "                    TRF_roll_tmp = TRF_2d\n",
    "\n",
    "                integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "                \n",
    "                RspecAbs_response = trapezoid(integrand, x = beta_TRF_rad_sorted, axis = 1)\n",
    "\n",
    "                calculated_spectrum = RspecAbs_response\n",
    "\n",
    "                measured_spectrum = responseSpectrum_measured_curr_seg_sliced[response].values\n",
    "\n",
    "                # Difference between measured and calculated spectra\n",
    "                expression = measured_spectrum - calculated_spectrum\n",
    "                \n",
    "                error = np.sqrt(trapezoid(np.abs(expression), fe_sliced) / m0)\n",
    "                # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "                CF += error\n",
    "            #only print every 100th count\n",
    "            #if count % 100 == 0 or count == 0:\n",
    "                #print(f\"count: {count}, alpha: {alpha}, error: {CF}\")\n",
    "            #count += 1\n",
    "        \n",
    "            return CF\n",
    "        # ---------------after iterating through cost function\n",
    "        # generate init population for new alpha\n",
    "\n",
    "        param_options_BFGS = {\n",
    "            'ftol' : 1e-9,\n",
    "            'gtol' : 1e-9\n",
    "        }\n",
    "\n",
    "        param_options_NM = {\n",
    "            'xatol': 1e-9,   # Tolerance for convergence on x\n",
    "            'fatol': 1e-9,   # Tolerance for convergence on the function value\n",
    "            'maxiter': 32*1e3,  # Maximum number of iterations # standard is N*200 where N is len(alpha) -> standard: 1600. If both maxiter and maxfev are set: will stop at first reached.\n",
    "            'maxfev': 32*1e3    # Maximum number of function evaluations\n",
    "        }\n",
    "\n",
    "        #solution = minimize(func, alpha, method=\"L-BFGS-B\", bounds = varbound_combined, options = param_options_BFGS) # can use tol = 1e-3\n",
    "        solution = minimize(func, alpha, method=\"nelder-mead\", bounds = varbound_combined, options = param_options_NM) # can use tol = 1e-3\n",
    "\n",
    "        alpha_final = solution['x']\n",
    "        alpha_final = alpha_final.tolist()\n",
    "\n",
    "        print(\"These are the final parameters:\")\n",
    "        print_params_combined(alpha_final)\n",
    "        RspecAbs_result, _ = calculateResponsSpectrum_own_combined(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha_final, df_ws_segments, fe,step, nr_freqs)\n",
    "        #RspecAbs_result_rad = RspecAbs_result / (2*np.pi)\n",
    "\n",
    "        error = solution['fun']\n",
    "\n",
    "        print(f\"this is the final error of LBFGS: {error}\")\n",
    "        \n",
    "        alpha_final.append(error)\n",
    "\n",
    "    # write results to temporary dfs\n",
    "        alpha_final_df = pd.DataFrame([alpha_final], columns=df_results_alpha.columns)\n",
    "\n",
    "        df_results_alpha = alpha_final_df\n",
    "        df_responseSpectrum_calculated = RspecAbs_result\n",
    "    \n",
    "\n",
    "        savetoCSVAllSegmentsCombined(df_results_alpha, f\"alpha_segment_{segment}_fe_{nr_freqs}_mtd_NM_12_param_same_init_alpha_inc_d_IMU\")\n",
    "        savetoCSVAllSegmentsCombined(df_responseSpectrum_calculated, f'responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_NM_12_param_same_init_alpha_inc_d_IMU')\n",
    "        if saveInitRS:\n",
    "            savetoCSVAllSegmentsCombined(df_responseSpectrum_calculated_init, f'responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_same_init_alpha_12_params_inc_d_IMU')\n",
    "\n",
    "        end_time_seg = time.time()\n",
    "        print(f\"Ran successfully. Execution time: {(end_time_seg - start_time_seg)/60} minutes\")\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_constant_data(f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments):\n",
    "    return f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_simulation_multiple_segments_LBFGS_combined(alpha_init_combined, varbound_combined, constant_data, \\\n",
    "                                    df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, param_options,saveInitRS = False):\n",
    "\n",
    "    start_time = time.time()\n",
    "    run_simulation_single_segment_for_all_segments_LBFGS_combined(constant_data, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, alpha_init_combined, varbound_combined,param_options, saveInitRS)\n",
    "\n",
    "    # Capture the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate and print the execution time\n",
    "    print(f\"Ran successfully the simulation with {nr_segments} compiled segments.\")\n",
    "    print(f\"Execution time: {(end_time - start_time)/60} minutes\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nr_freqs = 600\n",
    "#nr_segments = 2\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "start_seg = 79\n",
    "stop_seg = 136\n",
    "nr_segments = stop_seg - start_seg\n",
    "\n",
    "\n",
    "gene_space = [{'low': float(bounds[0]), 'high': float(bounds[1])} for bounds in varbound_combined] # create continous voundaries\n",
    "\n",
    "\n",
    "# Set options for the Nelder-Mead optimizer\n",
    "algorithm_param_pygad_4 = {'max_num_iteration': 2, # 1000\n",
    "                    'population_size': 150, # can try 150 \n",
    "                    'mutation_num_genes': 1, # prev 0.3\n",
    "                    'elit_ratio': 2, # prev 0.2\n",
    "                    'crossover_probability': 0.7,\n",
    "                    'num_parents_mating': 15, # prev 0.2\n",
    "                    'crossover_type': 'uniform',\n",
    "                    'max_iteration_without_improv': 150,\n",
    "                    'gene_space' : gene_space   \n",
    "                    }\n",
    "\n",
    "\n",
    "constant_data = prepare_constant_data(f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments)\n",
    "\n",
    "run_simulation_multiple_segments_LBFGS_combined(alpha_init_combined, varbound_combined, constant_data, \\\n",
    "                                    df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, algorithm_param_pygad_4, saveInitRS = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readResults(segment, nr_run, nr_freqs, iterations):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "  \"\"\"\n",
    "  # Define the paths to the files\n",
    "  df_results_alpha_path = f\"df_results_ALL_combined/alpha_segment_{segment}_fe_{nr_freqs}_mtd_LBFGS_12_param_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_LBFGS_12_param_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_init_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_iter_1.csv\"\n",
    "  \"\"\"\n",
    "  df_results_alpha_path = f\"df_results_ALL_combined/alpha_segment_{segment}_fe_{nr_freqs}_mtd_NM_12_param_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_NM_12_param_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_init_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_iter_1.csv\"\n",
    "\n",
    "  # Read the DataFrames from the CSV files\n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "  responseSpectrum_calculated_current = pd.read_csv(responseSpectrum_calculated_path)\n",
    "  responseSpectrum_calculated_init = pd.read_csv(responseSpectrum_calculated_init_path)\n",
    "\n",
    "  return df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init\n",
    "\n",
    "\n",
    "def readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, response, df_motions_segments):\n",
    "  nperseg = 2048\n",
    "  fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg,plot = None, save = False) # this is given in encounter freq\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    #title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_LBFGS'\n",
    "    title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_NM'\n",
    "    responseSpectrum_measured_curr_seg = responseSpectrum_measured[segment]\n",
    "\n",
    "    responseSpectrum_measured_curr_seg_sliced, fe_sliced = responseSpectrum_measured_slice(responseSpectrum_measured_curr_seg, fe, step, nr_freqs)\n",
    "\n",
    "    #method = 'L-BFGS-B'\n",
    "    method = 'NM'\n",
    "\n",
    "    plotResponseSpectrumResult_same_segment_initial_CFE_ALL(segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current,responseSpectrum_calculated_init, title_file, method, save = True)\n",
    "\n",
    "    if response != None:\n",
    "      title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_resp_{response}_mtd_NM'\n",
    "      #title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_resp_{response}_mtd_LBFGS'\n",
    "      plotResponseSpectrumResult_single_response(response, segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current, responseSpectrum_calculated_init, title_file, method, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_seg = 0\n",
    "stop_seg = 135\n",
    "nr_run = 1\n",
    "response = None\n",
    "\n",
    "nr_segments = stop_seg - start_seg\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, response, df_motions_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readResults(segment, nr_run, nr_freqs, iterations):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "\n",
    "  df_results_alpha_path = f\"df_results_ALL_combined/alpha_segment_{segment}_fe_{nr_freqs}_mtd_NM_12_param_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_NM_12_param_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_init_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_iter_1.csv\"\n",
    "\n",
    "  # Read the DataFrames from the CSV files\n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "  responseSpectrum_calculated_current = pd.read_csv(responseSpectrum_calculated_path)\n",
    "  responseSpectrum_calculated_init = pd.read_csv(responseSpectrum_calculated_init_path)\n",
    "\n",
    "  return df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init\n",
    "\n",
    "\n",
    "def readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, response, df_motions_segments):\n",
    "  nperseg = 2048\n",
    "  fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg,plot = None, save = False) # this is given in encounter freq\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    #title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_LBFGS'\n",
    "    title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_NM'\n",
    "    responseSpectrum_measured_curr_seg = responseSpectrum_measured[segment]\n",
    "    ic(len(responseSpectrum_measured_curr_seg))\n",
    "    responseSpectrum_measured_curr_seg_sliced, fe_sliced = responseSpectrum_measured_slice(responseSpectrum_measured_curr_seg, fe, step, nr_freqs)\n",
    "\n",
    "    #method = 'L-BFGS-B'\n",
    "    method = 'NM'\n",
    "\n",
    "    plotResponseSpectrumResult_same_segment_initial_CFE_ALL(segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current,responseSpectrum_calculated_init, title_file, method, save = True)\n",
    "\n",
    "    if response != None:\n",
    "      title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_resp_{response}_mtd_NM'\n",
    "      #title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_resp_{response}_mtd_LBFGS'\n",
    "      plotResponseSpectrumResult_single_response(response, segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current, responseSpectrum_calculated_init, title_file, method, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_seg = 0\n",
    "stop_seg = 135\n",
    "nr_run = 1\n",
    "response = None\n",
    "\n",
    "nr_segments = stop_seg - start_seg\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, response, df_motions_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15 parameters!!!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculateResponsSpectrum_own_combined_all_resp(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs):\n",
    "\n",
    "    RspecAbs = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "\n",
    "    timestamp, ws_2d_mu = list(df_ws_segments.items())[segment]\n",
    "    yaw = df_pos_segments_avg[segment]['hdt']  # 1 value per segment. Heading [deg]\n",
    "    U = df_speed_segments_avg[segment]['Speed']  # Speed Over Ground [m/s]\n",
    "\n",
    "    beta_TRF = mu_deg - yaw # Might have to use re_range() here to avoid negative angles\n",
    "    beta_TRF = re_range(beta_TRF) # ensure that beta_TRF is within the range of [0, 360]\n",
    "    beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "\n",
    "    responseSpectrum_measured_curr_seg_sliced, ws_2d_intrp, fe_sliced = interpolateFreq(f0, fe, segment, timestamp,  responseSpectrum_measured, ws_2d_mu, beta_TRF, mu_deg, step, nr_freqs, plot = False)\n",
    "    fe_sliced_rad = 2* np.pi* (fe_sliced)\n",
    "    \n",
    "    responses = ['Roll_rad','Heave',  'Pitch_rad']\n",
    "\n",
    "    Nabla = None   # Volume Deplacement\n",
    "    A_WP = None # Waterplane area\n",
    "\n",
    "    C_B_1 = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "    C_B_2 = Nabla / (alpha[4] * alpha[5] * alpha[6])\n",
    "    C_B_3 = Nabla / (alpha[7] * alpha[8] * alpha[9])\n",
    "\n",
    "    #alpha[3] = A_WP / (alpha[0] * alpha[1])\n",
    "\n",
    "    sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "    sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "    \n",
    "    beta_TRF_sorted = np.sort(beta_TRF)\n",
    "    beta_TRF_rad_sorted = np.sort(beta_TRF_rad)\n",
    "\n",
    "    for response in responses:\n",
    "        \n",
    "        #m0 =  trapezoid(responseSpectrum_measured_ground_truth[response],fe) # variance\n",
    "\n",
    "        # Calculate the CFEs\n",
    "        if response == \"Heave\":\n",
    "            # transfer function for Heave is in units [m/m]\n",
    "            TRF_2d = heaveCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B_1) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "            TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[14]**2) * TRF_roll_tmp**2))\n",
    "            TRF_2d = TRF_2d * alpha[3] # multiply by the gain\n",
    "            \n",
    "        if response == \"Pitch_rad\":\n",
    "            # transfer function for Pitch is in units [rad/m]\n",
    "            #TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_2) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "            TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_2) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "        if response == \"Roll_rad\":\n",
    "            #kappa = alpha[7] - alpha[9]\n",
    "            kappa = alpha[10] - alpha[12]\n",
    "            \n",
    "            #TRF_2d = rollCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_3,alpha[7],alpha[8],kappa,alpha[10],T_N=0)\n",
    "            TRF_2d = rollCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[7],alpha[8],alpha[9],C_B_3,alpha[10],alpha[11],kappa,alpha[13],T_N=0)\n",
    "            TRF_roll_tmp = TRF_2d\n",
    "\n",
    "        #PlotTRF(TRF_2d, freq_intrp_rad, response, beta_TRF)\n",
    "        #TRF_2d = TRF_2d / (2 * np.pi) # convert the transfer function from rad/s to Hz\n",
    "\n",
    "        # for every response: calculate the response spectrum\n",
    "        #dx = beta_TRF_rad[1] - beta_TRF_rad[0]\n",
    "        integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "        \n",
    "        RspecAbs_response = trapezoid(integrand, x = beta_TRF_rad_sorted, axis = 1)\n",
    "        RspecAbs[response] = RspecAbs_response\n",
    "\n",
    "    RspecAbs['segment'] = segment\n",
    "\n",
    "    return RspecAbs, responseSpectrum_measured_curr_seg_sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_generation(ga_instance):\n",
    "    generation = ga_instance.generations_completed\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    average_fitness = np.mean([fitness for fitness in ga_instance.last_generation_fitness if fitness is not None])\n",
    "    worst_fitness = min([fitness for fitness in ga_instance.last_generation_fitness if fitness is not None])\n",
    "    diversity = len(set(ga_instance.last_generation_fitness))\n",
    "\n",
    "    print(f\"Generation = {generation}\")\n",
    "    print(f\"Average Fitness = {average_fitness:.2f}\")\n",
    "    print(f\"Best Fitness = {solution_fitness:.4f}\")\n",
    "    print(f\"Worst Fitness = {worst_fitness:.2f}\")\n",
    "    print(f\"Diversity (unique fitness values) = {diversity}\")\n",
    "\n",
    "last_fitness = 0\n",
    "def callback_generation(ga_instance):\n",
    "    global last_fitness\n",
    "\n",
    "    error = 1/ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1]\n",
    "    print(\"Generation = {generation}\".format(generation=ga_instance.generations_completed))\n",
    "    #print(\"Fitness    = {fitness}\".format(fitness=ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1]))\n",
    "    print(f\"Error     = {error}\")\n",
    "    print(\"Change     = {change}\".format(change=ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1] - last_fitness))\n",
    "    last_fitness = ga_instance.best_solution(pop_fitness=ga_instance.last_generation_fitness)[1]\n",
    "\n",
    "def plotGA(ga_instance, segment, nr_freqs):\n",
    "\n",
    "        #ga_instance.summary()\n",
    "        print(\"plot fitness\")\n",
    "        ga_instance.plot_fitness()\n",
    "\n",
    "        print(\"plot new solution rate\")\n",
    "        #ga_instance.plot_new_solution_rate()\n",
    "\n",
    "        print(\"plot genes\")\n",
    "        #ga_instance.plot_genes(plot_type= \"scatter\", title = f\"gene_plot_segment_{segment}_fe_{nr_freqs}\",save_dir = (f\"Plots/PYGAD/GeneticAlgorithm/gene_plot_scatter_segment_{segment}_fe_{nr_freqs}\"))\n",
    "        ga_instance.plot_genes(plot_type= \"plot\", title = f\"gene_plot_segment_{segment}_fe_{nr_freqs}\",save_dir = (f\"Plots/PYGAD/GeneticAlgorithm/gene_plot_segment_{segment}_fe_{nr_freqs}\"))\n",
    "        # plot boxplot for every parameter\n",
    "        #ga_instance.plot_genes(graph_type=\"boxplot\", save_dir = (f\"Plots/PYGAD/GeneticAlgorithm/gene_plot_boxplot_segment_{segment}_fe_{nr_freqs}\"))\n",
    "\n",
    "\n",
    "        # slightly implements some variation to the initial population so that not all individuals are the same\n",
    "def generate_initial_population(base_solution, population_size, variation_range=0.1):\n",
    "    initial_population = []\n",
    "    for _ in range(population_size):\n",
    "        varied_solution = [np.random.uniform(low=max(0, gene - abs(gene * variation_range)),\n",
    "                                             high=gene + abs(gene * variation_range))\n",
    "                           for gene in base_solution]\n",
    "        initial_population.append(varied_solution)\n",
    "    return initial_population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation_single_segment_for_all_segments_PYGAD_combined_all(constant_data, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, alpha_init_combined, varbound_combined, algorithm_param_pygad, saveInitRS = False):\n",
    "    \n",
    "    f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments = constant_data\n",
    "    count = 0\n",
    "    for segment in range(start_seg, stop_seg):\n",
    "        start_time_seg = time.time()\n",
    "        print(f\"Current segment: {segment}\")\n",
    "\n",
    "        if count != 0:\n",
    "            #print(f\"these are the parameters of previous segment finalist alpha: {alpha}\")\n",
    "            alpha = alpha_final_pygad[:-1] # slice off the last parameter error.\n",
    "        else:\n",
    "            alpha = alpha_init_combined\n",
    "\n",
    "        alpha = alpha_init_combined\n",
    "\n",
    "        segment_data = prepare_segment_data(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "        fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced = segment_data\n",
    "        beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "        fe_sliced_rad = fe_sliced * 2 * np.pi\n",
    "\n",
    "        #RspecAbs_result_init, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own_combined(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    "        RspecAbs_result_init, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own_combined_all_resp(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    "\n",
    "        df_responseSpectrum_calculated_init = pd.DataFrame(RspecAbs_result_init, columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "        df_responseSpectrum_calculated = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "        df_results_alpha = pd.DataFrame(columns=['L_1', 'B_1', 'T_1', 'gain_heave', 'L_2', 'B_2', 'T_2', 'L_3', 'B_3', 'T_3', 'C_WP_2', 'GM_T_2', 'delta_2', 'tau_2', 'd_IMU_2', 'Error'])\n",
    "        sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "        sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "        beta_TRF_sorted = np.sort(beta_TRF)\n",
    "        \n",
    "        error = 0\n",
    "\n",
    "        #print(f\"these are the starting values of alpha: {alpha}\")\n",
    "        count = 0\n",
    "        # Cost function which is to be minimised.\n",
    "        def fitness_func(ga_instance, solution, solution_idx):\n",
    "            nonlocal count\n",
    "            responses = ['Roll_rad','Heave',  'Pitch_rad']\n",
    "            alpha = solution\n",
    "            #print(f\"In cost function. alpha: {alpha}\")\n",
    "            m0 = {} # variance of response spectrum initialized\n",
    "            CF = 0 # cost function initialized\n",
    "            \n",
    "            Nabla = None  # Volume Deplacement\n",
    "            A_WP = None # Waterplane area\n",
    "\n",
    "            C_B_1 = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "            C_B_2 = Nabla / (alpha[4] * alpha[5] * alpha[6])\n",
    "            C_B_3 = Nabla / (alpha[7] * alpha[8] * alpha[9])\n",
    "\n",
    "            sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "            sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "            beta_TRF_sorted = np.sort(beta_TRF)\n",
    "            beta_TRF_rad_sorted = np.sort(beta_TRF_rad)\n",
    "        \n",
    "            for response in responses:\n",
    "                \n",
    "                m0 =  trapezoid(responseSpectrum_measured_curr_seg_sliced[response], fe_sliced) # variance of measured response spectrum. Note: is given in abs freq\n",
    "\n",
    "                # Calculate the CFEs\n",
    "                if response == \"Heave\":\n",
    "                    # transfer function for Heave is in units [m/m]\n",
    "                    TRF_2d = heaveCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B_1) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "                    TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[14]**2) * TRF_roll_tmp**2))\n",
    "                    TRF_2d = TRF_2d * alpha[3] # multiply by the gai\n",
    "                    \n",
    "                if response == \"Pitch_rad\":\n",
    "                    # transfer function for Pitch is in units [rad/m]\n",
    "                    #TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_2) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "                    TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[4],alpha[5],alpha[6],C_B_2) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "                if response == \"Roll_rad\":\n",
    "                    kappa = alpha[10] - alpha[12]\n",
    "                    TRF_2d = rollCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[7],alpha[8],alpha[9],C_B_3,alpha[10],alpha[11],kappa,alpha[13],T_N=0)\n",
    "                    TRF_roll_tmp = TRF_2d\n",
    "\n",
    "                integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "                RspecAbs_response = trapezoid(integrand, x = beta_TRF_rad_sorted, axis = 1)\n",
    "\n",
    "                calculated_spectrum = RspecAbs_response\n",
    "\n",
    "                measured_spectrum = responseSpectrum_measured_curr_seg_sliced[response].values\n",
    "\n",
    "                # Difference between measured and calculated spectra\n",
    "                expression = measured_spectrum - calculated_spectrum\n",
    "                \n",
    "                error = np.sqrt(trapezoid(np.abs(expression), fe_sliced) / m0)\n",
    "                # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "                CF += error\n",
    "    \n",
    "        \n",
    "            return 1/CF\n",
    "        # ---------------after iterating through cost function\n",
    "        # generate init population for new alpha\n",
    "        init_population = generate_initial_population(alpha, population_size = algorithm_param_pygad['population_size'], variation_range=0.1)\n",
    "\n",
    "        ga_instance = pygad.GA(num_generations= algorithm_param_pygad['max_num_iteration'],\n",
    "                               sol_per_pop= algorithm_param_pygad['population_size'],\n",
    "                               num_parents_mating=algorithm_param_pygad['num_parents_mating'],\n",
    "                               fitness_func = fitness_func,\n",
    "                               num_genes=len(alpha),\n",
    "                               gene_type=float,\n",
    "                               gene_space=algorithm_param_pygad['gene_space'], # parent_selection_type=\"rws\",\n",
    "                               mutation_num_genes=algorithm_param_pygad['mutation_num_genes'], #when mutation_type = 'adaptive' has to be set to the following format: [60,30]\n",
    "                               crossover_probability=algorithm_param_pygad['crossover_probability'],\n",
    "                               mutation_type=\"random\",\n",
    "                               mutation_by_replacement=True, # to make sure genes do not go beyond range after mutation. prev true\n",
    "                               crossover_type=algorithm_param_pygad['crossover_type'], \n",
    "                               on_generation=callback_generation,\n",
    "                               save_solutions = True,\n",
    "                               initial_population = init_population,\n",
    "                               stop_criteria = [f\"saturate_{algorithm_param_pygad['max_iteration_without_improv']}\"],\n",
    "                               keep_elitism = algorithm_param_pygad['elit_ratio']\n",
    "                            )\n",
    "        \n",
    "        ga_instance.run()\n",
    "        solution, solution_fitness, solution_idx  = ga_instance.best_solution()\n",
    "        plotGA(ga_instance, segment, nr_freqs)\n",
    "\n",
    "        alpha_final_pygad = solution\n",
    "        alpha_final_pygad = alpha_final_pygad.tolist()\n",
    "        error = 1/solution_fitness\n",
    "\n",
    "        print(\"These are the final parameters after using GA for finding global optimum:\")\n",
    "        print_params_combined(alpha_final_pygad)\n",
    "        print(f\"this is the final error of GA: {error}\")\n",
    "        #RspecAbs_result, _ = calculateResponsSpectrum_own(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha_final, df_ws_segments, fe,step, nr_freqs)\n",
    "        #RspecAbs_result, _ =  calculateResponsSpectrum_own_combined(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha_final_pygad, df_ws_segments, fe,step, nr_freqs)\n",
    "        RspecAbs_result, _ =  calculateResponsSpectrum_own_combined_all_resp(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha_final_pygad, df_ws_segments, fe,step, nr_freqs)\n",
    "\n",
    "        \n",
    "        #RspecAbs_result_rad = RspecAbs_result / (2*np.pi)\n",
    "\n",
    "        print(f\"this was the final error of the cost function {error}\")\n",
    "        # Append results to df_results_alpha\n",
    "        alpha_final_pygad.append(error)\n",
    "\n",
    "    # write results to temporary dfs\n",
    "        alpha_final_df = pd.DataFrame([alpha_final_pygad], columns=df_results_alpha.columns)\n",
    "\n",
    "        df_results_alpha = alpha_final_df\n",
    "        df_responseSpectrum_calculated = RspecAbs_result\n",
    "\n",
    "        # Save results to CSV\n",
    "        savetoCSVAllSegmentsCombined(df_results_alpha, f'alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{algorithm_param_pygad[\"max_num_iteration\"]}_all_responses')\n",
    "        savetoCSVAllSegmentsCombined(df_responseSpectrum_calculated, f'responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{algorithm_param_pygad[\"max_num_iteration\"]}_all_responses')\n",
    "        if saveInitRS:\n",
    "            savetoCSVAllSegmentsCombined(df_responseSpectrum_calculated_init, f'responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_all_responses')\n",
    "\n",
    "        end_time_seg = time.time()\n",
    "        print(f\"Ran successfully. Execution time: {(end_time_seg - start_time_seg)/60} minutes\")\n",
    "\n",
    "        count += 1\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_simulation_multiple_segments_PYGAD_combined_all(alpha_init_combined, varbound_combined, constant_data, \\\n",
    "                                    df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, param_options,saveInitRS = False):\n",
    "\n",
    "    start_time = time.time()\n",
    "    run_simulation_single_segment_for_all_segments_PYGAD_combined_all(constant_data, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, alpha_init_combined, varbound_combined,param_options, saveInitRS)\n",
    "\n",
    "    # Capture the end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Calculate and print the execution time\n",
    "    print(f\"Ran successfully the simulation with {nr_segments} compiled segments.\")\n",
    "    print(f\"Execution time: {(end_time - start_time)/60} minutes\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_motions_segments)\n",
    "def prepare_constant_data(f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments):\n",
    "    return f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nr_freqs = 600\n",
    "#nr_segments = 2\n",
    "#136 max segments. stop seg = 136\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "start_seg = 0\n",
    "stop_seg = 136\n",
    "nr_segments = stop_seg - start_seg\n",
    "\n",
    "\n",
    "alpha_init_combined_all = [L, B, T, gain_heave, L, B, T, L, B, T, C_WP, GM_T, delta, tau, d_IMU]\n",
    "\n",
    "varbound_combined_all = np.array([\n",
    "[(1/2)*L, (3/2)*L],   # L_1 - Params for heave\n",
    "[(1/2)*B, (3/2)*B],   # B_1\n",
    "[(1/2)*T, (3/2)*T],   # T_1\n",
    "[0.1, 7],     # gain heave,\n",
    "[(1/2)*L, (3/2)*L],   # L_2 --  param for roll\n",
    "[(1/4)*B, 2*B],   # B_2\n",
    "[(1/4)*T, 2*T],   # T_2 -- \n",
    "[(1/2)*L, (3/2)*L],   # L_3 --  param for pitch\n",
    "[(1/4)*B, 2*B],   # B_3\n",
    "[(1/4)*T, 2.5*T],   # T_3 --  \n",
    "[(1/2)*C_WP, (3/2)*C_WP],     # C_WP\n",
    "[0.1, 2*B],   # GM_T\n",
    "[0.1, 0.99],     # delta. if it is 1 a singularity occurs\n",
    "[0.1, 1],     # tau\n",
    "[5, 1/2 * L]    # d_IMU\n",
    "])\n",
    "\n",
    "gene_space = [{'low': float(bounds[0]), 'high': float(bounds[1])} for bounds in varbound_combined_all] # create continous voundaries\n",
    "\n",
    "# Set options for the Nelder-Mead optimizer\n",
    "algorithm_param_pygad_4 = {'max_num_iteration':300, # 1000\n",
    "                    'population_size': 50, # can try 150 \n",
    "                    'mutation_num_genes': 1, # prev 0.3\n",
    "                    'elit_ratio': 2, # prev 0.2\n",
    "                    'crossover_probability': 0.7,\n",
    "                    'num_parents_mating': 15, # prev 0.2\n",
    "                    'crossover_type': 'uniform',\n",
    "                    'max_iteration_without_improv': 150, # prev 150\n",
    "                    'gene_space' : gene_space   \n",
    "                    }\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "constant_data = prepare_constant_data(f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments)\n",
    "\n",
    "run_simulation_multiple_segments_PYGAD_combined_all(alpha_init_combined_all, varbound_combined_all, constant_data, \\\n",
    "                                    df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, algorithm_param_pygad_4, saveInitRS = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readResults(segment, nr_run, nr_freqs, iterations):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Define the paths to the files\n",
    "  \n",
    "  df_results_alpha_path = f\"df_results_ALL_combined/alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{iterations}_all_responses_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{iterations}_all_responses_iter_{nr_run}.csv\"\n",
    "  #responseSpectrum_calculated_init_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_iter_1.csv\"\n",
    "  responseSpectrum_calculated_init_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_all_responses_iter_1.csv\"\n",
    "\n",
    "\n",
    "  # Read the DataFrames from the CSV files\n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "  responseSpectrum_calculated_current = pd.read_csv(responseSpectrum_calculated_path)\n",
    "  responseSpectrum_calculated_init = pd.read_csv(responseSpectrum_calculated_init_path)\n",
    "\n",
    "  return df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init\n",
    "\n",
    "\n",
    "def readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, iterations, response, df_motions_segments):\n",
    "  nperseg = 2048\n",
    "  fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg,plot = None, save = False) # this is given in encounter freq\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_runs_{iterations}'\n",
    "\n",
    "    responseSpectrum_measured_curr_seg = responseSpectrum_measured[segment]\n",
    "    ic(len(responseSpectrum_measured_curr_seg))\n",
    "    responseSpectrum_measured_curr_seg_sliced, fe_sliced = responseSpectrum_measured_slice(responseSpectrum_measured_curr_seg, fe, step, nr_freqs)\n",
    "\n",
    "    method = 'PyGAD'\n",
    "\n",
    "    plotResponseSpectrumResult_same_segment_initial_CFE_ALL(segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current,responseSpectrum_calculated_init, title_file, method, save = True)\n",
    "\n",
    "    if response != None:\n",
    "      title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_resp_{response}_mtd_PYGAD_runs_{iterations}'\n",
    "      plotResponseSpectrumResult_single_response(response, segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current, responseSpectrum_calculated_init, title_file, method, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_seg = 0\n",
    "stop_seg = 136\n",
    "nr_run = 1\n",
    "response = None\n",
    "iterations = 100 # max number of iterations\n",
    "\n",
    "nr_segments = stop_seg - start_seg\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, iterations, response, df_motions_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_motions_segments)\n",
    "def prepare_constant_data(f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments):\n",
    "    return f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nr_freqs = 600\n",
    "#nr_segments = 2\n",
    "#136 max segments. stop seg = 136\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "start_seg = 0\n",
    "stop_seg = 136\n",
    "nr_segments = stop_seg - start_seg\n",
    "\n",
    "alpha_init_combined_all = [L, B, T, gain_heave, L, B, T, L, B, T, C_WP, GM_T, delta, tau, d_IMU]\n",
    "\n",
    "varbound_combined_all = np.array([\n",
    "[(1/2)*L, (3/2)*L],   # L_1 - Params for heave\n",
    "[(1/2)*B, (3/2)*B],   # B_1\n",
    "[(1/2)*T, (3/2)*T],   # T_1\n",
    "[0.1, 7],     # gain heave,\n",
    "[(1/2)*L, (3/2)*L],   # L_2 --  param for roll\n",
    "[(1/4)*B, 2*B],   # B_2\n",
    "[(1/4)*T, 2*T],   # T_2 -- \n",
    "[(1/2)*L, (3/2)*L],   # L_3 --  param for pitch\n",
    "[(1/4)*B, 2*B],   # B_3\n",
    "[(1/4)*T, 2.5*T],   # T_3 --  \n",
    "[(1/2)*C_WP, (3/2)*C_WP],     # C_WP\n",
    "[0.1, 2*B],   # GM_T\n",
    "[0.1, 0.99],     # delta. if it is 1 a singularity occurs\n",
    "[0.1, 1],     # tau\n",
    "[5, 1/2 * L]    # d_IMU\n",
    "])\n",
    "\n",
    "gene_space = [{'low': float(bounds[0]), 'high': float(bounds[1])} for bounds in varbound_combined_all] # create continous voundaries\n",
    "\n",
    "# Set options for the Nelder-Mead optimizer\n",
    "algorithm_param_pygad_4 = {'max_num_iteration':300, # 1000\n",
    "                    'population_size': 50, # can try 150 \n",
    "                    'mutation_num_genes': 1, # prev 0.3\n",
    "                    'elit_ratio': 2, # prev 0.2\n",
    "                    'crossover_probability': 0.7,\n",
    "                    'num_parents_mating': 15, # prev 0.2\n",
    "                    'crossover_type': 'uniform',\n",
    "                    'max_iteration_without_improv': 150, # prev 150\n",
    "                    'gene_space' : gene_space   \n",
    "                    }\n",
    "\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "constant_data = prepare_constant_data(f0,fe,mu_deg,step,nr_freqs, start_seg,stop_seg, nr_segments)\n",
    "\n",
    "run_simulation_multiple_segments_PYGAD_combined_all(alpha_init_combined_all, varbound_combined_all, constant_data, \\\n",
    "                                    df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  \\\n",
    "                                    responseSpectrum_measured, algorithm_param_pygad_4, saveInitRS = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readResults(segment, nr_run, nr_freqs, iterations):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "  \n",
    "  # Define the paths to the files\n",
    "\n",
    "  df_results_alpha_path = f\"df_results_ALL_combined/alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{iterations}_all_responses_iter_{nr_run}.csv\"\n",
    "  responseSpectrum_calculated_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{iterations}_all_responses_iter_{nr_run}.csv\"\n",
    "  #responseSpectrum_calculated_init_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_iter_1.csv\"\n",
    "  responseSpectrum_calculated_init_path = f\"responseSpectrumResults_ALL_combined/responseSpectrum_calculated_alpha_init_segment_{segment}_fe_{nr_freqs}_all_responses_iter_1.csv\"\n",
    "\n",
    "\n",
    "  # Read the DataFrames from the CSV files\n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "  responseSpectrum_calculated_current = pd.read_csv(responseSpectrum_calculated_path)\n",
    "  responseSpectrum_calculated_init = pd.read_csv(responseSpectrum_calculated_init_path)\n",
    "\n",
    "  return df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init\n",
    "\n",
    "\n",
    "def readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, iterations, response, df_motions_segments):\n",
    "  nperseg = 2048\n",
    "  fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg,plot = None, save = False) # this is given in encounter freq\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    df_results_alpha_current, responseSpectrum_calculated_current, responseSpectrum_calculated_init = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_runs_{iterations}'\n",
    "\n",
    "    responseSpectrum_measured_curr_seg = responseSpectrum_measured[segment]\n",
    "    ic(len(responseSpectrum_measured_curr_seg))\n",
    "    responseSpectrum_measured_curr_seg_sliced, fe_sliced = responseSpectrum_measured_slice(responseSpectrum_measured_curr_seg, fe, step, nr_freqs)\n",
    "    ic(len(responseSpectrum_measured_curr_seg_sliced))\n",
    "    ic(len(fe_sliced))\n",
    "\n",
    "    method = 'PyGAD'\n",
    "\n",
    "    plotResponseSpectrumResult_same_segment_initial_CFE_ALL(segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current,responseSpectrum_calculated_init, title_file, method, save = True)\n",
    "\n",
    "    if response != None:\n",
    "      title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_resp_{response}_mtd_PYGAD_runs_{iterations}'\n",
    "      plotResponseSpectrumResult_single_response(response, segment, fe_sliced, responseSpectrum_measured_curr_seg_sliced, responseSpectrum_calculated_current, responseSpectrum_calculated_init, title_file, method, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_seg = 0\n",
    "stop_seg = 136\n",
    "nr_run = 1\n",
    "response = None\n",
    "iterations = 100 # max number of iterations\n",
    "\n",
    "nr_segments = stop_seg - start_seg\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "readResultsAll(nr_segments,start_seg, stop_seg, nr_freqs, nr_run, iterations, response, df_motions_segments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of results - Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# simple mean method. \"gjennomsnittet\"\n",
    "def simpleMean(df_results_alpha):\n",
    "   df_results_alpha_excluding_last_column = df_results_alpha.iloc[:, :-1]\n",
    "   \n",
    "   return df_results_alpha_excluding_last_column.mean()\n",
    "\n",
    "def weightedAvg(df_results_alpha, fmax = 2.4):\n",
    "   # raphaels used 1.5. should look at the typical values of the CF\n",
    "   param_sum_numerator = pd.Series([0] * (len(df_results_alpha.columns) - 1), index=df_results_alpha.columns[:-1])\n",
    "   param_sum_denominator = 0\n",
    "\n",
    "   weights = []\n",
    "\n",
    "   segment_below_acc_fitness = []\n",
    "\n",
    "   for segment, row in df_results_alpha.iterrows():\n",
    "      if row['Error'] < fmax:\n",
    "         weight_i = fmax - row['Error']\n",
    "         weights.append(weight_i)\n",
    "      else:\n",
    "         weight_i = 0\n",
    "         segment_below_acc_fitness.append(segment)\n",
    "      \n",
    "      #alpha['Weight'] = weight_i\n",
    "      # update the sums for weighted avg calc\n",
    "      param_sum_numerator += weight_i * row[:-1] # to slice off the last column: error\n",
    "      param_sum_denominator += weight_i\n",
    "   \n",
    "   # Calculate weighted average if denominator is not zero\n",
    "   if param_sum_denominator != 0:\n",
    "      alpha_WA = param_sum_numerator / param_sum_denominator\n",
    "   else:\n",
    "      alpha_WA = pd.Series([None] * len(df_results_alpha.columns[:-1]), index=df_results_alpha.columns[:-1])\n",
    "\n",
    "   return alpha_WA, segment_below_acc_fitness, weights\n",
    "\n",
    "\n",
    "def weighted_std(df, weights):\n",
    "    \"\"\"\n",
    "    Calculate the weighted standard deviation for each column in a DataFrame using\n",
    "    the provided weights.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): DataFrame containing different responses.\n",
    "        weights (list or pd.Series): Weights corresponding to each row in df.\n",
    "\n",
    "    Returns:\n",
    "        pd.Series: Weighted standard deviations for each column in df.\n",
    "    \"\"\"\n",
    "    if len(weights) != len(df):\n",
    "        raise ValueError(\"Length of weights must match the number of rows in DataFrame.\")\n",
    "\n",
    "    mean_weighted = np.average(df, weights=weights, axis=0)\n",
    "    variance = np.average((df - mean_weighted)**2, weights=weights, axis=0)\n",
    "    \n",
    "    N = len(weights)  # Total number of weights assumed to be non-zero\n",
    "\n",
    "    if N > 1:\n",
    "        std_weighted = np.sqrt(N / (N - 1) * variance)\n",
    "    else:\n",
    "        std_weighted = np.zeros_like(variance)  # Avoid division by zero if N <= 1\n",
    "\n",
    "    return pd.Series(std_weighted, index=df.columns)\n",
    "\n",
    "def std_SM(df_results_alpha, alpha_SM):\n",
    "    # Initialize a dictionary to store the standard deviations\n",
    "    std_devs = {}\n",
    "    \n",
    "    # Calculate standard deviations\n",
    "    for column in df_results_alpha.columns[:-1]:  # Exclude the 'Error' column\n",
    "        mean = alpha_SM[column]\n",
    "        squared_diff = (df_results_alpha[column] - mean) ** 2\n",
    "        variance = squared_diff.mean()  # Using mean() to compute variance\n",
    "        std_dev = np.sqrt(variance)\n",
    "        \n",
    "        std_devs[column] = std_dev\n",
    "\n",
    "    return std_devs\n",
    "\n",
    "def calculateResponseSpectrum_entire_run(alpha, df_ws_segments, nr_seg_compile):\n",
    "    responseSpectrum_calculated = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "    alpha = alpha.tolist()\n",
    "    for segment in range(nr_seg_compile):\n",
    "        timestamp, ws = list(df_ws_segments.items())[segment]\n",
    "        responseSpectrum_calculated_tmp = calculateResponseSpectrum(alpha, ws, segment)\n",
    "\n",
    "         # for first iteration: Create df\n",
    "        if segment == 0:\n",
    "            responseSpectrum_calculated = responseSpectrum_calculated_tmp\n",
    "\n",
    "        # else: update existing df\n",
    "        else:\n",
    "            responseSpectrum_calculated = pd.concat([responseSpectrum_calculated, responseSpectrum_calculated_tmp], ignore_index=True)\n",
    "    \n",
    "    return responseSpectrum_calculated\n",
    "\n",
    "def printStatsTable(data):\n",
    "  init_mean, init_std, segment_specific_mean, segment_specific_std, SM_mean, SM_std, WA_mean, WA_std = data\n",
    "\n",
    "# Printing the table similar to Table 5 format\n",
    "  print(\"{:<20} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(\"\", \"Mean [-]\", \"\", \"Standard Deviation [-]\", \"\", \"\", \"\"))\n",
    "  print(\"{:<20} {:<10} {:<10} {:<10} {:<10} {:<10} {:<10}\".format(\"\", \"Vert.\", \"Roll\", \"Pitch\", \"Vert.\", \"Roll\", \"Pitch\"))\n",
    "  print(\"{:<20} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}\".format(\"Actual geometry\", init_mean['Heave'], init_mean['Roll_rad'], init_mean['Pitch_rad'], init_std['Heave'], init_std['Roll_rad'], init_std['Pitch_rad']))\n",
    "  print(\"{:<20} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}\".format(\"Segment-specific\", segment_specific_mean['Heave'], segment_specific_mean['Roll_rad'], segment_specific_mean['Pitch_rad'], segment_specific_std['Heave'], segment_specific_std['Roll_rad'], segment_specific_std['Pitch_rad']))\n",
    "  print(\"{:<20} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}\".format(\"Simple mean\", SM_mean['Heave'], SM_mean['Roll_rad'], SM_mean['Pitch_rad'], SM_std['Heave'], SM_std['Roll_rad'], SM_std['Pitch_rad']))\n",
    "  print(\"{:<20} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f} {:<10.3f}\".format(\"Weighted avg.\", WA_mean['Heave'], WA_mean['Roll_rad'], WA_mean['Pitch_rad'], WA_std['Heave'], WA_std['Roll_rad'], WA_std['Pitch_rad']))\n",
    "\n",
    "def print_params_combined(param_values):\n",
    "    param_names = ['L_1', 'B_1', 'T_1', 'gain_heave', 'L_2', 'B_2', 'T_2', 'C_WP_2', 'GM_T_2', 'delta_2', 'tau_2', 'd_IMU_2']\n",
    "\n",
    "    for name, value in zip(param_names, param_values):\n",
    "        print(f\"{name} = {value:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INclude staistics for all 12 params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateResponsSpectrum_own_init(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs):\n",
    "\n",
    "    RspecAbs = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "\n",
    "    timestamp, ws_2d_mu = list(df_ws_segments.items())[segment]\n",
    "    yaw = df_pos_segments_avg[segment]['hdt']  # 1 value per segment. Heading [deg]\n",
    "    U = df_speed_segments_avg[segment]['Speed']  # Speed Over Ground [m/s]\n",
    "\n",
    "    beta_TRF = mu_deg - yaw # Might have to use re_range() here to avoid negative angles\n",
    "    beta_TRF = re_range(beta_TRF) # ensure that beta_TRF is within the range of [0, 360]\n",
    "    beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "\n",
    "    responseSpectrum_measured_curr_seg_sliced, ws_2d_intrp, fe_sliced = interpolateFreq(f0, fe, segment, timestamp,  responseSpectrum_measured, ws_2d_mu, beta_TRF, mu_deg, step, nr_freqs, plot = False)\n",
    "    fe_sliced_rad = 2* np.pi* (fe_sliced)\n",
    "    \n",
    "    responses = ['Roll_rad','Heave',  'Pitch_rad']\n",
    "\n",
    "    \n",
    "    A_WP = None # Waterplane area\n",
    "    Nabla = None   # Volume Deplacement\n",
    "    C_B = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "    #alpha[3] = A_WP / (alpha[0] * alpha[1])\n",
    "\n",
    "    sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "    sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "    beta_TRF_sorted = np.sort(beta_TRF)\n",
    "    beta_TRF_rad_sorted = np.sort(beta_TRF_rad)\n",
    "\n",
    "    for response in responses:\n",
    "        \n",
    "        #m0 =  trapezoid(responseSpectrum_measured_ground_truth[response],fe) # variance\n",
    "\n",
    "        # Calculate the CFEs\n",
    "        if response == \"Heave\":\n",
    "            # transfer function for Heave is in units [m/m]\n",
    "            TRF_2d = heaveCF(fe_sliced_rad,beta_TRF,U,alpha[0],alpha[1],alpha[2],C_B) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "            TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[7]**2) * TRF_roll_tmp**2))\n",
    "            TRF_2d = TRF_2d * alpha[3]\n",
    "\n",
    "        if response == \"Pitch_rad\":\n",
    "            # transfer function for Pitch is in units [rad/m]\n",
    "            TRF_2d = pitchCF(fe_sliced_rad,beta_TRF,U,alpha[0],alpha[1],alpha[2],C_B) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "        if response == \"Roll_rad\":\n",
    "            kappa = alpha[3] - alpha[5]\n",
    "            \n",
    "            TRF_2d = rollCF(fe_sliced_rad,beta_TRF,U,alpha[0],alpha[1],alpha[2],C_B,alpha[3],alpha[4],kappa,alpha[6],T_N=0)\n",
    "            TRF_roll_tmp = TRF_2d\n",
    "\n",
    "\n",
    "        # for every response: calculate the response spectrum\n",
    "        integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "        RspecAbs_response = trapezoid(integrand, x = beta_TRF_rad_sorted, axis = 1)\n",
    "        RspecAbs[response] = RspecAbs_response\n",
    "\n",
    "    RspecAbs['segment'] = segment\n",
    "\n",
    "    return RspecAbs, responseSpectrum_measured_curr_seg_sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateErrorBetweenSpectra_combined(df_results_alpha_current, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data, alpha_is_series = False):\n",
    "   df_error = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "   #ic(type(df_results_alpha_current))\n",
    "   if isinstance(df_results_alpha_current, pd.Series):\n",
    "      #ic(\"df_results_alpha is a series\")\n",
    "      alpha = df_results_alpha_current.tolist() # it is a nested list, but I want it in 1d, so choose the first segment\n",
    "      #ic(alpha)\n",
    "      #alpha = alpha[:-1] # don't want the included cost function error\n",
    "      #ic(alpha)\n",
    "\n",
    "   elif not isinstance(df_results_alpha_current, list):\n",
    "      #ic(\"df_results_alpha is a pd df\")\n",
    "      alpha = df_results_alpha_current.values.tolist()[0] # it is a nested list, but I want it in 1d, so choose the first segment\n",
    "      #ic(alpha)\n",
    "\n",
    "   else: # df_results_alpha_current is a list -> only alpha\n",
    "      alpha = df_results_alpha_current\n",
    " \n",
    "\n",
    "   error_list = []\n",
    "   m0 = 0\n",
    "\n",
    "   fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced = segment_data\n",
    "\n",
    "\n",
    "   responseSpectrum_calculated_tmp, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own_combined(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    "\n",
    "\n",
    "   responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "\n",
    "   for response in responses:\n",
    "      m0 =  trapezoid(responseSpectrum_measured_curr_seg_sliced[response],fe_sliced) # variance\n",
    "\n",
    "      measured_spectrum = responseSpectrum_measured_curr_seg_sliced[response].values\n",
    "      calculated_spectrum = responseSpectrum_calculated_tmp[response]\n",
    "\n",
    "      expression = measured_spectrum - calculated_spectrum\n",
    "      error = trapezoid(np.abs(expression), fe_sliced) / m0\n",
    "         \n",
    "      # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "      error_list.append(error)\n",
    "\n",
    "\n",
    "   df_error = pd.DataFrame([error_list], columns=df_error.columns)\n",
    "\n",
    "\n",
    "   # after iterating through all segments\n",
    "   return df_error\n",
    "\n",
    "def calculateErrorBetweenSpectra_combined_init(df_results_alpha_current, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data, alpha_is_series = False):\n",
    "   df_error = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "   #ic(type(df_results_alpha_current))\n",
    "   if isinstance(df_results_alpha_current, pd.Series):\n",
    "      #ic(\"df_results_alpha is a series\")\n",
    "      alpha = df_results_alpha_current.tolist() # it is a nested list, but I want it in 1d, so choose the first segment\n",
    "      #ic(alpha)\n",
    "      #alpha = alpha[:-1] # don't want the included cost function error\n",
    "      #ic(alpha)\n",
    "\n",
    "   elif not isinstance(df_results_alpha_current, list):\n",
    "      #ic(\"df_results_alpha is a pd df\")\n",
    "      alpha = df_results_alpha_current.values.tolist()[0] # it is a nested list, but I want it in 1d, so choose the first segment\n",
    "      #ic(alpha)\n",
    "\n",
    "   else: # df_results_alpha_current is a list -> only alpha\n",
    "      alpha = df_results_alpha_current\n",
    "      #ic(alpha)\n",
    "\n",
    "   error_list = []\n",
    "   m0 = 0\n",
    "   #timestamp, ws = list(df_ws_segments.items())[segment]\n",
    "   fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced = segment_data\n",
    "\n",
    "\n",
    "   responseSpectrum_calculated_tmp, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own_init(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    "\n",
    "   responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "   for response in responses:\n",
    "      m0 =  trapezoid(responseSpectrum_measured_curr_seg_sliced[response],fe_sliced) # variance\n",
    "\n",
    "      measured_spectrum = responseSpectrum_measured_curr_seg_sliced[response].values\n",
    "      calculated_spectrum = responseSpectrum_calculated_tmp[response]\n",
    "\n",
    "      expression = measured_spectrum - calculated_spectrum\n",
    "      error = trapezoid(np.abs(expression), fe_sliced) / m0\n",
    "         \n",
    "      # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "      error_list.append(error)\n",
    "\n",
    "   df_error = pd.DataFrame([error_list], columns=df_error.columns)\n",
    "\n",
    "   return df_error\n",
    "    \n",
    "def prepare_segment_data_no_plot(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False):\n",
    "    # This function prepares the data required for each segment\n",
    "    timestamp, ws_2d_mu = list(df_ws_segments.items())[segment]\n",
    "    yaw = df_pos_segments_avg[segment]['hdt']\n",
    "    U = df_speed_segments_avg[segment]['Speed']\n",
    "\n",
    "    beta_TRF = mu_deg - yaw # Might have to use re_range() here to avoid negative angles\n",
    "    beta_TRF = re_range(beta_TRF) # ensure that beta_TRF is within the range of [0, 360]\n",
    "    \n",
    "    responseSpectrum_measured_curr_seg_sliced, ws_2d_intrp, fe_sliced  = interpolateFreq(f0, fe, segment, timestamp,  responseSpectrum_measured, ws_2d_mu, beta_TRF, mu_deg, step, nr_freqs, plot = False)\n",
    "\n",
    "\n",
    "    return fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced\n",
    "\n",
    "def printTableParams(alpha):\n",
    "   # Iterate over the desired order and print the key-value pairs\n",
    "\n",
    "   # Define the desired order of the keys\n",
    "   desired_order = ['L_1', 'B_1', 'T_1', 'gain_heave', 'L_2', 'B_2', 'T_2', 'C_WP_2', 'GM_T_2', 'delta_2', 'tau_2', 'd_IMU_2']\n",
    "   alpha_list = alpha\n",
    "   if (type(alpha) != list):\n",
    "   # Extract the corresponding values from the Series\n",
    "      alpha_list = [alpha[key] for key in desired_order if key in alpha]\n",
    "\n",
    "   # Create a DataFrame with the desired order as the header and values as the second row\n",
    "   df = pd.DataFrame([alpha_list], columns=desired_order)\n",
    "\n",
    "   # Display the DataFrame as a table\n",
    "   print(df)\n",
    "\n",
    "def printTableParams_with_error(alpha):\n",
    "   # Iterate over the desired order and print the key-value pairs\n",
    "\n",
    "   # Define the desired order of the keys\n",
    "   desired_order = ['L_1', 'B_1', 'T_1', 'gain_heave', 'L_2', 'B_2', 'T_2', 'C_WP_2', 'GM_T_2', 'delta_2', 'tau_2', 'd_IMU_2', 'Error']\n",
    "   alpha_list = alpha\n",
    "   if (type(alpha) != list):\n",
    "   # Extract the corresponding values from the Series\n",
    "      alpha_list = [alpha[key] for key in desired_order if key in alpha]\n",
    "\n",
    "   # Create a DataFrame with the desired order as the header and values as the second row\n",
    "   df = pd.DataFrame([alpha_list], columns=desired_order)\n",
    "\n",
    "   # Display the DataFrame as a table\n",
    "   print(df)\n",
    "\n",
    "def normalize_parameters(df, alpha_init_combined):\n",
    "   \"\"\"\n",
    "   Normalizes specified parameters in the DataFrame based on actual physical values.\n",
    "\n",
    "   Parameters:\n",
    "      df (pd.DataFrame): DataFrame containing the data.\n",
    "      params (list of tuples): Each tuple contains the column name to normalize and the actual value.\n",
    "   \"\"\"\n",
    "\n",
    "   params_to_normalize = [\n",
    "      ('L_1', alpha_init_combined[0]),\n",
    "      ('B_1', alpha_init_combined[1]),\n",
    "      ('T_1', alpha_init_combined[2]),\n",
    "      ('L_2', alpha_init_combined[0]),\n",
    "      ('B_2', alpha_init_combined[1]),\n",
    "      ('T_2', alpha_init_combined[2])\n",
    "      ]\n",
    "\n",
    "   for param, actual in params_to_normalize:\n",
    "      normalized_col_name = f'{param}_n'  # Generates new column name\n",
    "      df[normalized_col_name] = df[param] / actual\n",
    "\n",
    "   return df\n",
    "\n",
    "def plot_tuning_parameters(df, parameters, alpha_init):\n",
    "   \"\"\"\n",
    "   Plots boxplots for tuning parameters in a DataFrame.\n",
    "\n",
    "   Parameters:\n",
    "      df (pd.DataFrame): The DataFrame containing the data.\n",
    "      parameters (list): A list of column names to plot.\n",
    "   \"\"\"\n",
    "\n",
    "   # Set up the figure with subplots\n",
    "   fig, axes = plt.subplots(nrows=len(parameters), ncols=1, figsize=(10, 2 * len(parameters)), constrained_layout=True)\n",
    "\n",
    "   for i, param in enumerate(parameters):\n",
    "      # Create boxplot for each parameter\n",
    "      axes[i].boxplot(df[param].dropna(), vert=False, patch_artist=True, showfliers=True,\n",
    "                     flierprops={'marker': 'o', 'color': 'black', 'markersize': 5},\n",
    "                     boxprops={'facecolor': 'white', 'color': 'black'},\n",
    "                     medianprops={'color': 'orange'},\n",
    "                     whiskerprops={'color': 'black', 'linestyle': '--'},\n",
    "                     capprops={'color': 'black'})\n",
    "      \n",
    "      # Adding titles and removing y ticks as we only have one box per plot\n",
    "      axes[i].set_title(param)\n",
    "      axes[i].set_yticks([])\n",
    "\n",
    "   # Display the plot\n",
    "   plt.show()\n",
    "\n",
    "def plot_tuning_parameters_grouped(df, grouped_params):\n",
    "   \"\"\"\n",
    "   Plots grouped boxplots for tuning parameters in a DataFrame. Each group of parameters\n",
    "   will be plotted horizontally in each subfigure.\n",
    "\n",
    "   Parameters:\n",
    "      df (pd.DataFrame): The DataFrame containing the data.\n",
    "      grouped_params (list of lists): A list where each sublist contains the names of three columns to plot together.\n",
    "   \"\"\"\n",
    "   # Calculate the number of rows needed\n",
    "   num_rows = len(grouped_params)\n",
    "   \n",
    "   # Set up the figure with subplots\n",
    "   fig, axes = plt.subplots(nrows=num_rows, ncols=1, figsize=(15, 4 * num_rows), constrained_layout=True)\n",
    "\n",
    "   # Check if there's only one row of subplots (axes will not be an array if only one subplot)\n",
    "   if num_rows == 1:\n",
    "      axes = [axes]  # Make it iterable\n",
    "\n",
    "   # Translate parameters to LaTeX-friendly names\n",
    "   latex_dict = {\n",
    "      'delta': r'\\delta',\n",
    "      'tau': r'\\tau'\n",
    "   }\n",
    "\n",
    "   for i, params in enumerate(grouped_params):\n",
    "   # Apply LaTeX formatting to each parameter name\n",
    "      formatted_params = []\n",
    "      for param in params:\n",
    "         if 'delta' in param:\n",
    "               param = r'\\delta'\n",
    "         elif 'tau' in param:\n",
    "               param = r'\\tau'\n",
    "         elif '_n' in param:\n",
    "               param = param.replace('_n', '')\n",
    "         elif '_' in param and '{' not in param and '}' not in param:\n",
    "               parts = param.split('_')\n",
    "               param = f'{parts[0]}_{{{parts[1]}}}'\n",
    "         formatted_params.append(f'${param}$')\n",
    "\n",
    "\n",
    "      label_fontsize = 16\n",
    "      #formatted_params = [fr'${latex_dict.get(param, param)}$' for param in params]\n",
    "\n",
    "      data_to_plot = [df[param].dropna() for param in params if param in df]\n",
    "      # Check if the data list is not empty\n",
    "      if data_to_plot:\n",
    "         axes[i].boxplot(data_to_plot, vert=False, patch_artist=True, showfliers=True,\n",
    "                           flierprops={'marker': 'o', 'color': 'black', 'markersize': 5},\n",
    "                           boxprops={'facecolor': 'white', 'color': 'black'},\n",
    "                           medianprops={'color': 'orange'},\n",
    "                           whiskerprops={'color': 'black', 'linestyle': '--'},\n",
    "                           capprops={'color': 'black'})\n",
    "      \n",
    "         # Set the y-tick labels to the parameter names, and ensure there's a title or label\n",
    "         #formatted_params = [fr'${param}$' for param in params]\n",
    "         #formatted_params = [param.replace('$delta$', '$\\delta$').replace('$tau$', '$\\tau$') for param in params]\n",
    "         axes[i].set_yticklabels(formatted_params, fontsize=label_fontsize)\n",
    "         axes[i].set_xlabel('[-]', fontsize=label_fontsize)\n",
    "         directory = 'Plots/Statistics/Boxplots'\n",
    "         fig.savefig(f\"{directory}/Group_{i+1}.svg\", format='svg', bbox_inches='tight')\n",
    "\n",
    "   # Show the plot\n",
    "   plt.show()\n",
    "\n",
    "     \n",
    "\n",
    "def plot_tuning_parameters_grouped(df, grouped_params, output_directory, label_fontsize=14):\n",
    "   \"\"\"\n",
    "   Plots grouped boxplots for tuning parameters in a DataFrame. Each group of parameters\n",
    "   will be plotted and saved individually with LaTeX formatting for all labels,\n",
    "   handling double subscripts and normalized variable names.\n",
    "\n",
    "   Parameters:\n",
    "      df (pd.DataFrame): The DataFrame containing the data.\n",
    "      grouped_params (list of lists): Each sublist contains names of three columns to plot together.\n",
    "      output_directory (str): Directory where the plots will be saved.\n",
    "      label_fontsize (int): Font size for x and y labels.\n",
    "   \"\"\"\n",
    "   # Create the output directory if it doesn't exist\n",
    "   if not os.path.exists(output_directory):\n",
    "      os.makedirs(output_directory)\n",
    "\n",
    "   for i, params in enumerate(grouped_params):\n",
    "      # Create a new figure for each group\n",
    "      fig, ax = plt.subplots(figsize=(8, 4))\n",
    "      xlabel = '[-]'\n",
    "\n",
    "      # Apply LaTeX formatting to each parameter name\n",
    "      formatted_params = []\n",
    "      for param in params:\n",
    "            #original_param = param\n",
    "\n",
    "         # Specific handling for parameters like 'd_IMU_2'\n",
    "         if param.startswith('d_IMU_'):\n",
    "            param = 'd_{IMU}'  # Remove numerical suffix and format correctly\n",
    "\n",
    "         elif 'delta' in param:\n",
    "               param = r'\\delta'\n",
    "         elif 'tau' in param:\n",
    "               param = r'\\tau'\n",
    "         elif 'GM' in param:\n",
    "               print(\"in GM\")\n",
    "               param = 'GM_T'\n",
    "               xlabel = r'$[m]$'\n",
    "         elif '_n' in param:\n",
    "               param = param.replace('_n', '')\n",
    "         elif '_' in param and '{' not in param and '}' not in param:\n",
    "               parts = param.split('_')\n",
    "               param = f'{parts[0]}_{{{parts[1]}}}'\n",
    "         formatted_params.append(f'${param}$')\n",
    "\n",
    "      # Prepare data to plot\n",
    "      data_to_plot = [df[param].dropna() for param in params if param in df]\n",
    "      #data_to_plot = [df[original_param].dropna() for original_param in params if original_param in df.columns]\n",
    "\n",
    "\n",
    "      if data_to_plot:\n",
    "         # Plotting the boxplot\n",
    "         box = ax.boxplot(data_to_plot, vert=False, patch_artist=True, showfliers=True,\n",
    "                           flierprops={'marker': 'o', 'color': 'black', 'markersize': 5},\n",
    "                           boxprops={'facecolor': 'white', 'color': 'black'},\n",
    "                           medianprops={'color': 'orange'},\n",
    "                           whiskerprops={'color': 'black', 'linestyle': '--'},\n",
    "                           capprops={'color': 'black'})\n",
    "         # Setting custom y-tick labels\n",
    "         ax.set_yticklabels(formatted_params, fontsize=label_fontsize)\n",
    "         ax.set_xlabel(xlabel, fontsize=label_fontsize)\n",
    "\n",
    "         # Save the individual figure\n",
    "         fig.savefig(f\"{output_directory}/Group_{i+1}.svg\", format='svg', bbox_inches='tight')\n",
    "\n",
    "         # Save the individual figure\n",
    "       # Close the figure to free up memory\n",
    "      plt.close(fig)\n",
    "      #plt.show()\n",
    "       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------NEW CODE--------------------------------------------\n",
    "\n",
    "def readResults(segment, nr_run, nr_freqs, iterations):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "\n",
    "  # 12 param solution inc d imu\n",
    "  df_results_alpha_path = f\"df_results_ALL_combined/alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{iterations}_same_init_alpha_inc_d_IMU_iter_{nr_run}.csv\"\n",
    "\n",
    "\n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "\n",
    "\n",
    "  return df_results_alpha_current\n",
    "\n",
    "def readResultsAll_including_statistics_combined(iterations,start_seg, stop_seg, nr_freqs, nr_run, df_motions_segments, alpha_init, alpha_init_8_param, fmax):\n",
    "  nperseg = 2048\n",
    "  fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg,plot = None, save = False) # this is given in encounter freq\n",
    "\n",
    "  df_error = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_results_alpha = pd.DataFrame(columns=['L_1', 'B_1', 'T_1', 'gain_heave', 'L_2', 'B_2', 'T_2', 'C_WP_2', 'GM_T_2', 'delta_2', 'tau_2', 'd_IMU_2', 'Error'])\n",
    " \n",
    "  print(f\"after defining df_results_alpha\")\n",
    "\n",
    "  print(df_results_alpha)\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    #ic(segment)\n",
    "\n",
    "    segment_data = prepare_segment_data_no_plot(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "\n",
    "    df_results_alpha_current  = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    # calculates the error for each response for the best resulting parameters of each segment\n",
    "    df_error_current = calculateErrorBetweenSpectra_combined(df_results_alpha_current, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "\n",
    "    if segment == 0:\n",
    "      df_error = pd.DataFrame(df_error_current, columns=df_error.columns)\n",
    "      df_results_alpha = pd.DataFrame(df_results_alpha_current, columns=df_results_alpha.columns)\n",
    "    else:\n",
    "      df_error = pd.concat([df_error, df_error_current], ignore_index=True)\n",
    "      df_results_alpha = pd.concat([df_results_alpha, df_results_alpha_current], ignore_index=True)\n",
    "    \n",
    "  # Single Mean\n",
    "  alpha_SM = simpleMean(df_results_alpha)\n",
    "  # Weighted Averaged. Is a dictionar\n",
    "  alpha_WA, segments_below_acc_fitness, weights = weightedAvg(df_results_alpha, fmax = fmax)\n",
    "\n",
    "\n",
    "\n",
    "  print(\"alpha Single Mean\")\n",
    "  printTableParams(alpha_SM)\n",
    "\n",
    "  print(\"alpha Weighted average\")\n",
    "  printTableParams(alpha_WA)\n",
    "  #nr_segments = stop_seg - start_seg\n",
    "  #nr_nonzero_weights =  nr_segments - len(segments_below_acc_fitness)\n",
    "\n",
    "  df_error_SM = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_WA = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_WA_std = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_init = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    #ic(segment)\n",
    "    segment_data = prepare_segment_data_no_plot(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "\n",
    "    df_results_alpha_current  = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    # calculates the error for each response for the best resulting parameters of each segment\n",
    "    df_error_current_SM = calculateErrorBetweenSpectra_combined(alpha_SM, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "    df_error_current_WA = calculateErrorBetweenSpectra_combined(alpha_WA, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "    df_error_current_init = calculateErrorBetweenSpectra_combined_init(alpha_init_8_param, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data) # for calculating \n",
    "\n",
    "    ###\n",
    "    if segment == 0:\n",
    "      df_error_SM = pd.DataFrame(df_error_current_SM, columns=df_error_SM.columns)\n",
    "      df_error_WA = pd.DataFrame(df_error_current_WA, columns=df_error_WA.columns)\n",
    "      df_error_init = pd.DataFrame(df_error_current_init, columns=df_error_init.columns)\n",
    "\n",
    "    else:\n",
    "      df_error_SM = pd.concat([df_error_SM, df_error_current_SM], ignore_index=True)\n",
    "      df_error_WA = pd.concat([df_error_WA, df_error_current_WA], ignore_index=True)\n",
    "      df_error_init = pd.concat([df_error_init, df_error_current_init], ignore_index=True)\n",
    "    ###\n",
    "\n",
    "    if segment not in segments_below_acc_fitness:\n",
    "\n",
    "      if df_error_WA_std.empty and df_error_WA_std.isna().all().all():\n",
    "        df_error_WA_std = pd.DataFrame(df_error_current_WA, columns=df_error_WA_std.columns)\n",
    "\n",
    "      else:\n",
    "        df_error_WA_std = pd.concat([df_error_WA_std, df_error_current_WA], ignore_index=True)\n",
    "\n",
    "  init_mean = df_error_init.mean()\n",
    "  init_std = df_error_init.std()    \n",
    "\n",
    "  segment_specific_tuning_mean = df_error.mean()\n",
    "  segment_specific_tuning_std = df_error.std()\n",
    "\n",
    "  SM_mean = df_error_SM.mean()\n",
    "  SM_std = df_error_SM.std()\n",
    "\n",
    "  WA_mean = df_error_WA.mean()\n",
    "\n",
    "  WA_std = df_error_WA_std.std()\n",
    " \n",
    "\n",
    "  WA_std_own_func = weighted_std(df_error_WA_std, weights)\n",
    "  ic(WA_std_own_func)\n",
    "  \n",
    "\n",
    "  data = init_mean, init_std, segment_specific_tuning_mean, segment_specific_tuning_std, SM_mean, SM_std, WA_mean, WA_std\n",
    "\n",
    "  printStatsTable(data)\n",
    "\n",
    "  data_w_own_std = init_mean, init_std, segment_specific_tuning_mean, segment_specific_tuning_std, SM_mean, SM_std, WA_mean, WA_std_own_func\n",
    "  printStatsTable(data_w_own_std)\n",
    "\n",
    "  title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD'\n",
    "\n",
    "\n",
    "  grouped_params = [\n",
    "    ['L_1_n', 'B_1_n', 'T_1_n'],\n",
    "    ['gain_heave', 'GM_T_2'],\n",
    "    ['L_2_n', 'B_2_n', 'T_2_n'],\n",
    "    ['C_WP_2', 'delta_2', 'tau_2'],\n",
    "    # Add more groups as needed\n",
    "  ]\n",
    "\n",
    "  directory = 'Plots/Statistics/Boxplots'\n",
    "\n",
    "  plot_tuning_parameters_grouped(df_results_alpha, grouped_params, directory, label_fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init_8_param = [L, B, T, C_WP, GM_T, delta, tau, d_IMU] # parameters which are to be optimized\n",
    "alpha_init_combined = [L, B, T, gain_heave, L, B, T, C_WP, GM_T, delta, tau, d_IMU]\n",
    "\n",
    "nr_run = 1 # test that 23 and 24 is the same\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "\n",
    "start_seg = 0\n",
    "stop_seg = 136\n",
    "nr_segments = stop_seg - start_seg\n",
    "\n",
    "#param_int = 4\n",
    "iterations = 100\n",
    "\n",
    "fmax = 2.0 # PYGAD 100 iters\n",
    "#fmax = 2.35 #LBFGSB\n",
    "#fmax = 2.35 #NM\n",
    "\n",
    "readResultsAll_including_statistics_combined(iterations,start_seg, stop_seg, nr_freqs, nr_run, df_motions_segments, alpha_init_combined, alpha_init_8_param, fmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9 param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateResponsSpectrum_own_heave(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs):\n",
    "\n",
    "    RspecAbs = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "\n",
    "    timestamp, ws_2d_mu = list(df_ws_segments.items())[segment]\n",
    "    yaw = df_pos_segments_avg[segment]['hdt']  # 1 value per segment. Heading [deg]\n",
    "    U = df_speed_segments_avg[segment]['Speed']  # Speed Over Ground [m/s]\n",
    "\n",
    "    beta_TRF = mu_deg - yaw # Might have to use re_range() here to avoid negative angles\n",
    "    beta_TRF = re_range(beta_TRF) # ensure that beta_TRF is within the range of [0, 360]\n",
    "    beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "    responseSpectrum_measured_curr_seg_sliced, ws_2d_intrp, fe_sliced = interpolateFreq(f0, fe, segment, timestamp,  responseSpectrum_measured, ws_2d_mu, beta_TRF, mu_deg, step, nr_freqs, plot = False)\n",
    "    fe_sliced_rad = 2* np.pi* (fe_sliced)\n",
    "    \n",
    "    responses = ['Roll_rad','Heave',  'Pitch_rad']\n",
    "\n",
    "    Nabla = None   # Volume Deplacement\n",
    "    A_WP = None # Waterplane area\n",
    "\n",
    "    C_B = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "  \n",
    "\n",
    "    sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "    sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "    \n",
    "    beta_TRF_sorted = np.sort(beta_TRF)\n",
    "\n",
    "    beta_TRF_rad_sorted = np.sort(beta_TRF_rad)\n",
    "\n",
    "    for response in responses:\n",
    "        \n",
    "        #m0 =  trapezoid(responseSpectrum_measured_ground_truth[response],fe) # variance\n",
    "\n",
    "        # Calculate the CFEs\n",
    "        if response == \"Heave\":\n",
    "            # transfer function for Heave is in units [m/m]\n",
    "            TRF_2d = heaveCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "            TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[7]**2) * TRF_roll_tmp**2))\n",
    "            TRF_2d = TRF_2d * alpha[8] # multiply by the gain\n",
    "            \n",
    "        if response == \"Pitch_rad\":\n",
    "            # transfer function for Pitch is in units [rad/m]\n",
    "            TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "        if response == \"Roll_rad\":\n",
    "            kappa = alpha[3] - alpha[5]\n",
    "            \n",
    "            TRF_2d = rollCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B,alpha[3],alpha[4],kappa,alpha[6],T_N=0)\n",
    "            TRF_roll_tmp = TRF_2d\n",
    "\n",
    "        #PlotTRF(TRF_2d, freq_intrp_rad, response, beta_TRF)\n",
    "        #TRF_2d = TRF_2d / (2 * np.pi) # convert the transfer function from rad/s to Hz\n",
    "\n",
    "        # for every response: calculate the response spectrum\n",
    "        #dx = beta_TRF_rad[1] - beta_TRF_rad[0]\n",
    "        integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "        \n",
    "        RspecAbs_response = trapezoid(integrand, x = beta_TRF_rad_sorted, axis = 1)\n",
    "        RspecAbs[response] = RspecAbs_response\n",
    "\n",
    "    RspecAbs['segment'] = segment\n",
    "\n",
    "    return RspecAbs, responseSpectrum_measured_curr_seg_sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateErrorBetweenSpectra_heave(df_results_alpha_current, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data, alpha_is_series = False):\n",
    "   df_error = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "   #ic(type(df_results_alpha_current))\n",
    "   if isinstance(df_results_alpha_current, pd.Series):\n",
    "      #ic(\"df_results_alpha is a series\")\n",
    "      alpha = df_results_alpha_current.tolist() # it is a nested list, but I want it in 1d, so choose the first segment\n",
    "   \n",
    "\n",
    "   elif not isinstance(df_results_alpha_current, list):\n",
    "      #ic(\"df_results_alpha is a pd df\")\n",
    "      alpha = df_results_alpha_current.values.tolist()[0] # it is a nested list, but I want it in 1d, so choose the first segment\n",
    "      #ic(alpha)\n",
    "\n",
    "   else: # df_results_alpha_current is a list -> only alpha\n",
    "      alpha = df_results_alpha_current\n",
    "      #ic(alpha)\n",
    "\n",
    "   error_list = []\n",
    "   m0 = 0\n",
    "\n",
    "   fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced = segment_data\n",
    "\n",
    "   responseSpectrum_calculated_tmp, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own_heave(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    "   \n",
    "   responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "   for response in responses:\n",
    "      m0 =  trapezoid(responseSpectrum_measured_curr_seg_sliced[response],fe_sliced) # variance\n",
    "\n",
    "      measured_spectrum = responseSpectrum_measured_curr_seg_sliced[response].values\n",
    "      calculated_spectrum = responseSpectrum_calculated_tmp[response]\n",
    "\n",
    "      expression = measured_spectrum - calculated_spectrum\n",
    "      error = trapezoid(np.abs(expression), fe_sliced) / m0\n",
    "         \n",
    "      # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "      error_list.append(error)\n",
    "      \n",
    "   df_error = pd.DataFrame([error_list], columns=df_error.columns)\n",
    "\n",
    "   return df_error\n",
    "\n",
    "\n",
    "def normalize_parameters(df, alpha_init_heave):\n",
    "   \"\"\"\n",
    "   Normalizes specified parameters in the DataFrame based on actual physical values.\n",
    "\n",
    "   Parameters:\n",
    "      df (pd.DataFrame): DataFrame containing the data.\n",
    "      params (list of tuples): Each tuple contains the column name to normalize and the actual value.\n",
    "   \"\"\"\n",
    "\n",
    "   params_to_normalize = [\n",
    "      ('L', alpha_init_heave[0]),\n",
    "      ('B', alpha_init_heave[1]),\n",
    "      ('T', alpha_init_heave[2]),\n",
    "      ]\n",
    "\n",
    "   for param, actual in params_to_normalize:\n",
    "      normalized_col_name = f'{param}_n'  # Generates new column name\n",
    "      df[normalized_col_name] = df[param] / actual\n",
    "\n",
    "   return df\n",
    "\n",
    "def plot_tuning_parameters_grouped(df, grouped_params, output_directory, label_fontsize=14):\n",
    "   \"\"\"\n",
    "   Plots grouped boxplots for tuning parameters in a DataFrame. Each group of parameters\n",
    "   will be plotted and saved individually with LaTeX formatting for all labels,\n",
    "   handling double subscripts and normalized variable names.\n",
    "\n",
    "   Parameters:\n",
    "      df (pd.DataFrame): The DataFrame containing the data.\n",
    "      grouped_params (list of lists): Each sublist contains names of three columns to plot together.\n",
    "      output_directory (str): Directory where the plots will be saved.\n",
    "      label_fontsize (int): Font size for x and y labels.\n",
    "   \"\"\"\n",
    "   # Create the output directory if it doesn't exist\n",
    "   if not os.path.exists(output_directory):\n",
    "      os.makedirs(output_directory)\n",
    "\n",
    "   for i, params in enumerate(grouped_params):\n",
    "      # Create a new figure for each group\n",
    "      fig, ax = plt.subplots(figsize=(8, 4))\n",
    "      xlabel = '[-]'\n",
    "\n",
    "      # Apply LaTeX formatting to each parameter name\n",
    "      formatted_params = []\n",
    "      for param in params:\n",
    "            #original_param = param\n",
    "\n",
    "         # Specific handling for parameters like 'd_IMU_2'\n",
    "         if param.startswith('d_IMU_'):\n",
    "            param = 'd_{IMU}'  # Remove numerical suffix and format correctly\n",
    "\n",
    "         elif 'delta' in param:\n",
    "               param = r'\\delta'\n",
    "         elif 'tau' in param:\n",
    "               param = r'\\tau'\n",
    "         elif 'GM' in param:\n",
    "               print(\"in GM\")\n",
    "               param = 'GM_T'\n",
    "               xlabel = r'$[m]$'\n",
    "         elif '_n' in param:\n",
    "               param = param.replace('_n', '')\n",
    "         elif '_' in param and '{' not in param and '}' not in param:\n",
    "               parts = param.split('_')\n",
    "               param = f'{parts[0]}_{{{parts[1]}}}'\n",
    "         formatted_params.append(f'${param}$')\n",
    "\n",
    "      # Prepare data to plot\n",
    "      data_to_plot = [df[param].dropna() for param in params if param in df]\n",
    "      #data_to_plot = [df[original_param].dropna() for original_param in params if original_param in df.columns]\n",
    "\n",
    "\n",
    "      if data_to_plot:\n",
    "         # Plotting the boxplot\n",
    "         box = ax.boxplot(data_to_plot, vert=False, patch_artist=True, showfliers=True,\n",
    "                           flierprops={'marker': 'o', 'color': 'black', 'markersize': 5},\n",
    "                           boxprops={'facecolor': 'white', 'color': 'black'},\n",
    "                           medianprops={'color': 'orange'},\n",
    "                           whiskerprops={'color': 'black', 'linestyle': '--'},\n",
    "                           capprops={'color': 'black'})\n",
    "         # Setting custom y-tick labels\n",
    "         ax.set_yticklabels(formatted_params, fontsize=label_fontsize)\n",
    "         ax.set_xlabel(xlabel, fontsize=label_fontsize)\n",
    "\n",
    "         # Save the individual figure\n",
    "         fig.savefig(f\"{output_directory}/Group_{i+1}.svg\", format='svg', bbox_inches='tight')\n",
    "\n",
    "         # Save the individual figure\n",
    "       # Close the figure to free up memory\n",
    "      plt.close(fig)\n",
    "      #plt.show()\n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------NEW CODE--------------------------------------------\n",
    "\n",
    "def readResults(segment, nr_run, nr_freqs, iterations):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "  \n",
    "  df_results_alpha_path = f\"df_results_ALL/alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_9_param_runs_{iterations}_inc_d_IMU_iter_{nr_run}.csv\"\n",
    "  \n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "\n",
    "\n",
    "  return df_results_alpha_current\n",
    "\n",
    "def readResultsAll_including_statistics_heave(iterations,start_seg, stop_seg, nr_freqs, nr_run, df_motions_segments, alpha_init, alpha_init_8_param, fmax):\n",
    "  nperseg = 2048\n",
    "  fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg,plot = None, save = False) # this is given in encounter freq\n",
    "\n",
    "  df_error = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_results_alpha = pd.DataFrame(columns=['L', 'B', 'T', 'C_WP', 'GM_T', 'delta', 'tau', 'd_IMU', 'gain_heave' ,'Error'])\n",
    "\n",
    "  \n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    #ic(segment)\n",
    "\n",
    "    segment_data = prepare_segment_data_no_plot(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "\n",
    "    df_results_alpha_current  = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    # calculates the error for each response for the best resulting parameters of each segment\n",
    "    df_error_current = calculateErrorBetweenSpectra_heave(df_results_alpha_current, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "\n",
    "    if segment == 0:\n",
    "      df_error = pd.DataFrame(df_error_current, columns=df_error.columns)\n",
    "      df_results_alpha = pd.DataFrame(df_results_alpha_current, columns=df_results_alpha.columns)\n",
    "    else:\n",
    "      df_error = pd.concat([df_error, df_error_current], ignore_index=True)\n",
    "      df_results_alpha = pd.concat([df_results_alpha, df_results_alpha_current], ignore_index=True)\n",
    "    \n",
    "  # Single Mean\n",
    "  alpha_SM = simpleMean(df_results_alpha)\n",
    "  # Weighted Averaged. Is a dictionar\n",
    "  alpha_WA, segments_below_acc_fitness, weights = weightedAvg(df_results_alpha, fmax = fmax)\n",
    "\n",
    "  df_error_SM = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_WA = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_WA_std = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_init = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    #ic(segment)\n",
    "    segment_data = prepare_segment_data_no_plot(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "\n",
    "    df_results_alpha_current  = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    # calculates the error for each response for the best resulting parameters of each segment\n",
    "    df_error_current_SM = calculateErrorBetweenSpectra_heave(alpha_SM, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "    df_error_current_WA = calculateErrorBetweenSpectra_heave(alpha_WA, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "    df_error_current_init = calculateErrorBetweenSpectra_combined_init(alpha_init_8_param, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data) # for calculating \n",
    "    # this final works uses 8 param solution. \n",
    "    ###\n",
    "    if segment == 0:\n",
    "      df_error_SM = pd.DataFrame(df_error_current_SM, columns=df_error_SM.columns)\n",
    "      df_error_WA = pd.DataFrame(df_error_current_WA, columns=df_error_WA.columns)\n",
    "      df_error_init = pd.DataFrame(df_error_current_init, columns=df_error_init.columns)\n",
    "\n",
    "    else:\n",
    "      df_error_SM = pd.concat([df_error_SM, df_error_current_SM], ignore_index=True)\n",
    "      df_error_WA = pd.concat([df_error_WA, df_error_current_WA], ignore_index=True)\n",
    "      df_error_init = pd.concat([df_error_init, df_error_current_init], ignore_index=True)\n",
    "    ###\n",
    "\n",
    "    if segment not in segments_below_acc_fitness:\n",
    "\n",
    "      if df_error_WA_std.empty and df_error_WA_std.isna().all().all():\n",
    "        df_error_WA_std = pd.DataFrame(df_error_current_WA, columns=df_error_WA_std.columns)\n",
    "\n",
    "      else:\n",
    "        df_error_WA_std = pd.concat([df_error_WA_std, df_error_current_WA], ignore_index=True)\n",
    "\n",
    "  init_mean = df_error_init.mean()\n",
    "  init_std = df_error_init.std()    \n",
    "\n",
    "  segment_specific_tuning_mean = df_error.mean()\n",
    "  segment_specific_tuning_std = df_error.std()\n",
    "\n",
    "  SM_mean = df_error_SM.mean()\n",
    "  SM_std = df_error_SM.std()\n",
    "\n",
    "  WA_mean = df_error_WA.mean()\n",
    "  WA_std = df_error_WA_std.std()\n",
    "\n",
    "\n",
    "  WA_std_own_func = weighted_std(df_error_WA_std, weights)\n",
    "  ic(WA_std_own_func)\n",
    "  \n",
    "\n",
    "  data = init_mean, init_std, segment_specific_tuning_mean, segment_specific_tuning_std, SM_mean, SM_std, WA_mean, WA_std\n",
    "\n",
    "  printStatsTable(data)\n",
    "\n",
    "  data_w_own_std = init_mean, init_std, segment_specific_tuning_mean, segment_specific_tuning_std, SM_mean, SM_std, WA_mean, WA_std_own_func\n",
    "  printStatsTable(data_w_own_std)\n",
    "\n",
    "  title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD'\n",
    "\n",
    "  df_results_alpha_norm = normalize_parameters(df_results_alpha, alpha_init)\n",
    "\n",
    "  grouped_params = [\n",
    "  ['T_n' ,'B_n','L_n'],\n",
    "  [ 'GM_T', 'd_IMU'],\n",
    "  ['gain_heave'],\n",
    "  ['tau_2', 'delta_2', 'C_WP_2'],\n",
    "]\n",
    "\n",
    "\n",
    "  directory = 'Plots/Statistics/Boxplots'\n",
    "\n",
    "  plot_tuning_parameters_grouped(df_results_alpha, grouped_params, directory, label_fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_init_8_param = [L, B, T, C_WP, GM_T, delta, tau, d_IMU] # parameters which are to be optimized\n",
    "alpha_init_combined = [L, B, T, gain_heave, L, B, T, C_WP, GM_T, delta, tau, d_IMU]\n",
    "\n",
    "alpha_init_heave = [L, B, T, C_WP, GM_T, delta, tau, d_IMU, gain_heave]\n",
    "\n",
    "nr_run = 1 # test that 23 and 24 is the same\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "\n",
    "start_seg = 0\n",
    "stop_seg = 136\n",
    "nr_segments = stop_seg - start_seg\n",
    "\n",
    "#param_int = 4\n",
    "iterations = 100\n",
    "\n",
    "fmax = 2.15 # PYGAD 100 iters\n",
    "\n",
    "\n",
    "readResultsAll_including_statistics_heave(iterations,start_seg, stop_seg, nr_freqs, nr_run, df_motions_segments, alpha_init_heave, alpha_init_8_param, fmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code for 8 param inc d imu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateResponsSpectrum_own_8_param(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs):\n",
    "\n",
    "    RspecAbs = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad', 'segment'])\n",
    "\n",
    "    timestamp, ws_2d_mu = list(df_ws_segments.items())[segment]\n",
    "    yaw = df_pos_segments_avg[segment]['hdt']  # 1 value per segment. Heading [deg]\n",
    "    U = df_speed_segments_avg[segment]['Speed']  # Speed Over Ground [m/s]\n",
    "\n",
    "    beta_TRF = mu_deg - yaw # Might have to use re_range() here to avoid negative angles\n",
    "    beta_TRF = re_range(beta_TRF) # ensure that beta_TRF is within the range of [0, 360]\n",
    "    beta_TRF_rad = np.deg2rad(beta_TRF)\n",
    "\n",
    "    responseSpectrum_measured_curr_seg_sliced, ws_2d_intrp, fe_sliced = interpolateFreq(f0, fe, segment, timestamp,  responseSpectrum_measured, ws_2d_mu, beta_TRF, mu_deg, step, nr_freqs, plot = False)\n",
    "    fe_sliced_rad = 2* np.pi* (fe_sliced)\n",
    "    \n",
    "    responses = ['Roll_rad','Heave',  'Pitch_rad']\n",
    "\n",
    "    Nabla = None   # Volume Deplacement\n",
    "    A_WP = None # Waterplane area\n",
    "\n",
    "    C_B = Nabla / (alpha[0] * alpha[1] * alpha[2])\n",
    "    #alpha[3] = A_WP / (alpha[0] * alpha[1])\n",
    "\n",
    "    sorted_indices_dirs = np.argsort(beta_TRF_rad)\n",
    "    sorted_ws_2d_beta_dirs = ws_2d_intrp[:, sorted_indices_dirs]\n",
    "    \n",
    "    beta_TRF_sorted = np.sort(beta_TRF)\n",
    "\n",
    "    beta_TRF_rad_sorted = np.sort(beta_TRF_rad)\n",
    "\n",
    "    for response in responses:\n",
    "        \n",
    "        #m0 =  trapezoid(responseSpectrum_measured_ground_truth[response],fe) # variance\n",
    "\n",
    "        # Calculate the CFEs\n",
    "        if response == \"Heave\":\n",
    "            # transfer function for Heave is in units [m/m]\n",
    "            TRF_2d = heaveCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B) # heaveCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "            TRF_2d = np.sqrt(TRF_2d**2 + ((alpha[7]**2) * TRF_roll_tmp**2))\n",
    "            \n",
    "        if response == \"Pitch_rad\":\n",
    "            # transfer function for Pitch is in units [rad/m]\n",
    "            TRF_2d = pitchCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B) # pitchCF(om0,beta_deg,U,L,B0,T,C_B=1)\n",
    "\n",
    "        if response == \"Roll_rad\":\n",
    "            kappa = alpha[3] - alpha[5]\n",
    "            \n",
    "            TRF_2d = rollCF(fe_sliced_rad,beta_TRF_sorted,U,alpha[0],alpha[1],alpha[2],C_B,alpha[3],alpha[4],kappa,alpha[6],T_N=0)\n",
    "            TRF_roll_tmp = TRF_2d\n",
    "\n",
    "        #PlotTRF(TRF_2d, freq_intrp_rad, response, beta_TRF)\n",
    "        #TRF_2d = TRF_2d / (2 * np.pi) # convert the transfer function from rad/s to Hz\n",
    "\n",
    "        # for every response: calculate the response spectrum\n",
    "        #dx = beta_TRF_rad[1] - beta_TRF_rad[0]\n",
    "        integrand = np.abs(TRF_2d * TRF_2d) * sorted_ws_2d_beta_dirs\n",
    "        \n",
    "        RspecAbs_response = trapezoid(integrand, x = beta_TRF_rad_sorted, axis = 1)\n",
    "        RspecAbs[response] = RspecAbs_response\n",
    "\n",
    "    RspecAbs['segment'] = segment\n",
    "\n",
    "    return RspecAbs, responseSpectrum_measured_curr_seg_sliced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateErrorBetweenSpectra_8_param(df_results_alpha_current, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data, alpha_is_series = False):\n",
    "   df_error = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "   #ic(type(df_results_alpha_current))\n",
    "   if isinstance(df_results_alpha_current, pd.Series):\n",
    "      #ic(\"df_results_alpha is a series\")\n",
    "      alpha = df_results_alpha_current.tolist() # it is a nested list, but I want it in 1d, so choose the first segment\n",
    "      #ic(alpha)\n",
    "      #alpha = alpha[:-1] # don't want the included cost function error\n",
    "      #ic(alpha)\n",
    "\n",
    "   elif not isinstance(df_results_alpha_current, list):\n",
    "      #ic(\"df_results_alpha is a pd df\")\n",
    "      alpha = df_results_alpha_current.values.tolist()[0] # it is a nested list, but I want it in 1d, so choose the first segment\n",
    "      #ic(alpha)\n",
    "\n",
    "   else: # df_results_alpha_current is a list -> only alpha\n",
    "      alpha = df_results_alpha_current\n",
    "      #ic(alpha)\n",
    "\n",
    "   error_list = []\n",
    "   m0 = 0\n",
    "\n",
    "   fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced = segment_data\n",
    "\n",
    "\n",
    "   responseSpectrum_calculated_tmp, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own_8_param(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    "\n",
    "\n",
    "   responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "   for response in responses:\n",
    "      m0 =  trapezoid(responseSpectrum_measured_curr_seg_sliced[response],fe_sliced) # variance\n",
    "\n",
    "      measured_spectrum = responseSpectrum_measured_curr_seg_sliced[response].values\n",
    "      calculated_spectrum = responseSpectrum_calculated_tmp[response]\n",
    "\n",
    "      expression = measured_spectrum - calculated_spectrum\n",
    "      error = trapezoid(np.abs(expression), fe_sliced) / m0\n",
    "         \n",
    "      # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "      error_list.append(error)\n",
    "\n",
    "\n",
    "   df_error = pd.DataFrame([error_list], columns=df_error.columns)\n",
    "\n",
    "\n",
    "   # after iterating through all segments\n",
    "   return df_error\n",
    "\n",
    "\n",
    "def normalize_parameters(df, alpha_init_heave):\n",
    "   \"\"\"\n",
    "   Normalizes specified parameters in the DataFrame based on actual physical values.\n",
    "\n",
    "   Parameters:\n",
    "      df (pd.DataFrame): DataFrame containing the data.\n",
    "      params (list of tuples): Each tuple contains the column name to normalize and the actual value.\n",
    "   \"\"\"\n",
    "\n",
    "   params_to_normalize = [\n",
    "      ('L', alpha_init_heave[0]),\n",
    "      ('B', alpha_init_heave[1]),\n",
    "      ('T', alpha_init_heave[2]),\n",
    "      ]\n",
    "\n",
    "   for param, actual in params_to_normalize:\n",
    "      normalized_col_name = f'{param}_n'  # Generates new column name\n",
    "      df[normalized_col_name] = df[param] / actual\n",
    "\n",
    "   return df\n",
    "\n",
    "def plot_tuning_parameters_grouped(df, grouped_params, output_directory, label_fontsize=14):\n",
    "   \"\"\"\n",
    "   Plots grouped boxplots for tuning parameters in a DataFrame. Each group of parameters\n",
    "   will be plotted and saved individually with LaTeX formatting for all labels,\n",
    "   handling double subscripts and normalized variable names.\n",
    "\n",
    "   Parameters:\n",
    "      df (pd.DataFrame): The DataFrame containing the data.\n",
    "      grouped_params (list of lists): Each sublist contains names of three columns to plot together.\n",
    "      output_directory (str): Directory where the plots will be saved.\n",
    "      label_fontsize (int): Font size for x and y labels.\n",
    "   \"\"\"\n",
    "   # Create the output directory if it doesn't exist\n",
    "   if not os.path.exists(output_directory):\n",
    "      os.makedirs(output_directory)\n",
    "\n",
    "   for i, params in enumerate(grouped_params):\n",
    "      # Create a new figure for each group\n",
    "      fig, ax = plt.subplots(figsize=(8, 4))\n",
    "      xlabel = '[-]'\n",
    "\n",
    "      # Apply LaTeX formatting to each parameter name\n",
    "      formatted_params = []\n",
    "      for param in params:\n",
    "            #original_param = param\n",
    "\n",
    "         # Specific handling for parameters like 'd_IMU_2'\n",
    "         if param.startswith('d_IMU_'):\n",
    "            param = 'd_{IMU}'  # Remove numerical suffix and format correctly\n",
    "\n",
    "         elif 'delta' in param:\n",
    "               param = r'\\delta'\n",
    "         elif 'tau' in param:\n",
    "               param = r'\\tau'\n",
    "         elif 'GM' in param:\n",
    "               print(\"in GM\")\n",
    "               param = 'GM_T'\n",
    "               xlabel = r'$[m]$'\n",
    "         elif '_n' in param:\n",
    "               param = param.replace('_n', '')\n",
    "         elif '_' in param and '{' not in param and '}' not in param:\n",
    "               parts = param.split('_')\n",
    "               param = f'{parts[0]}_{{{parts[1]}}}'\n",
    "         formatted_params.append(f'${param}$')\n",
    "\n",
    "      # Prepare data to plot\n",
    "      data_to_plot = [df[param].dropna() for param in params if param in df]\n",
    "      #data_to_plot = [df[original_param].dropna() for original_param in params if original_param in df.columns]\n",
    "\n",
    "\n",
    "      if data_to_plot:\n",
    "         # Plotting the boxplot\n",
    "         box = ax.boxplot(data_to_plot, vert=False, patch_artist=True, showfliers=True,\n",
    "                           flierprops={'marker': 'o', 'color': 'black', 'markersize': 5},\n",
    "                           boxprops={'facecolor': 'white', 'color': 'black'},\n",
    "                           medianprops={'color': 'orange'},\n",
    "                           whiskerprops={'color': 'black', 'linestyle': '--'},\n",
    "                           capprops={'color': 'black'})\n",
    "         # Setting custom y-tick labels\n",
    "         ax.set_yticklabels(formatted_params, fontsize=label_fontsize)\n",
    "         ax.set_xlabel(xlabel, fontsize=label_fontsize)\n",
    "\n",
    "         # Save the individual figure\n",
    "         fig.savefig(f\"{output_directory}/Group_{i+1}.svg\", format='svg', bbox_inches='tight')\n",
    "\n",
    "         # Save the individual figure\n",
    "       # Close the figure to free up memory\n",
    "      plt.close(fig)\n",
    "      #plt.show()\n",
    "       \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------NEW CODE--------------------------------------------\n",
    "\n",
    "def readResults(segment, nr_run, nr_freqs, iterations):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "  \n",
    "  df_results_alpha_path = f\"df_results_ALL/alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_runs_{iterations}_same_init_alpha_8_param_inc_d_IMU_iter_{nr_run}.csv\"\n",
    " \n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "\n",
    "\n",
    "  return df_results_alpha_current\n",
    "\n",
    "def readResultsAll_including_statistics_8_param(iterations,start_seg, stop_seg, nr_freqs, nr_run, df_motions_segments, alpha_init, alpha_init_8_param, fmax):\n",
    "  nperseg = 2048\n",
    "  fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg,plot = None, save = False) # this is given in encounter freq\n",
    "\n",
    "  df_error = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "  df_results_alpha = pd.DataFrame(columns=['L', 'B', 'T', 'C_WP', 'GM_T', 'delta', 'tau', 'd_IMU', 'Error'])\n",
    "\n",
    "  \n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    #ic(segment)\n",
    "\n",
    "    segment_data = prepare_segment_data_no_plot(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "\n",
    "    df_results_alpha_current  = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    # calculates the error for each response for the best resulting parameters of each segment\n",
    "    df_error_current = calculateErrorBetweenSpectra_8_param(df_results_alpha_current, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "\n",
    "    if segment == 0:\n",
    "      df_error = pd.DataFrame(df_error_current, columns=df_error.columns)\n",
    "      df_results_alpha = pd.DataFrame(df_results_alpha_current, columns=df_results_alpha.columns)\n",
    "    else:\n",
    "      df_error = pd.concat([df_error, df_error_current], ignore_index=True)\n",
    "      df_results_alpha = pd.concat([df_results_alpha, df_results_alpha_current], ignore_index=True)\n",
    "    \n",
    "  # Single Mean\n",
    "  alpha_SM = simpleMean(df_results_alpha)\n",
    "  # Weighted Averaged. Is a dictionar\n",
    "  alpha_WA, segments_below_acc_fitness, weights = weightedAvg(df_results_alpha, fmax = fmax)\n",
    "  \n",
    "  ic(len(segments_below_acc_fitness))\n",
    "  ic(segments_below_acc_fitness)\n",
    "  ic(len(weights))\n",
    "\n",
    "\n",
    "  df_error_SM = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_WA = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_WA_std = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_init = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    #ic(segment)\n",
    "    segment_data = prepare_segment_data_no_plot(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "\n",
    "    df_results_alpha_current  = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    # calculates the error for each response for the best resulting parameters of each segment\n",
    "    df_error_current_SM = calculateErrorBetweenSpectra_8_param(alpha_SM, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "    df_error_current_WA = calculateErrorBetweenSpectra_8_param(alpha_WA, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "    df_error_current_init = calculateErrorBetweenSpectra_combined_init(alpha_init_8_param, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data) # for calculating \n",
    "    # this final works uses 8 param solution. \n",
    "    ###\n",
    "    if segment == 0:\n",
    "      df_error_SM = pd.DataFrame(df_error_current_SM, columns=df_error_SM.columns)\n",
    "      df_error_WA = pd.DataFrame(df_error_current_WA, columns=df_error_WA.columns)\n",
    "      df_error_init = pd.DataFrame(df_error_current_init, columns=df_error_init.columns)\n",
    "\n",
    "    else:\n",
    "      df_error_SM = pd.concat([df_error_SM, df_error_current_SM], ignore_index=True)\n",
    "      df_error_WA = pd.concat([df_error_WA, df_error_current_WA], ignore_index=True)\n",
    "      df_error_init = pd.concat([df_error_init, df_error_current_init], ignore_index=True)\n",
    "    ###\n",
    "\n",
    "    if segment not in segments_below_acc_fitness:\n",
    "\n",
    "      if df_error_WA_std.empty and df_error_WA_std.isna().all().all():\n",
    "        df_error_WA_std = pd.DataFrame(df_error_current_WA, columns=df_error_WA_std.columns)\n",
    "\n",
    "      else:\n",
    "        df_error_WA_std = pd.concat([df_error_WA_std, df_error_current_WA], ignore_index=True)\n",
    "\n",
    "  init_mean = df_error_init.mean()\n",
    "  init_std = df_error_init.std()    \n",
    "\n",
    "  segment_specific_tuning_mean = df_error.mean()\n",
    "  segment_specific_tuning_std = df_error.std()\n",
    "\n",
    "  SM_mean = df_error_SM.mean()\n",
    "  SM_std = df_error_SM.std()\n",
    "\n",
    "  WA_mean = df_error_WA.mean()\n",
    "  WA_std = df_error_WA_std.std()\n",
    "  \n",
    "  WA_std_own_func = weighted_std(df_error_WA_std, weights)\n",
    "  ic(WA_std_own_func)\n",
    "  \n",
    "\n",
    "  data = init_mean, init_std, segment_specific_tuning_mean, segment_specific_tuning_std, SM_mean, SM_std, WA_mean, WA_std\n",
    "\n",
    "  printStatsTable(data)\n",
    "\n",
    "  data_w_own_std = init_mean, init_std, segment_specific_tuning_mean, segment_specific_tuning_std, SM_mean, SM_std, WA_mean, WA_std_own_func\n",
    "  printStatsTable(data_w_own_std)\n",
    "\n",
    "  title_file = f'After_optm_results_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD'\n",
    "\n",
    "  df_results_alpha_norm = normalize_parameters(df_results_alpha, alpha_init)\n",
    "\n",
    "  grouped_params = [\n",
    "  ['T_n' ,'B_n','L_n'],\n",
    "  [ 'GM_T', 'd_IMU'],\n",
    "  ['tau_2', 'delta_2', 'C_WP_2'],\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "  directory = 'Plots/Statistics/Boxplots'\n",
    "\n",
    "  plot_tuning_parameters_grouped(df_results_alpha, grouped_params, directory, label_fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "alpha_init_8_param = [L, B, T, C_WP, GM_T, delta, tau, d_IMU] # parameters which are to be optimized\n",
    "alpha_init_combined = [L, B, T, gain_heave, L, B, T, C_WP, GM_T, delta, tau, d_IMU]\n",
    "\n",
    "alpha_init_heave = [L, B, T, C_WP, GM_T, delta, tau, d_IMU, gain_heave]\n",
    "\n",
    "nr_run = 1 # test that 23 and 24 is the same\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "\n",
    "start_seg = 0\n",
    "stop_seg = 136\n",
    "nr_segments = stop_seg - start_seg\n",
    "\n",
    "#param_int = 4\n",
    "iterations = 100\n",
    "\n",
    "fmax = 2.25 # PYGAD 100 iters\n",
    "\n",
    "\n",
    "readResultsAll_including_statistics_8_param(iterations,start_seg, stop_seg, nr_freqs, nr_run, df_motions_segments, alpha_init_8_param, alpha_init_8_param, fmax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 param statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateErrorBetweenSpectra_combined_15_param(df_results_alpha_current, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data, alpha_is_series = False):\n",
    "   df_error = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "   #ic(type(df_results_alpha_current))\n",
    "   if isinstance(df_results_alpha_current, pd.Series):\n",
    "      #ic(\"df_results_alpha is a series\")\n",
    "      alpha = df_results_alpha_current.tolist() # it is a nested list, but I want it in 1d, so choose the first segment\n",
    "      #alpha = alpha[:-1] # don't want the included cost function error\n",
    "      #ic(alpha)\n",
    "\n",
    "   elif not isinstance(df_results_alpha_current, list):\n",
    "      #ic(\"df_results_alpha is a pd df\")\n",
    "      alpha = df_results_alpha_current.values.tolist()[0] # it is a nested list, but I want it in 1d, so choose the first segment\n",
    "      #ic(alpha)\n",
    "\n",
    "   else: # df_results_alpha_current is a list -> only alpha\n",
    "      alpha = df_results_alpha_current\n",
    "      #ic(alpha)\n",
    "\n",
    "   error_list = []\n",
    "   m0 = 0\n",
    "\n",
    "   fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced = segment_data\n",
    "\n",
    "\n",
    "   responseSpectrum_calculated_tmp, responseSpectrum_measured_curr_seg_sliced = calculateResponsSpectrum_own_combined_all_resp(segment, mu_deg, f0, df_pos_segments_avg, df_speed_segments_avg, alpha, df_ws_segments, fe,step, nr_freqs)\n",
    "\n",
    "\n",
    "   responses = ['Heave', 'Roll_rad', 'Pitch_rad']\n",
    "\n",
    "   for response in responses:\n",
    "      m0 =  trapezoid(responseSpectrum_measured_curr_seg_sliced[response],fe_sliced) # variance\n",
    "\n",
    "      measured_spectrum = responseSpectrum_measured_curr_seg_sliced[response].values\n",
    "      calculated_spectrum = responseSpectrum_calculated_tmp[response]\n",
    "\n",
    "      expression = measured_spectrum - calculated_spectrum\n",
    "      error = trapezoid(np.abs(expression), fe_sliced) / m0\n",
    "         \n",
    "      # Integrate the absolute value of the expression over 'fe'. Divide by m0\n",
    "      error_list.append(error)\n",
    "\n",
    "   df_error = pd.DataFrame([error_list], columns=df_error.columns)\n",
    "   return df_error\n",
    "\n",
    "\n",
    "    \n",
    "def prepare_segment_data_no_plot(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False):\n",
    "    # This function prepares the data required for each segment\n",
    "    timestamp, ws_2d_mu = list(df_ws_segments.items())[segment]\n",
    "    yaw = df_pos_segments_avg[segment]['hdt']\n",
    "    U = df_speed_segments_avg[segment]['Speed']\n",
    "\n",
    "\n",
    "\n",
    "    beta_TRF = mu_deg - yaw # Might have to use re_range() here to avoid negative angles\n",
    "    beta_TRF = re_range(beta_TRF) # ensure that beta_TRF is within the range of [0, 360]\n",
    "\n",
    "    responseSpectrum_measured_curr_seg_sliced, ws_2d_intrp, fe_sliced  = interpolateFreq(f0, fe, segment, timestamp,  responseSpectrum_measured, ws_2d_mu, beta_TRF, mu_deg, step, nr_freqs, plot = False)\n",
    "\n",
    "\n",
    "    return fe_sliced, f0, ws_2d_intrp, beta_TRF, fe, U, responseSpectrum_measured_curr_seg_sliced\n",
    "\n",
    "def printTableParams(alpha):\n",
    "\n",
    "   desired_order = ['L_1', 'B_1', 'T_1', 'gain_heave', 'L_2', 'B_2', 'T_2', 'L_3', 'B_3', 'T_3', 'C_WP_2', 'GM_T_2', 'delta_2', 'tau_2', 'd_IMU_2']\n",
    "   alpha_list = alpha\n",
    "   if (type(alpha) != list):\n",
    "   # Extract the corresponding values from the Series\n",
    "      alpha_list = [alpha[key] for key in desired_order if key in alpha]\n",
    "\n",
    "   # Create a DataFrame with the desired order as the header and values as the second row\n",
    "   df = pd.DataFrame([alpha_list], columns=desired_order)\n",
    "\n",
    "   # Display the DataFrame as a table\n",
    "   print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------NEW CODE--------------------------------------------\n",
    "\n",
    "def readResults(segment, nr_run, nr_freqs, iterations):\n",
    "  \"\"\"\n",
    "  Reads the results from the CSV files based on the iteration number provided.\n",
    "\n",
    "  :param nr_run: The iteration number of the results to read.\n",
    "  :return: A tuple of DataFrames containing results from specific folders.\n",
    "  \"\"\"\n",
    "\n",
    "  \n",
    "  df_results_alpha_path = f\"df_results_ALL_combined/alpha_segment_{segment}_fe_{nr_freqs}_mtd_PYGAD_12_param_runs_{iterations}_all_responses_iter_{nr_run}.csv\"\n",
    "\n",
    "  df_results_alpha_current = pd.read_csv(df_results_alpha_path)\n",
    "  \n",
    "\n",
    "  return df_results_alpha_current\n",
    "\n",
    "def readResultsAll_including_statistics_combined(iterations,start_seg, stop_seg, nr_freqs, nr_run, df_motions_segments, alpha_init, alpha_init_8_param, fmax):\n",
    "  nperseg = 2048\n",
    "  fe, responseSpectrum_measured = getListResponseSpectrum(df_motions_segments, nperseg,plot = None, save = False) # this is given in encounter freq\n",
    "\n",
    "  df_error = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "\n",
    "  df_results_alpha = pd.DataFrame(columns=['L_1', 'B_1', 'T_1', 'gain_heave', 'L_2', 'B_2', 'T_2', 'L_3', 'B_3', 'T_3', 'C_WP_2', 'GM_T_2', 'delta_2', 'tau_2', 'd_IMU_2', 'Error'])\n",
    "  \n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    #ic(segment)\n",
    "\n",
    "    segment_data = prepare_segment_data_no_plot(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "\n",
    "    df_results_alpha_current = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "    \n",
    "    # calculates the error for each response for the best resulting parameters of each segment\n",
    "    df_error_current = calculateErrorBetweenSpectra_combined_15_param(df_results_alpha_current, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "\n",
    "    if segment == 0:\n",
    "      df_error = pd.DataFrame(df_error_current, columns=df_error.columns)\n",
    "      df_results_alpha = pd.DataFrame(df_results_alpha_current, columns=df_results_alpha.columns)\n",
    "    else:\n",
    "      df_error = pd.concat([df_error, df_error_current], ignore_index=True)\n",
    "      df_results_alpha = pd.concat([df_results_alpha, df_results_alpha_current], ignore_index=True)\n",
    "    \n",
    "  # Single Mean\n",
    "  alpha_SM = simpleMean(df_results_alpha)\n",
    "  # Weighted Averaged. Is a dictionar\n",
    "  alpha_WA, segments_below_acc_fitness, weights = weightedAvg(df_results_alpha, fmax = fmax)\n",
    "  ic(len(segments_below_acc_fitness))\n",
    "  ic(segments_below_acc_fitness)\n",
    "\n",
    "\n",
    "  print(\"alpha Single Mean\")\n",
    "  printTableParams(alpha_SM)\n",
    "\n",
    "  print(\"alpha Weighted average\")\n",
    "  printTableParams(alpha_WA)\n",
    "  #nr_segments = stop_seg - start_seg\n",
    "  #nr_nonzero_weights =  nr_segments - len(segments_below_acc_fitness)\n",
    "\n",
    "  df_error_SM = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_WA = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_WA_std = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "  df_error_init = pd.DataFrame(columns=['Heave', 'Roll_rad', 'Pitch_rad'])\n",
    "\n",
    "  for segment in range(start_seg, stop_seg):\n",
    "    #ic(segment)\n",
    "    segment_data = prepare_segment_data_no_plot(f0, fe, mu_deg, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg, responseSpectrum_measured, step, nr_freqs, savePolar = False)\n",
    "\n",
    "    df_results_alpha_current = readResults(segment, nr_run, nr_freqs, iterations)\n",
    "  \n",
    "    \n",
    "    # calculates the error for each response for the best resulting parameters of each segment\n",
    "    #calculateErrorBetweenSpectra_combined_15_param\n",
    "    df_error_current_SM = calculateErrorBetweenSpectra_combined_15_param(alpha_SM, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "    df_error_current_WA = calculateErrorBetweenSpectra_combined_15_param(alpha_WA, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data)\n",
    "    df_error_current_init = calculateErrorBetweenSpectra_combined_init(alpha_init_8_param, segment, df_ws_segments, df_pos_segments_avg, df_speed_segments_avg,  mu_deg, fe, segment_data) # for calculating \n",
    "\n",
    "    ###\n",
    "    if segment == 0:\n",
    "      df_error_SM = pd.DataFrame(df_error_current_SM, columns=df_error_SM.columns)\n",
    "      df_error_WA = pd.DataFrame(df_error_current_WA, columns=df_error_WA.columns)\n",
    "      df_error_init = pd.DataFrame(df_error_current_init, columns=df_error_init.columns)\n",
    "\n",
    "    else:\n",
    "      df_error_SM = pd.concat([df_error_SM, df_error_current_SM], ignore_index=True)\n",
    "      df_error_WA = pd.concat([df_error_WA, df_error_current_WA], ignore_index=True)\n",
    "      df_error_init = pd.concat([df_error_init, df_error_current_init], ignore_index=True)\n",
    "    ###\n",
    "\n",
    "    if segment not in segments_below_acc_fitness:\n",
    "\n",
    "      if df_error_WA_std.empty and df_error_WA_std.isna().all().all():\n",
    "        df_error_WA_std = pd.DataFrame(df_error_current_WA, columns=df_error_WA_std.columns)\n",
    "\n",
    "      else:\n",
    "        df_error_WA_std = pd.concat([df_error_WA_std, df_error_current_WA], ignore_index=True)\n",
    "\n",
    "  init_mean = df_error_init.mean()\n",
    "  init_std = df_error_init.std()    \n",
    "\n",
    "  segment_specific_tuning_mean = df_error.mean()\n",
    "  segment_specific_tuning_std = df_error.std()\n",
    "\n",
    "  SM_mean = df_error_SM.mean()\n",
    "  SM_std = df_error_SM.std()\n",
    "\n",
    "  WA_mean = df_error_WA.mean()\n",
    "  WA_std = df_error_WA_std.std()\n",
    "  \n",
    "\n",
    "\n",
    "  WA_std_own_func = weighted_std(df_error_WA_std, weights)\n",
    "  ic(WA_std_own_func)\n",
    "\n",
    "\n",
    "  data = init_mean, init_std, segment_specific_tuning_mean, segment_specific_tuning_std, SM_mean, SM_std, WA_mean, WA_std\n",
    "\n",
    "  #printStatsTable(data)\n",
    "\n",
    "  data_w_own_std = init_mean, init_std, segment_specific_tuning_mean, segment_specific_tuning_std, SM_mean, SM_std, WA_mean, WA_std_own_func\n",
    "  printStatsTable(data_w_own_std)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "alpha_init_8_param = [L, B, T, C_WP, GM_T, delta, tau, d_IMU] # parameters which are to be optimized\n",
    "\n",
    "\n",
    "alpha_init_combined = [L, B, T, gain_heave, L, B, T, C_WP, GM_T, delta, tau, d_IMU]\n",
    "\n",
    "alpha_init_combined_all = [L, B, T, gain_heave, L, B, T, L, B, T, C_WP, GM_T, delta, tau, d_IMU]\n",
    "\n",
    "varbound_combined_all = np.array([\n",
    "[(1/2)*L, (3/2)*L],   # L_1 - Params for heave\n",
    "[(1/2)*B, (3/2)*B],   # B_1\n",
    "[(1/2)*T, (3/2)*T],   # T_1\n",
    "[0.1, 7],     # gain heave,\n",
    "[(1/2)*L, (3/2)*L],   # L_2 --  param for roll\n",
    "[(1/4)*B, 2*B],   # B_2\n",
    "[(1/4)*T, 2*T],   # T_2 -- \n",
    "[(1/2)*L, (3/2)*L],   # L_3 --  param for pitch\n",
    "[(1/4)*B, 2*B],   # B_3\n",
    "[(1/4)*T, 2.5*T],   # T_3 --  \n",
    "[(1/2)*C_WP, (3/2)*C_WP],     # C_WP\n",
    "[0.1, 2*B],   # GM_T\n",
    "[0.1, 0.99],     # delta. if it is 1 a singularity occurs\n",
    "[0.1, 1],     # tau\n",
    "[5, 1/2 * L]    # d_IMU\n",
    "])\n",
    "\n",
    "nr_run = 1 # test that 23 and 24 is the same\n",
    "step = 1\n",
    "nr_freqs = 1000\n",
    "\n",
    "start_seg = 0\n",
    "stop_seg = 136\n",
    "nr_segments = stop_seg - start_seg\n",
    "\n",
    "#param_int = 4\n",
    "iterations = 200\n",
    "\n",
    "#fmax = 2.3 # PYGAD 100 iters\n",
    "#fmax = 1.85 # PYGAD 150 iters\n",
    "#fmax = 2.2 # PYGAD 200 iters\n",
    "fmax =  2.25# PYGAD 300 iters\n",
    "\n",
    "#fmax = 2.3 #LBFGSB\n",
    "#fmax = 2.3 #NM\n",
    "\n",
    "readResultsAll_including_statistics_combined(iterations,start_seg, stop_seg, nr_freqs, nr_run, df_motions_segments, alpha_init_combined_all, alpha_init_8_param, fmax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Misc plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSeaPeak(tp):\n",
    "        print(f\"peak period: {tp}\")\n",
    "        fp = 1/tp\n",
    "        print(f\"peak frequency: {fp}\")\n",
    "        return fp\n",
    "\n",
    "def plotWaveSpectra(df_ws_segments, segment, mu_rad, om0, save = False):\n",
    "        timestamp, ws = list(df_ws_segments.items())[segment]\n",
    "        print(f\" the wave spectra is calculated at timestamp : {timestamp}\")\n",
    "        \n",
    "        #print(f\"this is segment array after masking freq: {segment_array}\")\n",
    "        #responseSpectrum_calculated = responseSpectrum_calculated[segment].loc[mask]\n",
    "        title_fig = f'Wave spectra for segment: {segment} at time: {timestamp}'       \n",
    "        \n",
    "        linewidth_measured = 2\n",
    "        measured_color = 'g'      # green\n",
    "        # A bright red for error\n",
    "        measured_marker = 's'     # Square marker\n",
    "\n",
    "        mu_rad_strings = ['{:.2f}'.format(x) for x in mu_rad]\n",
    "        mu_deg = (mu_rad/np.pi) * 180 \n",
    "        mu_deg_strings = ['{:.2f}'.format(x) for x in mu_deg]\n",
    "        dir_len = len(mu_rad)\n",
    "        dir_indeces = np.arange(dir_len)\n",
    "\n",
    "        print(f\"this is dir_indeces length : {dir_len} and value: {dir_indeces}\")\n",
    "        print(f\"this is the type of om0 : {type(om0)}\")\n",
    "        print(f\"this is omega0 length {len(om0)} and value : {om0}\")\n",
    "\n",
    "        for index in range(dir_len):\n",
    "                ws_per_dir = ws[: , index]\n",
    "                direction_string = mu_rad_strings[index]\n",
    "                direction_string_deg = mu_deg_strings[index]\n",
    "                plt.plot(om0, ws_per_dir)\n",
    "                \n",
    "                # Set titles and labels\n",
    "                plt.title(f\"Wave spectra for direction: {direction_string} rad or {direction_string_deg} deg. Time: {timestamp}\")\n",
    "                plt.xlabel(r\"$Frequency [Hz]$\")\n",
    "                plt.ylabel(\"[m^2 *s/rad]\")\n",
    "\n",
    "                # Add legend\n",
    "                #\"ax.legend()\"\n",
    "                plt.grid(True)\n",
    "                title_file = f'seg_{segment}_WaveSpectra_dir_{index}'\n",
    "\n",
    "                if (save):\n",
    "                        folder_path = 'Plots/WaveSpectra'\n",
    "                        saveSVG(title_file, folder_path)\n",
    "\n",
    "                # Adjust layout for a cleaner look\n",
    "                plt.tight_layout()\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "segment = 0\n",
    "\n",
    "print(\"for swell\")\n",
    "tp_swell = 6.934275\n",
    "\n",
    "fp_swell = printSeaPeak(tp_swell)\n",
    "\n",
    "print(\"for sea\")\n",
    "tp_sea = 3.23489\n",
    "\n",
    "fp_sea = printSeaPeak(tp_sea)\n",
    "\n",
    "plotWaveSpectra(df_ws_segments, segment, mu_rad, om0, save = False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
